# Prompt Instructions

I need you to write a ~1000 word blog post for my Hugo-based site at https://rikkisnah.github.io/ about how Large Language Models work.

## Requirements

### Style Guidelines (match my existing blogs)
- Professional but accessible tone - avoid overly academic language
- Technical depth without jargon overload - explain concepts simply
- Use concrete examples throughout (cloud AI services, GPU clusters, inference endpoints)
- Short paragraphs, clear headers
- No bullet point lists unless absolutely necessary - write in prose

### Structure
1. Hook/intro - why this matters for engineers and developers
2. The Core Idea - explain what an LLM actually is (prediction engine, not magic)
3. How Training Works - simplified explanation with cloud GPU cluster context
4. How Inference Works - explain what happens when you call an API endpoint
5. Practical Examples - show code snippets using Generative AI SDK/API calls
6. Conclusion - tie it back to practical applications and infrastructure

### Code Snippets Required
Include 1-2 Python snippets showing Generative AI API calls:
- Basic text generation call
- Show the request/response to demystify "the magic"

### References Required
- Include numbered references section at the end
- Cite: Generative AI service documentation, Anthropic/OpenAI technical blogs for foundational concepts
- Search for current sources and include URLs

### DO NOT
- Use the acronym "LLM" in headers - spell out "Large Language Model" or use "AI Model"
- Be overly promotional or salesy
- Include more than 2-3 bullet point lists
- Make it sound like a press release

### Format
- Markdown format
- Save to: `./blogs/how-ai-models-work.md`
- Include author line: "Posted by: Rikki Snah | [Current Date]"
- Include tags at the end: `#AIFundamentals #GenerativeAI #MachineLearning #AI`

### References
Use the following files for references and data points:
- `claude2.md`
- `gemini2.md`
- `gemini.md`
- `grok2.md`
- `grok.md`
- `how_llms_learn_from_the_internet_the_training_process.md`
- `How_LLMs_Work_OCI_Blog.md`
- `instructions.md`
- `perplexit.md`
- `perplexity_2.md`