# How I Track OCI AI2 Compute: Sources That Keep Me Ahead

Staying ahead in OCI AI2 Compute is less about a single “golden” source and more about building a repeatable information system. I need fast internal signal, deeper technical context, and external perspective that helps me interpret what matters for NPI, customer impact, and platform evolution. Here is the set of sources I rely on and how I use them together.

## Internal Signal: Slack from AI2 Compute Leaders

Slack is my fastest feedback loop. I monitor threads and updates from @gsiekas, @avnchhab, @ppmcdani, @mdfield, @binwan, @lanyao, and @zberkshi. These leaders often share early details on NPI timelines, hotspot investigations, and the trade-offs behind key decisions. A short message can expose intent, risk, or dependency that is not yet captured in formal documentation.

## Internal Depth: SharePoint and Otube

The AI2 Compute Collaboration Space in SharePoint is my internal knowledge base. It is where I read longer-form articles, postmortems, and architecture notes that connect Slack updates to the underlying technical story.

For structured learning, I watch Otube’s GPU Team Vlog channel. It covers AI2 Compute from the GPU perspective and provides practical explanations of GPU architecture and system behavior. I also use the Engineering Community Brown Bags and Tech Talks (B2T2) channel to keep a system-level view of OCI engineering decisions. These sessions prevent me from getting siloed and show how AI2 Compute fits into broader OCI strategy.

## Key People: Deep Technical Writing

Some of the most valuable information comes from engineers who document their thinking directly. I follow Jag Brar’s Confluence page for insight on network evolution and RDMA design decisions. I also track Nikhil Shetty and Jacob Uecker for focused network design notes and customer-impact context. These sources are high signal because they show how senior engineers reason through constraints and make trade-offs.

## Industry Awareness: Podcasts and Magazines

To keep up with external developments, I listen to The AI Daily Brief. The daily cadence helps me spot patterns across vendor announcements and market shifts that eventually influence customer expectations. I complement that with Harvard Business Review and The Washington Post technology section for leadership and policy context.

## Academic and Research Inputs

Academic sources keep me grounded in foundational research. I read IIT Madras research publications and MIT Technology Review to track emerging ideas and validate where innovation is heading.

For near-term research signals, I monitor Journal Club summaries, the arXiv computer science recent list, and Hugging Face trending papers. I also follow the SemiAnalysis newsletter because it translates research and market data into practical implications for infrastructure and supply chains.

## Engineering Process and Personal Readiness

ECARs are my window into what is changing right now. They surface the design documents under review and expose where validation is still in progress. Even when I am not directly involved, reading ECARs helps me anticipate shifts in design or operational posture.

Finally, I maintain my own technical sharpness. LeetCode keeps my problem-solving instinct healthy, and Educative provides refreshers on system engineering and AI/ML concepts. That baseline makes it easier to read internal docs quickly and contribute with confidence.

## Bringing It Together

My system is simple: Slack for rapid signal, SharePoint and Otube for depth, key engineers for authoritative documentation, external media for awareness, research sources for early indicators, ECARs for decision flow, and practice platforms for personal readiness. When these sources reinforce each other, I can build a reliable mental model of what is happening in AI2 Compute and why it matters. That model keeps me ahead of the news and, more importantly, ready to act on it.
