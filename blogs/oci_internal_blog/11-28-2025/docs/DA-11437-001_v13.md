# DA-11437-001_v13

_Converted from PDF: 2025-11-28_

---

Debug and RAS Guide for NVIDIA Data
Center Products




                                                          bs
Application Note




                                                        La
                                           03 e
                                         5: cl
                                       :1 ra
                                     16 al O
                                   28 ti
                                 1- en
                               -1 fid
                             25 on
                           20 C
                          2 IA
                        71 ID
                      09 NV
                   11 ah
                     sn
                   Ki
                ik
              R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL | PREPARED AND PROVIDED UNDER NDA   DA-11437-001_v13 | September 2025
Document History

DA-11437-001_v13
 Version      Date                     Authors        Description of Change
 01           October 31, 2023         DP, SM         Initial release – Preliminary information
 02           February 21, 2024        DP, SM         > Added error code to Table 1
                                                      > Added “SXID Error Codes” chapter
                                                      > Added error codes to Table 3
                                                      > Updated “Partner Diagnostics Error Codes” chapter
                                                      > Updated “Extended Utility Diagnostic Error Codes”
                                                        chapter




                                                                            bs
                                                      > Updated “Unable to Reach Maximum GPU Clocks”
                                                        section




                                                                          La
 03           May 13, 2024             DP, SM         > Updated Table 4 with error codes




                                              03 e
                                            5: cl
                                                      > Added Section “NVIDIA Grace Partner Diagnostics




                                          :1 ra
                                                        Error Code to Action Mapping”



                                        16 al O
                                                      > Added Section “Troubleshooting Steps”
 04           May 20, 2024             DP, SM         Updated “Next Steps” in Table 4
                                      28 ti
                                    1- en

 05           May 29, 2024             DP, SM         > Updated error codes in Table 3
                                  -1 fid


                                                      > Updated actions in “Troubleshooting Actions for
                                25 on



                                                        CPU Diagnostic Error Codes”
                              20 C




 06           July 9, 2024             DP, SM         Added networking platforms
                             2 IA




 07           October 29, 2024         DP, AB, SM     > Added Section “NVIDIA GB200 NVL Related NVLink
                           71 ID




                                                        MODS Error Code to Action Mapping”
                         09 NV




                                                      > Added “NVLink5 and Link Quality Monitoring”
                                                        chapter
                      11 ah




 08           December 2, 2024         AB, SM         > Updated PCIe Pass or Fail criteria
                        sn




                                                      > Updated Chapter 10 “NVLink5 Diagnostics and Link
                      Ki




                                                        Quality Monitoring”
                  ik




                                                      > Added the following sections:
                R




                                                        • “Ongoing NVLink5 Monitoring Validations”
                                                        • “GB200 NVL Systems Maintenance Flow Overview”
                                                        • “GB200 NVL Replacement Steps”
                                                        • “NVLink5 Data Center Acceptance Validation”
 09           January 24, 2025         AB, KP, SM     Updated sections on GPU EUD and GPU FD error codes
                                                      to action mapping




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                     DA-11437-001_v13 | ii
 Version      Date                     Authors        Description of Change
 10           February 18, 2025        AB, MA, GL,    > Updated Table 1-2: Related Documents
                                       SM             > Updated Chapter 3 SXID Error Codes
                                                      > Chapter 4: Updated sections on L10 Compute
                                                        Diagnostics and L11 Partner Diagnostics Error Code
                                                        to Action Mapping
                                                      > Updated Section 5.2: CPU EUD Related Error Code to
                                                        Action Mapping
                                                      > Updated Chapter 10: NVLink5 Diagnostics and Link
                                                        Quality Monitoring
                                                      > Updated Section 10.3: FEC Histogram Bins
                                                       • Updated Section 10.7: Thresholds and Pass or Fail
                                                         Criteria




                                                                           bs
                                                       • Added Section 10.13 NVLink5 Debug GB200 NVL




                                                                         La
                                                         NVLink Mapping Tools
                                                      > Added Section 14.2: NVDebug for Datacenter




                                              03 e
                                            5: cl
                                                        Products




                                          :1 ra
 11           April 18, 2025           AB, SM         > Added Section 4.6 “NVIDIA CPU Related Common


                                        16 al O
                                                        Error Code to Action Mapping”
                                                      > Updated Section 4.8 “NVIDIA CPU Related Error
                                      28 ti
                                    1- en
                                                        Codes to Action Mapping”
                                  -1 fid


                                                      > Updated Chapter 10 “NVLink5 Diagnostics and Link
                                                        Quality Monitoring”
                                25 on




                                                      > Updated troubleshooting for Ethernet in Table 20-8
                              20 C




 12           June 11, 2025            ZH, AB, SM     > Updated Chapter 10 "NVLink5 Diagnostics and Link
                             2 IA




                                                        Quality Monitoring"
                           71 ID




                                                      > Updated Section 4.2 "L10 Compute Field Diagnostics
                         09 NV




                                                        Error Code to Action Mapping"
                      11 ah




                                                      > Updated Section 4.3 "L11 Rack Field Diagnostics
                                                        Error Code to Action Mapping"
                        sn




                                                      > Updated Section 4.6 "NVIDIA CPU Related Common
                      Ki




                                                        Error Code to Action Mapping"
                  ik




                                                      > Added Chapter 22 "Telemetry in Multi-node NVLink
                R




                                                        Systems
                                                      > Document restructuring to differentiate debug for
                                                        Switch devices in HGX-8 GPU Systems and
                                                        NVSwitches in Multi-node NVLink Systems
 13           September 10, 2025       AB, SM         > Removed sections applicable to "MultiNode NVLink
                                                        Troubleshooting"
                                                      > Added references to "Multi Node NVLink
                                                        Troubleshooting Guide"
                                                      > Added Error Codes to GPU FD, L10 FD, L11 FD and
                                                        CPU FD Error Codes to Action Mapping Tables.
                                                      > Updated Chapter 2 "XID Error Codes"
                                                      > Updated Chapter 3 "SXID Error Codes"
                                                      > Updated Section 20.5 "Link Status Opcodes"


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | iii
Table of Contents

Chapter 1.    Introduction............................................................................................................................ 1
  1.1      Terminology ................................................................................................................................... 2
  1.2      Related Documents .................................................................................................................... 3
Chapter 2.                XID Error Codes..................................................................................................................... 5
Chapter 3.                SXID Error Codes .................................................................................................................. 6
Chapter 4.    Partner Diagnostics Error Codes and Actions .......................................................... 7
  4.1      GPU Field Diagnostics Error Code to Action Mapping ................................................. 8
  4.2      L10 Compute Field Diagnostics Error Code to Action Mapping............................ 18




                                                                                                                    bs
  4.3      L11 Rack Field Diagnostics Error Code to Action Mapping..................................... 36




                                                                                                                  La
  4.4      HGX Baseboard Diagnostics Error Code to Action Mapping .................................. 56
  4.5      Troubleshooting Actions for Partner Diagnostics Error Codes ............................. 60




                                                         03 e
                                                       5: cl
    4.5.1     Missing GPU Property ..................................................................................................... 60




                                                     :1 ra
    4.5.2     Missing GPU ........................................................................................................................ 60

                                                   16 al O
    4.5.3     Missing NVSwitch Property .......................................................................................... 60
                                                 28 ti
    4.5.4     Missing NVSwitch ............................................................................................................. 60
                                               1- en

    4.5.5     Custom BMC Commands ............................................................................................... 60
                                             -1 fid


    4.5.6     Providing Partner Diagnostic Logs ............................................................................ 61
                                           25 on




  4.6      CPU Field Diagnostics Common Error Code to Action Mapping ........................... 61
                                         20 C
                                        2 IA




  4.7      CPU Field Diagnostics Error Code to Action Mapping............................................... 63
                                      71 ID




  4.8      Diagnostic Error Codes .......................................................................................................... 70
                                    09 NV




    4.8.1     Free Memory ....................................................................................................................... 70
    4.8.2     Secure Partition ................................................................................................................. 71
                                 11 ah




    4.8.3     RMA Actions ........................................................................................................................ 71
                                   sn




    4.8.4     CPU Isolation ....................................................................................................................... 71
                                 Ki




    4.8.5     Providing Partner Diagnostic Logs ............................................................................ 71
                            ik
                        R




Chapter 5.   Extended Utility Diagnostic Error Codes ................................................................. 72
  5.1      GPU EUD Error Code to Action Mapping ........................................................................ 72
  5.2      CPU EUD Related Error Code to Action Mapping ........................................................ 83
    5.2.1    List of Tests ......................................................................................................................... 85
Chapter 6.                ECC and Error Containment ......................................................................................... 86
Chapter 7.       Thermal Issues ................................................................................................................... 87
  7.1      Thermal Hardware Slowdown.............................................................................................. 87
  7.2      Thermal Hardware Shutdown and OVERT Event ......................................................... 87
  7.3      Thermal Issue Caused by TIM and Thermal Solutions for Partner Cooled SKUs
           ......................................................................................................................................................... 88
Chapter 8.                System Power Checks..................................................................................................... 89

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                                                 DA-11437-001_v13 | iv
    8.1     Unable to Reach Maximum TGP ......................................................................................... 89
    8.2     Unable to Reach Maximum GPU Clocks .......................................................................... 89
      8.2.1    Redfish for Programmable EDPp................................................................................ 90
      8.2.2    SMBPBI for Programmable EDPp ............................................................................... 90
      8.2.3    NVFlash for Programmable EDPp .............................................................................. 90
    8.3     Checking Power Brake ........................................................................................................... 91
Chapter 9.             PCI Express Hardware Error and GPU Falling off the Bus Scenarios ........... 92
Chapter 10.            NVLink Error Scenarios ................................................................................................... 95
Chapter 11. Checking NVLink State with In-Band and Out-of-Band Tools......................... 97
  11.1    Checking for NVLink State ................................................................................................... 97
    11.1.1 NVSMI .................................................................................................................................... 97




                                                                                                          bs
    11.1.2 DCGM ..................................................................................................................................... 98




                                                                                                        La
    11.1.3 SMBPBI for NVLink State Status ................................................................................ 98
    11.1.4 Checking for NVLink Error Counters ......................................................................... 98




                                                      03 e
                                                    5: cl
    11.1.5 NVSMI .................................................................................................................................... 98




                                                  :1 ra
                                                16 al O
    11.1.6 NVML API.............................................................................................................................. 99
    11.1.7 SMBPBI for NVLink Error Counters ........................................................................... 99
                                              28 ti
                                            1- en
Chapter 12. Debug and Triage ............................................................................................................ 100
                                          -1 fid


  12.1   Baseboard Debug ................................................................................................................... 100
                                        25 on




  12.2   Out-of-Band Debug ............................................................................................................... 101
                                      20 C




  12.3   Firmware Update Issue ........................................................................................................ 101
                                     2 IA




  12.4   PCIe Enumeration and Non-Booting Issue ................................................................... 102
                                   71 ID




  12.5   Thermal Issue ........................................................................................................................... 102
                                 09 NV




Chapter 13. Issue Reporting Guidelines .......................................................................................... 103
                              11 ah




  13.1    Hardware and Software Platform Information .......................................................... 103
                                sn




  13.2    NVDebug for Datacenter Products................................................................................. 103
                              Ki




    13.2.1 Collecting Rack-level Logs in GB NVL Systems ................................................... 104
                         ik




  13.3    System Event Logs and Telemetry Logging ................................................................ 106
                      R




Chapter 14. Out-of-Band Telemetry through Redfish .............................................................. 108
  14.1   Checking PCIe Retimer Link Status Corresponding to SXM................................. 108
  14.2   Checking for SXM PWR_GOOD Status.......................................................................... 109
  14.3   Checking for SXM THERM_OVERT Status ................................................................... 110
  14.4   Checking for ERoT Fatal Error Status ............................................................................ 111
  14.5   Downloading FPGA Register Table .................................................................................. 112
  14.6   Downloading ERoT Logs ...................................................................................................... 112
  14.7   Downloading PCIe Retimer LTSSM Log......................................................................... 113
Chapter 15. Reliability, Availability, and Serviceability ............................................................... 114
  15.1   Error Counters and Thresholds......................................................................................... 114
Chapter 16.            ConnectX-7 Platforms .................................................................................................. 116

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                                      DA-11437-001_v13 | v
     16.1    ConnectX-7 Thermal Issues ............................................................................................... 116
       16.1.1 Thermal Warnings ........................................................................................................... 116
       16.1.2 Thermal Hardware Shutdown and OVERT Event ................................................ 116
     16.2    ConnectX-7 Debug Steps ................................................................................................... 117
       16.2.1 ASIC Thermal Warning Message ............................................................................... 117
       16.2.2 Transceiver Thermal Warning Message ................................................................. 117
     16.3    ConnectX-7 Power ................................................................................................................. 118
Chapter 17. BlueField-3 Platforms .................................................................................................... 119
  17.1   OS Dump .................................................................................................................................... 119
  17.2   DDR .............................................................................................................................................. 121
  17.3   BMC ............................................................................................................................................. 121
  17.4   USB............................................................................................................................................... 122




                                                                                                               bs
  17.5   eMMC .......................................................................................................................................... 122




                                                                                                             La
  17.6   NVMe SDD................................................................................................................................. 123




                                                       03 e
  17.7   Power and Thermal ................................................................................................................ 125




                                                     5: cl
                                                   :1 ra
  17.8   ERoT ............................................................................................................................................. 125


                                                 16 al O
  17.9   1G OOB Interface ................................................................................................................... 125
                                               28 ti
Chapter 18. NVIDIA Quantum-3 Platforms.................................................................................... 126
                                             1- en

  18.1   Link Monitoring ....................................................................................................................... 126
                                           -1 fid


  18.2   PRBS in Test Mode - mlxlink .............................................................................................. 127
                                         25 on




  18.3   Loopback Test ......................................................................................................................... 128
                                       20 C




  18.4   Sideband Management ........................................................................................................ 128
                                      2 IA
                                    71 ID




  18.5   Quantum-3 Thermal .............................................................................................................. 128
                                  09 NV




  18.6   Quantum-3 Power .................................................................................................................. 130
  18.7   IBDiagnet Tool ......................................................................................................................... 130
                               11 ah




  18.8   Security ...................................................................................................................................... 130
                                 sn
                               Ki




Chapter 19. Troubleshooting Networking Interfaces................................................................ 132
  19.1    PCIe Interface .......................................................................................................................... 132
                          ik
                       R




    19.1.1 PCIe Troubleshooting .................................................................................................... 132
    19.1.2 PCIe Useful Metrics ........................................................................................................ 133
    19.1.3 Pass or Fail Criteria......................................................................................................... 133
    19.1.4 Error Detection ................................................................................................................ 134
    19.1.5 Error Reporting and Logging ...................................................................................... 134
  19.2    Ethernet and InfiniBand Interfaces ................................................................................ 135
    19.2.1 Ethernet and InfiniBand Troubleshooting ............................................................. 135
    19.2.2 Link is Down ...................................................................................................................... 135
    19.2.3 Link is Flapping................................................................................................................. 136
    19.2.4 Ethernet and InfiniBand Useful Metrics ................................................................ 137
    19.2.5 Ethernet and InfiniBand Error Detection............................................................... 137
    19.2.6 Ethernet and InfiniBand Error Reporting and Logging .................................... 137

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                                           DA-11437-001_v13 | vi
Chapter 20. Understanding the mlxlink Utility Output ............................................................. 138
  20.1   Operational Information ...................................................................................................... 138
  20.2   Supported Information ........................................................................................................ 139
  20.3   Troubleshooting Information ............................................................................................ 140
  20.4   Physical Counters and BER Information ....................................................................... 140
  20.5   Link Status Opcodes ............................................................................................................. 141




                                                                                                   bs
                                                                                                 La
                                                    03 e
                                                  5: cl
                                                :1 ra
                                              16 al O
                                            28 ti
                                          1- en
                                        -1 fid
                                      25 on
                                    20 C
                                   2 IA
                                 71 ID
                               09 NV
                            11 ah
                              sn
                            Ki
                       ik
                    R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                             DA-11437-001_v13 | vii
List of Figures

Figure 4-1.      GPU Field Diagnostics Error Code ................................................................................. 8
Figure 4-2.      Grace CPU Partner Diagnostics Error Log .............................................................. 61
Figure 13-1      NVDebug Tool in GB NVL Systems Overview ....................................................... 104
Figure 14-1.     Output of PCIe Retimer Link Status through Redfish Example ................... 109
Figure 14-2.     Output of SXM PWR_GOOD Status through Redfish Example.................... 110
Figure 14-3.     Output of SXM ERoT Fatal Error Status through Redfish Example ........... 111




                                                                                           bs
                                                                                         La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                    DA-11437-001_v13 | viii
List of Tables

Table 1-1.       Terminology ............................................................................................................................ 2
Table 1-2.       Related Documents ............................................................................................................. 3
Table 4-1.       Data Center Action to Data Center Description Mapping – GPU FD............... 8
Table 4-2.       GPU Diagnostics Error Code to Action Mapping .................................................. 10
Table 4-3.       L10 Diagnostics Error Code to Action Mapping ................................................... 18
Table 4-4.       L11 Diagnostics Error Code to Action Mapping ................................................... 36
Table 4-5.       HGX Baseboard Diagnostics Error Code to Action Mapping ........................... 57
Table 4-6.       Grace CPU Field Diagnostics Common Error Code to Action Mapping....... 62
Table 4-7.       CPU Field Diagnostics Error Code to Action Mapping ....................................... 63




                                                                                                            bs
Table 5-1.       Data Center Action to Data Center Description Mapping – GPU EUD ........ 73




                                                                                                          La
Table 5-2.       GPU EUD Error Code to Action Mapping ................................................................. 74




                                                03 e
Table 5-3.       CPU EUD Related Error Code to Action Mapping ................................................. 83




                                              5: cl
                                            :1 ra
Table 6-1.       ECC Error Containment .................................................................................................. 86


                                          16 al O
Table 8-1.       SMBPBI for Programmable EDPp Commands ...................................................... 90
Table 9-1.       PCIe Error Scenarios ........................................................................................................ 92
                                        28 ti
                                      1- en
Table 10-1.      NVLink Error Debug and Triage Scenarios .............................................................. 95
                                    -1 fid


Table 15-1.      Error Counters and Thresholds ................................................................................. 114
                                  25 on



Table 17-1.      DDR ....................................................................................................................................... 121
                                20 C




Table 17-2.      BMC ...................................................................................................................................... 121
                               2 IA




Table 17-3.      USB ....................................................................................................................................... 122
                             71 ID




Table 17-4.      eMMC ................................................................................................................................... 122
                           09 NV




Table 17-5.      NVMe SSD .......................................................................................................................... 123
                        11 ah




Table 17-6.      BF-3 Power and Thermal .............................................................................................. 125
                          sn




Table 17-7.      ERoT...................................................................................................................................... 125
                        Ki




Table 17-8.      1G OOB Interface ............................................................................................................ 125
                  ik




Table 18-1.      IB XDR KPI Values............................................................................................................ 127
                R




Table 19-1.      PCIe Gen 3.0 ...................................................................................................................... 133
Table 19-2.      PCIe Gen 4.0 ...................................................................................................................... 133
Table 19-3.      PCIe Gen 5.0 ...................................................................................................................... 134
Table 19-4.      PCIe Related Issues ........................................................................................................ 134
Table 19-5.      Error Reporting and Logging ...................................................................................... 134
Table 19-6.      Link is Down ...................................................................................................................... 136
Table 19-7.      Ethernet and InfiniBand Error Detection............................................................... 137
Table 19-8.      Ethernet and InfiniBand Error Reporting and Logging .................................... 137
Table 20-1.      Operational Information ............................................................................................... 138
Table 20-2.      Supported Information ................................................................................................. 139
Table 20-3.      Link Status Opcodes ...................................................................................................... 141


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                                                         DA-11437-001_v13 | ix
Chapter 1. Introduction



This debug and reliability, availability, and serviceability (RAS) guide for data center
products is intended to assist partners and customers in analyzing and triaging data
center product-related hardware and software issues.




                                                                   bs
This application note describes different error scenarios that may be encountered when




                                                                 La
using the NVIDIA data center graphics processing units (GPUs), NVIDIA® NVSwitch™




                                              03 e
devices, NVIDIA MGX™, NVIDIA DGX™ and NVIDIA HGX™ baseboard products. They




                                            5: cl
include XID, SXID, Field Diagnostics, NVIDIA® NVLink™, and PCIe related errors.




                                          :1 ra
                                        16 al O
XID message is an error message from the NVIDIA driver that is printed to the operating
system’s (OS) kernel log or event log. XID messages indicate that a general GPU error
                                      28 ti
                                    1- en
occurred. The messages can be indicative of a hardware problem, an NVIDIA software
problem, or a user application problem.
                                  -1 fid
                                25 on



SXID message is an error message from the NVIDIA driver for NVSwitch related error
                              20 C




conditions.
                             2 IA




For detailed information on XID and SXID messages, refer to the “GPU Management and
                           71 ID




Deployment” website at: https://docs.nvidia.com/deploy/xid-errors/index.html
                         09 NV




This application note also focuses on different networking platform products such as
                      11 ah




NVIDIA® BlueField®-3 (BF-3) and NVIDIA® CONNECTX®-7 (CX-7), along with shared
                        sn




interfaces across all platforms including PCIe, NVLink, InfiniBand, and Ethernet. Every
                      Ki




section presents relevant commands and debugging procedures to address various error
scenarios.
                  ik
                R




        Note: For troubleshooting guidance related to GB NVL Multi Node NVLink Systems, refer to
        the Multi Node NVLink Troubleshooting Guide (NVOnline: 1138824).




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                         DA-11437-001_v13 | 1
                                                                                                 Introduction



1.1              Terminology
The following table lists the key terms and their descriptions used within this application
note.

Table 1-1.          Terminology
 Term              Description
 AER               Advanced Error Reporting
 AN                Auto Negotiation
 BDF               Bus Device Function
 BMC               Baseboard Management Controller




                                                                             bs
 CEC               Consumer Electronics Control




                                                                           La
 CPO               Co Package Optics
 DDR               Double Data Rate memory




                                              03 e
                                            5: cl
 DLL               Data Link Layer




                                          :1 ra
                                        16 al O
 ELS               External Laser Source
 ERoT              External Root-of-Trust
                                      28 ti
                                    1- en
 EUD               Extended Utility Diagnostic
                                  -1 fid


 FEC               Forward Error Correction
                                25 on



 FW                Firmware
                              20 C




 LACC              Linear Active Copper Cable
                             2 IA




 MDIO              Management Data Input/Output
                           71 ID




 NIC               Network Interface Card
                         09 NV




 NMI               Non-Maskable Interrupt
                      11 ah




 OOB               Out-of-band
                        sn




 OS                Operating System
                      Ki




 PCIe              PCI Express
                  ik




 PLL signals       Phase-Locked Loop Signals
                R




 PLR               Physical Layer Retransmission
 PSID              Parameter Set Identification
 RAS               Reliability, Availability, and Serviceability
 RMA               Returned Material
 RMA               Return Merchandise Authorization
 TLP               Transmission line pulse
 VL                Virtual Lanes
 WJH               What-Just-Happened
 NVSwitch Tray     A physical tray containing the NVSwitch ASICs to which the GPU NVLink devices connect.
 Compute Tray      A physical tray that is inserted into a slot in the rack and has CPUs and GPUs.
 FM                Fabric Manager - NVLink network control plane service is provided by the FM service.


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 2
                                                                                              Introduction


 Term              Description
 GFM               Global Fabric Manager
                   An instance of FM with a specific set of features enabled. There is one GFM per NVLink
                   domain (cluster).
 NVLSM             NVLink Subnet Manager
                   A service that originates from NVIDIA InfiniBand switches and has the modifications to
                   effectively manage NVSwitches.
 Access NVLink     An NVLink between a GPU and an NVSwitch
 Trunk NVLink      An NVLink between NVSwitches
 NVOS              NVIDIA Networking OS, which was previously known as MLNX-OS.
                   NVOS is used as the Switch OS for L1 NVSwitch Trays.
 XID               The XID message is an error report from the NVIDIA driver that is printed to the




                                                                            bs
                   operating system’s kernel log or event log. XID messages indicate that a general GPU




                                                                          La
                   error occurred.




                                              03 e
                                            5: cl
                                          :1 ra
1.2              Related Documents
                                        16 al O
The following table lists the documents that are relevant to this application note.
                                      28 ti
                                    1- en
                                  -1 fid


Table 1-2.          Related Documents
                                25 on




 NVOnline ID                Document Title or Link
                              20 C




 1113192                    Collect eMMC Lifetime Tool
                             2 IA
                           71 ID




 1115699                    XID and SXID Catalog for NVIDIA Data Center Products
                         09 NV




 1092300                    NVIDIA Data Center Products Telemetry Catalog
 1120466                    Partner Diagnostics User Guide
                      11 ah




 1091416                    Data Center Partner Diagnostics Playbook
                        sn




 1123468                    NVIDIA GB200 NVL Service Flow User Guide
                      Ki




 1114436                    NVIDIA NVOS User Manual
                  ik
                R




 1001187                    SMBus Post Box Interface (SMBPBI) For GPUs
 1093241                    NVIDIA Hopper HGX 8-GPU Telemetry Playbook
 1106532                    NVOnline Partner Portal Guidelines
 1117886                    GB200 NVL72 Rack Level Integration and Partner Guidelines
 1118938                    GB200 NVL72 Rack System Build and Assembly Instruction Guide
 1116117                    NVIDIA Server RAS Catalog
 1115302                    NVIDIA Grace CPER Catalog
 1109504                    NVIDIA Debug Tool for Datacenter Products (NVDebug)
 1124813                    GB200 NVL NVLink Mapping Tool
 1126922                    GB200 NVL Mapper Diagnostic Visualization Tool
 1138824                    Multi Node NVLink Troubleshooting Guide



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 3
                                                                                       Introduction


 NVOnline ID                Document Title or Link
 Not applicable             NVIDIA Cumulus Linux User Guide
 Not applicable             NVIDIA Firmware Tools (MFT) Documentation
 Not applicable             NVIDIA Adapter Cards Firmware Release Notes




                                                                          bs
                                                                        La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                  R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                            DA-11437-001_v13 | 4
Chapter 2. XID Error Codes



When the GPU driver is run, it displays any XID errors in the dmesg log. GPU error events
cause the driver to display XID error codes and GPU information in the kernel log.
Error codes provide insight into the cause of the failure and could be used to infer steps




                                                                bs
required to address the failure.




                                                              La
XID error codes can also appear within Virtual Machines (VMs). XID reported within VMs




                                              03 e
                                            5: cl
can be caused by configuration issues in the VM creation and does not necessarily refer




                                          :1 ra
to real hardware faults.


                                        16 al O
For the latest GPU XID error code to action mapping, refer to the NVIDIA Server RAS
                                      28 ti
Catalog (NVOnline: 1116117).
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 5
Chapter 3. SXID Error Codes



When an NVSwitch (based on NVLink4 or older generations of NVLink) port generates a
runtime error, the error report from NVSwitch will be logged with the SXID error code.




                                                                    bs
        Note: SXID error codes are not applicable to NVLink5 NVSwitch devices.




                                                                  La
                                              03 e
Error codes provide insight into the cause of the failure and could be used to infer steps




                                            5: cl
                                          :1 ra
required to address the failure.


                                        16 al O
For more information, refer to the NVIDIA Server RAS Catalog (NVOnline: 1116117).
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                          DA-11437-001_v13 | 6
Chapter 4.                         Partner Diagnostics Error
                                   Codes and Actions



When the NVIDIA Partner Diagnostics is run, it will show the results of the run on the




                                                                    bs
console and create a tarball containing logs from the run. The console output will be




                                                                  La
saved in a file named ‘run.log’ inside the tarball. Faulty systems will cause the diagnostic




                                              03 e
to fail, and it will display ‘FAIL’ along with error codes and error messages for the failing




                                            5: cl
tests on the console and at the end of the run.log file.




                                          :1 ra
                                        16 al O
Error codes provide insight into the cause of the failure and could be used to infer steps
required to address the failure. Refer to the following sections to learn more about the
                                      28 ti
common measures to address the failure per error code.
                                    1- en

>   Section 4.1 “GPU Related Error Code to Action Mapping”
                                  -1 fid
                                25 on



>   Section 4.2 “L10 Compute Field Diagnostics Error Code to Action Mapping”
                              20 C




>   Section 4.3 “L11 Rack Field Diagnostics Error Code to Action Mapping”
                             2 IA




>   Section 4.4 “HGX Baseboard Diagnostics Error Code to Action Mapping”
                           71 ID




>   Section 4.7 “CPU Field Diagnostics Error Code to Action Mapping”
                         09 NV
                      11 ah




        Note: Error Codes to Action Mapping tables presented in this Chapter include a dedicated
                        sn




        column that summarizes the Data Center Actions. Steps itemized in this column may be
        different from the details under the Next Steps column. In some cases, the Next Steps
                      Ki




        column assumes the Integrator who can perform low level device/component triaging and
                  ik




        debug, which may not be possible in the Data Center.
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                          DA-11437-001_v13 | 7
                                                                 Partner Diagnostics Error Codes and Actions


Figure 4-1.         GPU Field Diagnostics Error Code




                                                                               bs
                                                                             La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
4.1              GPU Field Diagnostics Error Code to
                                    1- en
                                  -1 fid



                 Action Mapping
                                25 on
                              20 C




For “GPU Field Diagnostic” related failures, look up the error code in Table 4-2 and follow
                             2 IA




the “Next Steps” column to address the failing system. The “Data Center Action
                           71 ID




Category” corresponding to each error code is also included with the corresponding
                         09 NV




action description in the following table.
                      11 ah
                        sn




Table 4-1.          Data Center Action to Data Center Description Mapping – GPU FD
                      Ki




 Data Center Action Category                 Data Center Description
                  ik
                R




 N/A                                         Not applicable.
 PROD_FIT                                    System is production ready if the error is not seen again, for
                                             e.g. after re-running the test with latest FW and latest Diag.
 PROD_FIT.RESET_DEVICE                       Reset failing device aka hot reset failing device. The system is
                                             then production ready.
 PROD_FIT.RESET_TRAY                         Reset tray with the failing device aka hot reset failing device.
                                             The system is then production ready.
 RECOVERY                                    Running additional tools can get the system back in production.
 RECOVERY.RESET_BM                           Restart bare metal aka cold reboot the system. Running
                                             additional tools can get the system back in production.
 RECOVERY.RESET_TRAY                         Restart tray aka cold reboot the entire tray. Running additional
                                             tools can get the system back in production.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 8
                                                                 Partner Diagnostics Error Codes and Actions


 Data Center Action Category                 Data Center Description
 RECOVERY.RESET_SW                           Warm reboot the system aka reload latest supported installed
                                             firmware / driver. Running additional tools can get the system
                                             back in production.
 RECOVERY.RUN_INFOROM                        Run InfoROM recovery tool. Running additional tools can get
                                             the system back in production. For Blackwell generation of
                                             products, please refer to InfoROM Cleansing for RMA - User
                                             Guide (NVOnline: 1120261).
 REPORT_NV_BUG                               Report Software NVBug to debug root cause with dmesg,
                                             diagnostic error logs, and NVIDIA Bug report tool log attached.
 RETURN_FOR_FURTHER_TRIAGE                   Take the failing tray or board out of production and return the
                                             failing tray or board to the integrator for further triage and
                                             possible RMA.




                                                                               bs
 RMA_DEVICE                                  For Hopper products, take the failing device out of production




                                                                             La
                                             and start RMA qualification for failing device.
                                             For Blackwell products, take the failing board out of production




                                              03 e
                                            5: cl
                                             and start RMA qualification for failing device.




                                          :1 ra
                                             Note that RMA decisions must involve the integrator.



                                        16 al O
                                             Datacenter actions may involve returning the component to
                                             the integrator and may possibly translate to RMA following
                                      28 ti
                                             further testing and investigation done by the integrator.
                                    1- en

 TRIAGE_BOARD                                Take the failing board out of production and follow next action
                                  -1 fid


                                             steps for that error code. If qualified for RMA, RMA the board.
                                25 on



                                             To RMA the board, return the board to the integrator for
                              20 C




                                             further triage.
                             2 IA




 TRIAGE_DEVICE                               For Hopper products, take the failing device out of production
                           71 ID




                                             and follow next action steps for that error code. If qualified for
                         09 NV




                                             RMA, RMA the device.
                                             For Blackwell products, take the failing board out of production
                      11 ah




                                             and follow next action steps for that error code. If qualified for
                        sn




                                             RMA, RMA the device.
                      Ki




 TRIAGE_TRAY                                 Take the tray with the failing device out of production and
                                             follow next action steps for that error code. If qualified for
                  ik




                                             RMA, RMA the board or the networking component. To RMA
                R




                                             the board, return the board to the integrator for further triage.
                                             The guide for RMA of the networking component(s) is RMA
                                             Checklists and Support Upgrade Procedures document.
                                             (https://docs.nvidia.com/networking/display/rmachecklistrev).
 ISOLATE_TRAY                                Isolate the failing tray with the reported information. If it is
                                             unreported which tray is failing, swap and test each Compute
                                             and Switch Tray to confirm what component the problem
                                             follows.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 9
                                                                               Partner Diagnostics Error Codes and Actions


Table 4-2.        GPU Diagnostics Error Code to Action Mapping
                                                                                                           Data Center Action
 Error Code      Error Message        Explanation               Next Steps
                                                                                                           Category
 MODS-           software error       An unexpected             1. Re-test with the latest GPU FD if not   1. REPORT_NV_BUG
 xxxxxxxxx002                         software error has        tested with the latest version.            2. PROD_FIT
                                      occurred.                 2. File Software NVBug to debug root
                                                                cause with dmesg, diagnostic error logs,
                                                                and NVIDIA Bug report tool log attached,
                                                                if the same error code is seen after the
                                                                GPU FD run.

 MODS-           bad parameter        Software error / bad      1. Re-test with the latest GPU FD if not   1. REPORT_NV_BUG
 xxxxxxxxx008    passed to            parameter passed to       tested with the latest version.            2. PROD_FIT
                 function             software function.        2. File Software NVBug to debug root
                                                                cause with dmesg, diagnostic error logs,




                                                                                             bs
                                                                and NVIDIA Bug report tool log attached,




                                                                                           La
                                                                if the same error code is seen after the
                                                                GPU FD run.




                                                            03 e
                                                          5: cl
 MODS-           script failed to     Script failed to          1. Re-test with the latest GPU FD if not   1. REPORT_NV_BUG




                                                        :1 ra
 xxxxxxxxx021    execute              execute.                  tested with the latest version.            2. PROD_FIT



                                                      16 al O
                                                                2. File Software NVBug to debug root
                                                    28 ti       cause with dmesg, diagnostic error logs,
                                                                and NVIDIA Bug report tool log attached,
                                                  1- en

                                                                if the same error code is seen after the
                                                -1 fid


                                                                GPU FD run.
                                              25 on



 MODS-           cannot hook          A software process or     1. Check firmware versions against the     1. PROD_FIT.RESET_DEVICE
                                            20 C




 xxxxxxxxx041    interrupt            GPU state is              latest NVIDIA release firmware versions.
                                      preventing hooking        2. Re-test with latest GPU FD if not
                                           2 IA




                                      interrupts.               tested with the latest GPU FD.
                                         71 ID




                                      -poll_interrupts option   3. Test with latest GPU FD by passing
                                       09 NV




                                      can be used in case       ‘poll_interrupts’ command line option if
                                      the system does not       the same error code is seen after the
                                    11 ah




                                      support MSI or MSI-X      run.
                                      sn




                                      IRQs.                     4. File Software NVBug to debug root
                                    Ki




                                                                cause with dmesg, diagnostic error logs,
                                                                and NVIDIA Bug report tool log attached,
                             ik




                                                                if the same error code is seen after the
                          R




                                                                GPU FD run.

 MODS-           NVRM invalid                                   1. Check firmware versions against the     1. REPORT_NV_BUG
 xxxxxxxxx060    param struct                                   latest NVIDIA release firmware versions.   2. PROD_FIT.RESET_DEVICE
                                                                2. Re-test with latest GPU FD if not
                                                                tested with the latest GPU FD.
                                                                3. File Software NVBug to debug root
                                                                cause with dmesg, diagnostic error logs,
                                                                and NVIDIA Bug report tool log attached,
                                                                if the same error code is seen after the
                                                                GPU FD run.

 MODS-           timeout error        Tests failed with SW      1. Check firmware versions against the     1. TRIAGE_DEVICE
 xxxxxxxxx077                         timeout issue and         latest NVIDIA release firmware versions.
                                      needs further             2. Re-test with the latest GPU FD if not
                                      investigation.            tested with the latest version.
                                                                3. File Software NVBug to debug root


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 10
                                                                              Partner Diagnostics Error Codes and Actions


                                                                                                            Data Center Action
Error Code      Error Message       Explanation               Next Steps
                                                                                                            Category
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached,
                                                              if the same error code is seen after the
                                                              GPU FD run.

MODS-           CRC/Checksum        Computation has           1. Check firmware versions against the        1. RETURN_FOR_
xxxxxxxxx083    miscompare          returned an incorrect     latest NVIDIA release firmware versions.      FURTHER_TRIAGE
                                    answer.                   2. Re-test with the latest GPU FD if not
                                                              tested with the latest version.
                                                              3. Start RMA Qualification if the same
                                                              error code is seen after the GPU FD run.

MODS-           unexpected          Diag received an          1. Check firmware versions against the        1. RETURN_FOR_
xxxxxxxxx097    device interrupts   unexpected interrupt      latest NVIDIA release firmware versions.      FURTHER_TRIAGE




                                                                                            bs
                                    that it considers an      2. Re-test with the latest GPU FD if not
                                    error.                    tested with the latest version.




                                                                                          La
                                                              3. Start RMA Qualification if the same




                                                       03 e
                                                              error code is seen after the GPU FD run.




                                                     5: cl
                                                   :1 ra
MODS-           Invalid InfoROM     InfoROM corruption        1. Check firmware versions against the        1. TRIAGE_DEVICE




                                                 16 al O
xxxxxxxxx124                        has occurred. Recover     latest NVIDIA release firmware versions.
                                    InfoROM by running        2. Run InfoROM recovery tool. For
                                    InfoROM recovery tool.    Blackwell generation of products, please
                                               28 ti
                                             1- en
                                                              refer to InfoROM Cleansing for RMA -
                                           -1 fid


                                                              User Guide (NVOnline: 1120261).
                                                              3. Re-test with the latest GPU FD if not
                                         25 on




                                                              tested with the latest version.
                                       20 C




                                                              4. Start RMA Qualification if the same
                                      2 IA




                                                              error code is seen after the GPU FD run.
                                    71 ID




MODS-           Vbios Certificate   An issue with the         1. Check firmware versions against the        1. RECOVERY.RESET_SW
                                  09 NV




xxxxxxxxx127    Error               VBIOS certificate.        latest NVIDIA release firmware versions.      2. PROD_FIT
                                                              2. Re-test with latest GPU FD if not
                               11 ah




                                                              tested with the latest GPU FD.
                                 sn




                                                              3. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                               Ki




                                                              and NVIDIA Bug report tool log attached,
                           ik




                                                              if the same error code is seen after the
                        R




                                                              GPU FD run.

MODS-           Acceptable          Check cooling systems     1. Check firmware versions against the        1. TRIAGE_DEVICE
xxxxxxxxx139    temperature         and engage with           latest NVIDIA release firmware versions.
                limits exceeded,    NVIDIA.                   2. Re-test with latest GPU FD if not
                or the thermal      Failing part qualifies    tested with the latest GPU FD.
                sensor is broken    for RMA only if the       3. Start RMA qualification if the same
                or miscalibrated    problem is isolated to    error code is seen after the GPU FD run
                                    NVIDIA hardware.          and only if the cooling solution is part of
                                                              NVIDIA hardware.

MODS-           NvLink bus error    NVLink is down or         1. Reseat the failing GPU.                    1. RETURN_FOR_
xxxxxxxxx140                        NVLink errors             2. Ensure GPU devices are detected on         FURTHER_TRIAGE
                                    occurred during           the system using lspci utility.
                                    NVLink testing.           3. Re-test with the latest GPU FD if not
                                                              tested with the latest version.



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                              DA-11437-001_v13 | 11
                                                                                Partner Diagnostics Error Codes and Actions


                                                                                                            Data Center Action
Error Code      Error Message        Explanation                 Next Steps
                                                                                                            Category
                                                                 4. Start RMA qualification if the same
                                                                 error code is seen after the GPU FD run.

MODS-           PCI Express bus      PCIe link errors cause      1. Reseat the failing GPU.                 1. RETURN_FOR_
xxxxxxxxx143    error                PCIe tests to fail.         2. Ensure GPU devices are detected on      FURTHER_TRIAGE
                                                                 the system using lspci utility.
                                                                 3. Re-test with the latest GPU FD if not
                                                                 tested with the latest version.
                                                                 4. Start RMA qualification if the same
                                                                 error code is seen after the GPU FD run.

MODS-           CUDA error           One of the CUDA tests       1. Check firmware versions against the     1. TRIAGE_DEVICE
xxxxxxxxx144                         is failing. File Software   latest NVIDIA release firmware versions.
                                     NV bug and attach           2. Re-test with the latest GPU FD if not




                                                                                              bs
                                     dmesg, diagnostic           tested with the latest version.




                                                                                            La
                                     error logs, NV bug          3. File Software NVBug to debug root
                                     report tool log, to         cause with dmesg, diagnostic error logs,




                                                         03 e
                                     debug root cause.           and NVIDIA Bug report tool log attached,




                                                       5: cl
                                                     :1 ra
                                                                 if the same error code is seen after the
                                                                 GPU FD run.


                                                   16 al O
MODS-           GFW boot             GPU firmware failed to      1. Check firmware versions against the     1. REPORT_NV_BUG
                                                 28 ti
xxxxxxxxx167    reported a failure   initialize                  latest NVIDIA release firmware versions.   2. RECOVERY.RESET_BM
                                               1- en

                                                                 2. Reseat failing GPU.                     3. PROD_FIT
                                             -1 fid


                                                                 3. Perform cold reboot i.e., full system
                                           25 on



                                                                 shutdown and manually reboot again.
                                                                 4. Ensure GPU and NVSwitches are
                                         20 C




                                                                 detected on the system using lspci
                                        2 IA




                                                                 utility.
                                      71 ID




                                                                 5. Re-test with latest GPU FD if not
                                    09 NV




                                                                 tested with the latest GPU FD.
                                                                 6. File Software NVBug to debug root
                                 11 ah




                                                                 cause with dmesg, diagnostic error logs,
                                                                 and NVIDIA Bug report tool log attached
                                   sn




                                                                 if the same error code is seen after the
                                 Ki




                                                                 GPU FD run.
                           ik




MODS-           bad memory           Computation has             1. Check firmware versions against the     1. RETURN_FOR_
                        R




xxxxxxxxx194                         returned an incorrect       latest NVIDIA release firmware versions.   FURTHER_TRIAGE
                                     answer.                     2. Re-test with the latest GPU FD if not
                                                                 tested with the latest version.
                                                                 3. Start RMA qualification if the same
                                                                 error code is seen after the GPU FD run.

MODS-           pci device not       Failure with PCIe           1. Check firmware versions against the     1. RECOVERY.RESET_BM
xxxxxxxxx220    found                device. Must isolate        latest NVIDIA release firmware versions.   2. PROD_FIT
                                     the failure to GPU or       2. Reseat the failing GPU.
                                     baseboard.                  3. Ensure GPU and NVSwitch devices are
                                                                 detected on the system using lspci
                                                                 utility.
                                                                 4. Perform cold reboot i.e., full system
                                                                 shutdown and manually reboot again.
                                                                 5. Re-test with the latest GPU FD if not
                                                                 tested with the latest version.


        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 12
                                                                              Partner Diagnostics Error Codes and Actions


                                                                                                           Data Center Action
Error Code      Error Message       Explanation                Next Steps
                                                                                                           Category
                                                               6. Start RMA qualification if the same
                                                               error code is seen after the GPU FD run.


MODS-           hardware was not    Something prevented        1. Check firmware versions against the      1. TRIAGE_DEVICE
xxxxxxxxx229    initialized         successful hardware        latest NVIDIA release firmware versions.
                                    initialization.            2. Re-test with latest GPU FD.
                                                               3. File Software NVBug to debug root
                                                               cause with dmesg, diagnostic error logs,
                                                               and NVIDIA Bug report tool log attached,
                                                               if the same error code is seen after the
                                                               GPU FD run.




                                                                                            bs
MODS-           Unexpected result   If running GPU FD on a     1. Check firmware versions against the      1. TRIAGE_DEVICE
xxxxxxxxx240    from hardware       single GPU, make sure      latest NVIDIA release firmware versions.




                                                                                          La
                                    the ‘skip_nvlink’          2. Re-test with the latest GPU FD if not




                                                          03 e
                                    parameter is used. If it   tested with the latest version.




                                                        5: cl
                                    is, then there is a        3. File Software NVBug to debug root




                                                      :1 ra
                                    possible setup issue,      cause with dmesg, diagnostic error logs,



                                                    16 al O
                                    confirm that NVLink        and NVIDIA Bug report tool log attached,
                                    topology is connected      if the same error code is seen after the
                                                  28 ti
                                    as expected by             GPU FD run.
                                                1- en

                                    running:
                                              -1 fid


                                    nvidia-smi nvlink -s
                                            25 on




                                    If NVLinks are
                                          20 C




                                    reported as inactive,
                                         2 IA




                                    debug NVLink issue.
                                       71 ID




MODS-           Read parameter      Re-test with the latest    1. Check firmware versions against the      1. TRIAGE_DEVICE
                                     09 NV




xxxxxxxxx272    differs from        GPU Field Diagnostics.     latest NVIDIA release firmware versions.
                expected            (v22.06-12 and later)      2. Re-test with the latest GPU FD if not
                                  11 ah




                                                               tested with the latest version.
                                    sn




                                                               3. File Software NVBug to debug root
                                  Ki




                                                               cause with dmesg, diagnostic error logs,
                                                               and NVIDIA Bug report tool log attached,
                           ik




                                                               if the same error code is seen, after the
                        R




                                                               GPU FD run.

MODS-           Hardware reports    Hardware failure has       1. Check firmware versions against the      1. RETURN_FOR_
xxxxxxxxx276    wrong status        occurred.                  latest NVIDIA release firmware versions.    FURTHER_TRIAGE
                                                               2. Re-test with the latest GPU FD if not
                                                               tested with the latest version.
                                                               3. Start RMA qualification if the same
                                                               error code is seen after the GPU FD run.

MODS-           Power is above      Power is too high          1. Re-test with latest GPU FD if not        1. REPORT_NV_BUG
xxxxxxxxx280    specified limit                                already tested with the latest GPU FD.      2. PROD_FIT
                                                               2. File Software NVBug to debug root
                                                               cause with dmesg, diagnostic error logs,
                                                               and NVIDIA Bug report tool log attached
                                                               if the same error code is seen after the
                                                               run.



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 13
                                                                             Partner Diagnostics Error Codes and Actions


                                                                                                         Data Center Action
Error Code      Error Message       Explanation               Next Steps
                                                                                                         Category
MODS-           Power is below      Power is too low          1. Re-test with latest GPU FD if not       1. REPORT_NV_BUG
xxxxxxxxx288    specified limit                               already tested with the latest GPU FD.     2. PROD_FIT
                                                              2. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached
                                                              if the same error code is seen after the
                                                              run.

MODS-           NvLink discovered   NVLink topology does      1. Check firmware versions against the     1. TRIAGE_DEVICE
xxxxxxxxx311    topology does not   not match expected        latest NVIDIA release firmware versions.
                match required      topology.                 2. Ensure GPU devices are detected on
                topology                                      the system using lspci utility.
                                                              3. Perform cold reboot i.e., full system




                                                                                           bs
                                                              shutdown and manually reboot again.
                                                              4. Reseat failing GPU if reboot did not




                                                                                         La
                                                              resolve the issue.




                                                          03 e
                                                              5. Re-install NVIDIA release driver if




                                                        5: cl
                                                              rebooting and reseating the GPU did not




                                                      :1 ra
                                                              resolve the issue.



                                                    16 al O
                                                              6. Re-test with latest GPU FD if not
                                                              tested with the latest GPU FD.
                                                  28 ti
                                                              7. File Software NVBug to debug root
                                                1- en

                                                              cause with dmesg, diagnostic error logs,
                                              -1 fid


                                                              and NVIDIA Bug report tool log attached,
                                            25 on



                                                              if the same error code is seen after the
                                          20 C




                                                              GPU FD run.
                                         2 IA




MODS-           ECC detected an     Uncorrectable error       1. Check firmware versions against the     1. TRIAGE_DEVICE
                                       71 ID




xxxxxxxxx317    uncorrectable       has occurred, reset for   latest NVIDIA release firmware versions.
                error in FB         row remapping to take     2. Power cycle GPU to trigger row
                                     09 NV




                                    place                     remapping.
                                                              3. Re-test with the latest GPU FD if not
                                  11 ah




                                                              tested with the latest version.
                                    sn




                                                              4. Start RMA qualification if the same
                                  Ki




                                                              error code is seen after the GPU FD run.
                           ik




MODS-           ECC detected an     An uncorrectable error    1. Check firmware versions against the     1. TRIAGE_DEVICE
                        R




xxxxxxxxx319    uncorrectable       has occurred in the L2    latest NVIDIA release firmware versions.
                error in L2         cache, start RMA          2. Re-test with the latest GPU FD if not
                                    qualification for         tested with the latest version.
                                    baseboard including       3. Start RMA qualification if the same
                                    the exact L2.             error code is seen after the GPU FD run.

MODS-           ECC detected a      Rate of correctable       1. Check firmware versions against the     1. TRIAGE_DEVICE
xxxxxxxxx320    correctable error   errors in the SM have     latest NVIDIA release firmware versions.
                in SM, threshold    exceeded threshold,       2. Re-test with the latest GPU FD if not
                exceeded            start RMA qualification   tested with the latest version.
                                    for baseboard             3. Start RMA Qualification if the same
                                    including the exact       error code is seen after the GPU FD run.
                                    SXMs.

MODS-           ECC detected an     An uncorrectable error    1. Check firmware versions against the     1. TRIAGE_DEVICE
xxxxxxxxx321    uncorrectable       has occurred in the SM    latest NVIDIA release firmware versions.
                error in SM         during testing, start     2. Re-test with the latest GPU FD if not


        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                          DA-11437-001_v13 | 14
                                                                             Partner Diagnostics Error Codes and Actions


                                                                                                           Data Center Action
Error Code      Error Message       Explanation               Next Steps
                                                                                                           Category
                                    RMA qualification for     tested with the latest version.
                                    baseboard including       3. Start RMA qualification if the same
                                    the exact SXMs.           error code is seen after the GPU FD run.

MODS-           Cannot pulse fast   GPU is taking too long    1. Reset the tray and retest.                1. RECOVERY.RESET_BM
xxxxxxxx332     enough to           to either:                2. File Software NVBug to debug root         2. REPORT_NV_BUG
                accurately make a   (a) Complete the          cause with dmesg, diagnostic error log,      3. PROD_FIT
                waveform            GEMM workload, or         and NVIDIA Bug report tool log attached
                                    (b) Report that it        if the same error is seen after the GPU
                                    completed the GEMM        FD run.
                                    workload.

MODS-           Buffer mismatch     Start RMA                 1. Check firmware versions against the       1. RETURN_FOR_
xxxxxxxxx341                        qualification for         latest NVIDIA release firmware versions.     FURTHER_TRIAGE




                                                                                            bs
                                    baseboard including       2. Re-test with the latest GPU FD if not
                                    the exact SXMs.           tested with the latest version.




                                                                                          La
                                                              3. Start RMA qualification if the same




                                                       03 e
                                                              error code is seen after the GPU FD run.




                                                     5: cl
                                                   :1 ra
MODS-           memory not          Need access to logs or    1. Check firmware versions against the       1. TRIAGE_DEVICE



                                                 16 al O
xxxxxxxxx351    strapped            failing system to         latest NVIDIA release firmware versions.
                correctly           debug root cause.         2. Re-test with latest GPU FD if not
                                               28 ti
                                                              tested with the latest GPU FD.
                                             1- en

                                                              3. File Software NVBug to debug root
                                           -1 fid


                                                              cause with dmesg, diagnostic error logs,
                                         25 on



                                                              and NVIDIA Bug report tool log attached,
                                                              if the same error code is seen after the
                                       20 C




                                                              GPU FD run.
                                      2 IA




MODS-           Row remapping       A row remapping           1. Check firmware versions against the       1. RETURN_FOR_
                                    71 ID




xxxxxxxxx363    failed              failure has occurred,     latest NVIDIA release firmware versions.     FURTHER_TRIAGE
                                  09 NV




                                    start RMA                 2. Re-test with the latest GPU FD if not
                                    qualification.            tested with the latest version.
                               11 ah




                                                              3. Start RMA qualification if the same
                                 sn




                                                              error code is seen after the GPU FD run.
                               Ki




MODS-           NVRM generic        Ensure the NV driver is   1. Check firmware versions against the       1. REPORT_NV_BUG
                          ik




xxxxxxxxx539    falcon error        fully unloaded, and       latest NVIDIA release firmware versions.     2. PROD_FIT.RESET_DEVICE
                        R




                                    other internal            2. Ensure NVIDIA driver is fully unloaded.
                                    processes do not try      3. Re-test with latest GPU FD if not
                                    to load the driver back   tested with the latest GPU FD.
                                    while running GPU FD.     4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached
                                                              if the same error code is seen after the
                                                              run.

MODS-           NVRM detected       Need access to logs or    1. Check firmware versions against the       1. TRIAGE_DEVICE
xxxxxxxxx541    memory error        failing system to         latest NVIDIA release firmware versions.
                                    debug root cause          2. Re-test with the latest GPU FD if not
                                                              tested with the latest version.
                                                              3. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached,



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 15
                                                                               Partner Diagnostics Error Codes and Actions


                                                                                                              Data Center Action
Error Code      Error Message         Explanation               Next Steps
                                                                                                              Category
                                                                if the same error code is seen after the
                                                                GPU FD run.

MODS-           NVRM VBIOS            It could be due to a      1. Check firmware versions against the        1. REPORT_NV_BUG
xxxxxxxxx542    invalid or rejected   varied NVRM VBIOS         latest NVIDIA release firmware versions.      2. PROD_FIT.RESET_DEVICE
                                      validation failure.       2. Re-test with latest GPU FD if not
                                      File Software NVBug       tested with the latest GPU FD.
                                      and attach dmesg,         3. File Software NVBug to debug root
                                      diagnostic error logs,    cause with dmesg, diagnostic error logs,
                                      NV bug report tool log,   and NVIDIA Bug report tool log attached,
                                      to debug root cause.      if the same error code is seen after the
                                                                GPU FD run.

MODS-           gnu stress test       Computation has           1. Check firmware versions against the        1. RETURN_FOR_




                                                                                             bs
xxxxxxxxx582    found pixel           returned an incorrect     latest NVIDIA release firmware versions.      FURTHER_TRIAGE
                miscompares           answer.                   2. Re-test with the latest GPU FD if not




                                                                                           La
                                                                tested with the latest version.




                                                        03 e
                                                                3. Start RMA qualification if the same




                                                      5: cl
                                                                error code is seen after the GPU FD run.




                                                    :1 ra
                                                  16 al O
MODS-           fan does not          Check cooling systems     1. Check firmware versions against the        1. TRIAGE_DEVICE
xxxxxxxxx599    seem to cool the      and engage with           latest NVIDIA release firmware versions.
                chip                  NVIDIA.                   2. Re-test with latest GPU FD if not
                                                28 ti
                                              1- en
                                      Failing part qualifies    tested with the latest GPU FD.
                                            -1 fid


                                      for RMA only if the       3. Start RMA qualification if the same
                                      problem is isolated to    error code is seen after the run and only
                                          25 on




                                      NVIDIA hardware.          if the cooling solution is part of NVIDIA
                                        20 C




                                                                hardware.
                                       2 IA




MODS-           Interrupt request     -poll_interrupts option   1. Check firmware versions against the        1. PROD_FIT.RESET_DEVICE
                                     71 ID




xxxxxxxxx609    mechanism does        can be used in case       latest NVIDIA release firmware versions.
                                   09 NV




                not work              the system does not       2. Re-test with latest GPU FD if not
                                      support legacy            tested with the latest GPU FD.
                                11 ah




                                      interrupts, MSI or MSI-   3. Test with latest GPU FD by passing ‘-
                                  sn




                                      X IRQs.                   poll_interrupts’ command line option if
                                                                the same error code is seen after the
                                Ki




                                                                GPU FD run.
                            ik




                                                                4. File Software NVBug to debug root
                         R




                                                                cause with dmesg, diagnostic error logs,
                                                                and NVIDIA Bug report tool log attached,
                                                                if the same error code is seen after the
                                                                GPU FD run.

MODS-           Extra golden code     One of the GPU Field      1. Check firmware versions against the        1. RETURN_FOR_
xxxxxxxxx614    miscompare            Diagnostics tests         latest NVIDIA release firmware versions.      FURTHER_TRIAGE
                                      failed the consistency    2. Re-test with the latest GPU FD if not
                                      check on expected         tested with the latest version.
                                      values.                   3. Start RMA qualification if the same
                                                                error code is seen after the GPU FD run.

MODS-           NVRM invalid          Need access to logs or    1. Check firmware versions against the        1. REPORT_NV_BUG
xxxxxxxxx679    argument              failing system to         latest NVIDIA release firmware versions.      2. PROD_FIT.RESET_DEVICE
                                      debug root cause if       2. Run InfoROM recovery tool. For
                                      error is seen after       Blackwell generation of products, please
                                                                refer to InfoROM Cleansing for RMA -


        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                                DA-11437-001_v13 | 16
                                                                             Partner Diagnostics Error Codes and Actions


                                                                                                         Data Center Action
Error Code      Error Message       Explanation               Next Steps
                                                                                                         Category
                                    running InfoROM           User Guide (NVOnline: 1120261).
                                    recovery tool.            3. Re-test with the latest GPU FD if not
                                                              tested with the latest version.
                                                              4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached
                                                              if the same error code is seen after the
                                                              GPU FD run.

MODS-           Failed to perform   Need to restore PCI       1. Check firmware versions against the     1. RECOVERY.RESET_BM
xxxxxxxxx735    hot reset           Config space to           latest NVIDIA release firmware versions.   2. PROD_FIT
                                    resolve the issue.        2. Perform hot reboot, i.e. reboot the
                                                              system to restore PCI config space.
                                                              3. Perform cold reboot i.e., full system




                                                                                          bs
                                                              shutdown and manually reboot again if




                                                                                        La
                                                              hot reboot does not resolve the issue.
                                                              4. Re-test with latest GPU FD if not




                                                      03 e
                                                    5: cl
                                                              tested with the latest GPU FD.




                                                  :1 ra
                                                              5. File Software NVBug to debug root



                                                16 al O
                                                              cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached,
                                              28 ti
                                                              if the same error code is seen after the
                                            1- en

                                                              GPU FD run.
                                          -1 fid


MODS-           Voltage value out   GPU Field Diagnostics     1. Check firmware versions against the     1. REPORT_NV_BUG
                                        25 on



xxxxxxxxx779    of range            bug has been fixed.       latest NVIDIA release firmware versions.   2. PROD_FIT.RESET_DEVICE
                                      20 C




                                                              2. Check the input voltage to the GPU
                                                              and the system power supply.
                                     2 IA




                                                              3. Re-test with the latest GPU FD if not
                                   71 ID




                                                              tested with the latest version.
                                 09 NV




                                                              4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,
                              11 ah




                                                              and NVIDIA Bug report tool log attached,
                                sn




                                                              if the same error code is seen after the
                              Ki




                                                              GPU FD run.
                           ik




MODS-           Mods detected an    A software error has      1. Check firmware versions against the     1. REPORT_NV_BUG
                        R




xxxxxxxxx818    assertion failure   occurred. Need access     latest NVIDIA release firmware versions.   2. PROD_FIT
                                    to logs or failing        2. Re-test with the latest GPU FD if not
                                    system to debug root      tested with the latest version.
                                    cause of the generic      3. File Software NVBug to debug root
                                    failure.                  cause with dmesg, diagnostic error logs,
                                                              and NVIDIA Bug report tool log attached,
                                                              if the same error code is seen after the
                                                              GPU FD run.




        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 17
                                                                               Partner Diagnostics Error Codes and Actions



         4.2               L10 Compute Field Diagnostics Error
                           Code to Action Mapping
         For “L10 Compute Field Diagnostic” related failures, look up the error code in Table 4-3
         and follow the “Next Steps” column to address the failing system. The “Data Center
         Action Category” corresponding to each error code is also included with the
         corresponding action description in the following table.
         The L10 Compute Diag is used to ensure the proper functioning and reliability of various
         hardware components and configurations of a GB NVL Compute Tray. This includes
         checking running environment and infoROM, validating NVIDIA® NVLink®-C2C, PCIe, and
         NVLink™ connectivity, and testing CPU and GPU performance. It tests thermal,
         compute, and memory performance.




                                                                                            bs
                                                                                          La
Table 4-3.          L10 Diagnostics Error Code to Action Mapping




                                                        03 e
                                                      5: cl
Error Code     Error Message    Explanation                    Next Steps                              Data Center Action Category




                                                    :1 ra
MODS-          MODS exited with MODS received a signal to      File Software NVBug to debug root cause 1. REPORT_NV_BUG



                                                  16 al O
xxxxxxxxx001   a specific status exit                          with dmesg, diagnostic error logs, and
                                                               NVIDIA Bug report tool log attached, if
                                                28 ti
                                              1- en
                                                               the same error code is seen after the L10
                                                               Compute Diag run.
                                            -1 fid


MODS-          software error   An unexpected software         1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
                                          25 on




xxxxxxxxx002                    error has occurred.            not tested with the latest L10 Compute     2. PROD_FIT
                                        20 C




                                                               Diag.
                                       2 IA




                                                               2. File Software NVBug to debug and root
                                     71 ID




                                                               cause with dmesg, diagnostic tool logs,
                                   09 NV




                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.
                                11 ah




MODS-          Bad command      Bad command line               1. Check Diag command line.                 1. REPORT_NV_BUG
                                  sn




xxxxxxxxx005   line argument    argument which could be        2. Re-test with latest L10 Compute Diag if 2. PROD_FIT
                                Ki




                                an issue in the Diag tool or   not tested with the latest L10 Compute
                                a user error in the Diag       Diag.
                            ik




                                command line.                  3. If still unresolved, file Software NVBug
                         R




                                                               to debug and root cause with dmesg,
                                                               diagnostic tool logs, and NVIDIA Bug
                                                               report tool log if the same error code is
                                                               seen after the run.

MODS-          bad parameter    Software error / bad           1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx008   passed to        parameter passed to            not tested with the latest L10 Compute     2. PROD_FIT
               function         software function.             Diag.
                                                               2. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          Low Bandwidth    Bandwidth measured             1. Check firmware versions against the    1. ISOLATE_TRAY
xxxxxxxxx014                    during test run is lower       latest NVIDIA release firmware versions. 2. TRIAGE_TRAY
                                than thresholds. Could be      2. Re-test with latest L10 Compute Diag 3. REPORT_NV_BUG
                                                               if not tested with the latest L10 Compute


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 18
                                                                                 Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                   Next Steps                                    Data Center Action Category
                                  an issue with RM driver or    Diag.
                                  NVLink connectivity.          3. Isolate the failing tray. If it is a
                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                4. File Software NVBug to debug and root
                                                                cause with dmesg, diagnostic tool logs,
                                                                NVOS tech support from master
                                                                NVSwitch and NVIDIA Bug report tool log
                                                                if the same error code is seen after the
                                                                run.

MODS-          C2C bus error      Potential issue in C2C bus.   1. If the same error code is seen after the 1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx015                                                    run with latest L10 Diag, return the board




                                                                                               bs
                                                                to the integrator for further triage.




                                                                                             La
                                                                2. Isolate the failing GPU board(s) with
                                                                reported PCIe ID and test with GPU FD.




                                                          03 e
                                                        5: cl
                                                                3. If the same error code is seen after the




                                                      :1 ra
                                                                run with latest Diag, RMA the board or the



                                                    16 al O
                                                                NBU unit. To RMA the board, return the
                                                                board to the integrator for further triage.
                                                  28 ti
                                                                The guide for RMA the NBU unit is RMA
                                                1- en

                                                                Checklists and Support Upgrade
                                              -1 fid


                                                                Procedures
                                            25 on



                                                                (https://docs.nvidia.com/networking/displ
                                                                ay/rmachecklistrev).
                                          20 C
                                         2 IA




MODS-          script failed to   Script failed to execute.     1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx021   execute                                          not tested with the latest L10 Compute     2. PROD_FIT
                                       71 ID




                                                                Diag.
                                     09 NV




                                                                2. File Software NVBug to debug and root
                                                                cause with dmesg, diagnostic tool logs,
                                  11 ah




                                                                and NVIDIA Bug report tool log if the
                                    sn




                                                                same error code is seen after the run.
                                  Ki




MODS-          Process signal     MODS receives a signal and 1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
                              ik




xxxxxxxxx024   received           stops.                     not tested with the latest L10 Compute     2. PROD_FIT
                           R




                                                             Diag.
                                                             2. File Software NVBug to debug and root
                                                             cause with dmesg, diagnostic tool logs,
                                                             and NVIDIA Bug report tool log if the
                                                             same error code is seen after the run.

MODS-          cannot hook        A software process or GPU 1. Check firmware versions against the       1. PROD_FIT.RESET_TRAY
xxxxxxxxx041   interrupt          state is preventing hooking latest NVIDIA release firmware versions.
                                  interrupts.                 2. Re-test with latest L10 Compute Diag if
                                                              not tested with the latest L10 Compute
                                                              Diag.
                                                              3. Isolate the failing GPU board(s) with
                                                              reported PCI id and test with GPU FD.
                                                              4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error logs,




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                              DA-11437-001_v13 | 19
                                                                            Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                Next Steps                                   Data Center Action Category
                                                            and NVIDIA Bug report tool log attached if
                                                            the same error code is seen after the run.

MODS-          Diag crashed,     Device stopped responding, 1. Re-test with latest L10 Compute Diag if 1. PROD_FIT.RESET_TRAY
xxxxxxxxx043   timeout, or did   crashed, or timed out.     not tested with the latest L10 Compute     2. REPORT_NV_BUG
               not respond                                  Diag.
                                                            2. File Software NVBug to debug root
                                                            cause with dmesg, diagnostic error logs,
                                                            and NVIDIA Bug report tool log attached if
                                                            the same error code is seen after the run.

MODS-          NVRM invalid                                 1. Check firmware versions against the     1. REPORT_NV_BUG
xxxxxxxxx060   param struct                                 latest NVIDIA release firmware versions. 2. PROD_FIT.RESET_TRAY
                                                            2. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute




                                                                                          bs
                                                            Diag.




                                                                                        La
                                                            3. File Software NVBug to debug root
                                                            cause with dmesg, diagnostic error logs,




                                                         03 e
                                                            and NVIDIA Bug report tool log attached if




                                                       5: cl
                                                            the same error code is seen after the run.




                                                     :1 ra
                                                   16 al O
MODS-          timeout error     Tests failed with SW       1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx077                     timeout issue and needs
                                                 28 ti      latest NVIDIA release firmware versions.
                                 further investigation.     2. Re-test with latest L10 Compute Diag if
                                               1- en
                                                            not tested with the latest L10 Compute
                                             -1 fid


                                                            Diag.
                                                            3. Isolate the failing unit. To isolate GPU
                                           25 on




                                                            board(s), test the failing GPU board(s)
                                         20 C




                                                            with reported PCI id with GPU FD. To
                                        2 IA




                                                            isolate networking component(s), swap
                                      71 ID




                                                            suspect networking component(s) with
                                    09 NV




                                                            known good parts and retest with the
                                                            latest L10 Compute Diag.
                                 11 ah




                                                            4. File Software NVBug to debug root
                                                            cause with dmesg, diagnostic error logs,
                                   sn




                                                            and NVIDIA Bug report tool log attached if
                                 Ki




                                                            the same error code is seen after the run.
                               ik




                                                            If qualify, RMA the board or the
                          R




                                                            networking component. To RMA the
                                                            board, return the board to the integrator
                                                            for further triage. The RMA guide for
                                                            networking components is the RMA
                                                            Checklists and Support Upgrade
                                                            Procedures document.
                                                            (https://docs.nvidia.com/networking/displ
                                                            ay/rmachecklistrev).

MODS-          CRC/Checksum      Computation has returned   1. Check firmware versions against the     1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx083   miscompare        an incorrect answer.       latest NVIDIA release firmware versions.
                                                            2. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            3. Isolate the failing GPU board(s) with
                                                            reported PCI ID and test with GPU FD.



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                        DA-11437-001_v13 | 20
                                                                                Partner Diagnostics Error Codes and Actions


Error Code     Error Message       Explanation                 Next Steps                                    Data Center Action Category
                                                               4. If the same error code is seen after the
                                                               run, return the board to the integrator
                                                               for further triage.

MODS-          unexpected          Diag received an            1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx097   device interrupts   unexpected interrupt that   latest NVIDIA release firmware versions.
                                   it considers an error.      2. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               3. Isolate the failing GPU board(s) with
                                                               reported PCI id and test with GPU FD.
                                                               4. If the same error code is seen after the
                                                               run, return the board to the integrator
                                                               for further triage.




                                                                                               bs
MODS-          Invalid InfoROM     InfoROM corruption has    1. Check firmware versions against the      1.TRIAGE_TRAY




                                                                                             La
xxxxxxxxx124                       occurred. Recover InfoROM latest NVIDIA release firmware versions.
                                   by running InfoROM        2. Run InfoROM recovery tool. For




                                                           03 e
                                   recovery tool.            Blackwell generation of products, please




                                                         5: cl
                                                             refer to InfoROM Cleansing for RMA - User




                                                       :1 ra
                                                             Guide (NVOnline: 1120261).



                                                     16 al O
                                                             3. Re-test with latest L10 Compute Diag if
                                                             not tested with the latest L10 Compute
                                                   28 ti
                                                 1- en
                                                             Diag.
                                                             4. If the same error code is seen after the
                                               -1 fid


                                                             run, return the board to the integrator
                                             25 on



                                                             for further triage.
                                           20 C




MODS-          Vbios Certificate   An issue with the VBIOS     1. Check firmware versions against the     1. RECOVERY.RESET_SW
                                          2 IA




xxxxxxxxx127   Error               certificate.                latest NVIDIA release firmware versions. 2. PROD_FIT
                                        71 ID




                                                               2. Re-test with latest L10 Compute Diag if
                                      09 NV




                                                               not tested with the latest L10 Compute
                                                               Diag.
                                   11 ah




                                                               3. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                     sn




                                                               and NVIDIA Bug report tool log if the
                                   Ki




                                                               same error code is seen after the run.
                             ik




MODS-          Acceptable          Check cooling systems and 1. Check firmware versions against the          1. TRIAGE_TRAY
                          R




xxxxxxxxx139   temperature         engage with NVIDIA. Failing latest NVIDIA release firmware versions.
               limits exceeded,    part qualifies for RMA only 2. Re-test with latest L10 Compute Diag if
               or the thermal      if the problem is isolated to not tested with the latest L10 Compute
               sensor is broken    NVIDIA hardware.              Diag.
               or miscalibrated                                  3. Isolate the failing unit. To isolate GPU
                                                                 board(s), test the failing GPU board(s)
                                                                 with reported PCI ID with GPU FD. To
                                                                 isolate networking component(s), swap
                                                                 suspect networking component(s) with
                                                                 known good parts and retest with the
                                                                 latest L10 Compute Diag
                                                                 4. If the same error code is seen after the
                                                                 run, return the board to the integrator for
                                                                 further triage. This should be RMA’ed only
                                                                 if the cooling solution is part of NVIDIA



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 21
                                                                               Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                 Next Steps                                  Data Center Action Category
                                                              hardware. If qualified, RMA the board or
                                                              the networking component. To RMA the
                                                              board, return the board to the integrator
                                                              for further triage. The RMA guide for
                                                              networking components is the RMA
                                                              Checklists and Support Upgrade
                                                              Procedures document.
                                                              (https://docs.nvidia.com/networking/displ
                                                              ay/rmachecklistrev).

MODS-          NvLink bus error   NVLink is down or NVLink    1. Reseat the tray containing the failing   1. TRIAGE_TRAY
xxxxxxxxx140                      errors occurred during      GPU.
                                  NVLink testing.             2. Ensure GPU and NVSwitches are
                                                              detected on the system using lspci utility.
                                                              3. Re-test with latest L10 Compute Diag if




                                                                                            bs
                                                              not tested with the latest L10 Compute




                                                                                          La
                                                              Diag.
                                                              4. Isolate the failing unit. To isolate GPU




                                                          03 e
                                                        5: cl
                                                              board(s), test the failing GPU board(s)




                                                      :1 ra
                                                              with reported PCI id with GPU FD. To



                                                    16 al O
                                                              isolate the networking component(s),
                                                              swap suspect networking component(s)
                                                  28 ti
                                                              with known good parts and retest with
                                                1- en

                                                              the latest L10 Compute Diag.
                                              -1 fid


                                                              5. If the same error code is seen after the
                                            25 on



                                                              run, RMA the board or the networking
                                                              component. To RMA the board, return the
                                          20 C




                                                              board to the integrator for further triage.
                                         2 IA




                                                              The RMA guide for networking
                                       71 ID




                                                              components is the RMA Checklists and
                                     09 NV




                                                              Support Upgrade Procedures document.
                                                              (https://docs.nvidia.com/networking/displ
                                  11 ah




                                                              ay/rmachecklistrev).
                                    sn




MODS-          PCI Express bus    PCIe link errors causes PCIe 1. Reseat the tray containing the failing   1. TRIAGE_TRAY
                                  Ki




xxxxxxxxx143   error              tests to fail.               GPU.
                                                               2. Ensure GPU and NVSwitches are
                            ik
                         R




                                                               detected on the system using lspci utility.
                                                               3. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               4. Isolate the failing unit. To isolate GPU
                                                               board(s), test the failing GPU board(s)
                                                               with reported PCI id with GPU FD. To
                                                               isolate networking component(s), swap
                                                               suspect networking component(s) with
                                                               known good parts and retest with the
                                                               latest L10 Compute Diag.
                                                               5. If the same error code is seen after the
                                                               run, RMA the board or the networking
                                                               component. To RMA the board, return the
                                                               board to the integrator for further triage.
                                                               The RMA guide for networking


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 22
                                                                             Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                Next Steps                                  Data Center Action Category
                                                            components is the RMA Checklists and
                                                            Support Upgrade Procedures document.
                                                            (https://docs.nvidia.com/networking/displ
                                                            ay/rmachecklistrev).

MODS-          CUDA error        One of the CUDA tests is   1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx144                     failing.                   latest NVIDIA release firmware versions.
                                                            2. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            3. Isolate the failing GPU board(s) with
                                                            reported PCI ID and test with GPU FD.
                                                            4. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                                                            and NVIDIA Bug report tool log if the




                                                                                          bs
                                                            same error code is seen after the run.




                                                                                        La
                                                            5. If the same error code is seen after the




                                                         03 e
                                                            run, return the board to the integrator




                                                       5: cl
                                                            for further triage.




                                                     :1 ra
MODS-          cuInit failed     Use updated version of        1. Check firmware versions against the     1. REPORT_NV_BUG



                                                   16 al O
xxxxxxxxx145                     diag. Diag releases later     latest NVIDIA release firmware versions. 2. PROD_FIT
                                 than 1.1 should no longer     2. Re-test with latest L10 Compute Diag if
                                                 28 ti
                                               1- en
                                 see this error code.          not tested with the latest L10 Compute
                                 The resolution for this error Diag.
                                             -1 fid


                                 code is the same as that      3. File Software NVBug to debug root
                                           25 on



                                 for 688.                      cause with dmesg, diagnostic error logs,
                                         20 C




                                                               and NVIDIA Bug report tool log attached if
                                        2 IA




                                                               the same error code is seen after the run.
                                      71 ID




MODS-          Resource in use   Resource is reserved by    1. Perform cold reboot i.e., full system   1. PROD_FIT.RESET_TRAY
                                    09 NV




xxxxxxxxx160                     another thread or test.    shutdown and manually reboot again.        2. REPORT_NV_BUG
                                                            2. File Software NVBug to debug root
                                 11 ah




                                                            cause with dmesg, diagnostic error logs,
                                                            and NVIDIA Bug report tool log attached if
                                   sn




                                                            the same error code is seen after the
                                 Ki




                                                            reboot.
                               ik




MODS-          GFW boot           GPU firmware failed to    1. Check firmware versions against the      1. REPORT_NV_BUG
                           R




xxxxxxxxx167   reported a failure initialize                latest NVIDIA release firmware versions. 2. RECOVERY.RESET_BM
                                                            2. Reseat the tray containing the failing   3. PROD_FIT
                                                            GPU.
                                                            3. Perform cold reboot i.e., full system
                                                            shutdown and manually reboot again.
                                                            4. Ensure GPU and NVSwitches are
                                                            detected on the system using lspci utility.
                                                            5. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            6. Isolate the failing GPU board(s) with
                                                            reported PCI ID and test with GPU FD.
                                                            7. File Software NVBug to debug root
                                                            cause with dmesg, diagnostic error logs,




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                        DA-11437-001_v13 | 23
                                                                                Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                   Next Steps                                   Data Center Action Category
                                                                and NVIDIA Bug report tool log attached if
                                                                the same error code is seen.

MODS-          bad memory         Computation has returned      1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx194                      an incorrect answer.          latest NVIDIA release firmware versions.
                                                                2. Re-test with latest L10 Compute Diag if
                                                                not tested with the latest L10 Compute
                                                                Diag.
                                                                3. Isolate the failing GPU board(s) with
                                                                reported PCI ID and test with GPU FD.
                                                                4. If the same error code is seen after the
                                                                run, return the board to the integrator for
                                                                further triage.

MODS-          Could not find     Diag detected inactive        1. Check firmware versions against the      (NVLink)




                                                                                              bs
xxxxxxxxx216   specified device   NVLinks across GPUs. If       latest NVIDIA release firmware versions. 1. ISOLATE_TRAY




                                                                                            La
                                  seen on all NVLinks on a      2. Re-test with latest L10 Compute Diag if 2. TRIAGE_TRAY
                                  GPU, could be a GPU           not tested with the latest L10 Compute      3. REPORT_NV_BUG




                                                          03 e
                                  specific problem.             Diag.                                       (GPU)




                                                        5: cl
                                                                3. If failure seen in NVLink related test   1. RETURN_FOR_FURTHER_TRIAGE




                                                      :1 ra
                                                                (NVLink connectivity issue), isolate the



                                                    16 al O
                                                                failing tray. If it is a Compute Tray, test
                                                                with L10 Compute Diag. If it is a Switch
                                                  28 ti
                                                1- en
                                                                Tray, follow NVIDIA GB200 NVL Service
                                                                Flow User Guide Section 4.3.
                                              -1 fid


                                                                4. If failure seen in non-NVLink related
                                            25 on



                                                                test, it could be a PCIe interface problem.
                                          20 C




                                                                Check if GPUs are enumerated in PCIe
                                         2 IA




                                                                tree via lscpi. Reset Compute Tray to
                                                                confirm if issue persists.
                                       71 ID




                                                                5. Perform cold reboot i.e., full system
                                     09 NV




                                                                shutdown and manually reboot again. If
                                                                issue persists, isolate the failing GPU
                                  11 ah




                                                                board(s) with reported PCI ID and test
                                    sn




                                                                with GPU FD.
                                  Ki




                                                                6. File Software NVBug to debug and root
                                                                cause with dmesg, diagnostic tool logs,
                            ik
                          R




                                                                and NVIDIA Bug report tool log if the
                                                                same error code persists, and the failure
                                                                is not isolated to a particular tray.

MODS-          pci device not     Failure with PCIe device.     1. Check firmware versions against the      1. RECOVERY.RESET_BM
xxxxxxxxx220   found              Need to isolate the failure   latest NVIDIA release firmware versions. 2. PROD_FIT
                                  to GPU, GB200 module or       2. Reseat the tray containing the failing
                                  tray.                         GPU.
                                                                3. Ensure GPU and NVSwitches are
                                                                detected on the system using lspci utility.
                                                                4. Perform cold reboot i.e., full system
                                                                shutdown and manually reboot again.
                                                                5. Re-test with latest L10 Compute Diag if
                                                                not tested with the latest L10 Compute
                                                                Diag.
                                                                6. Isolate the failing unit. To isolate GPU
                                                                board(s), test the failing GPU board(s)


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                            DA-11437-001_v13 | 24
                                                                              Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                 Next Steps                                    Data Center Action Category
                                                             with reported PCI id with GPU FD. To
                                                             isolate the networking component(s),
                                                             swap suspect networking component(s)
                                                             with known good parts and retest with
                                                             the latest L10 Compute Diag.
                                                             7. If the same error code is seen after the
                                                             run, return the board to the integrator for
                                                             further triage.

MODS-          hardware was not Something prevented          1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx229   initialized      successful hardware          latest NVIDIA release firmware versions.
                                initialization.              2. Check all the necessary power cables
                                                             are attached to the tray.
                                                             3. Re-test with latest L10 Compute Diag if
                                                             not tested with the latest L10 Compute




                                                                                            bs
                                                             Diag.




                                                                                          La
                                                             4. Isolate the failing unit. To isolate GPU
                                                             board(s), test the failing GPU board(s)




                                                         03 e
                                                       5: cl
                                                             with reported PCI ID with GPU FD. To




                                                     :1 ra
                                                             isolate the networking component(s),



                                                   16 al O
                                                             swap suspect networking component(s)
                                                             with known good parts and retest with
                                                 28 ti
                                                             the latest L10 Compute Diag.
                                               1- en

                                                             5. File Software NVBug to debug and root
                                             -1 fid


                                                             cause with dmesg, diagnostic tool logs,
                                           25 on



                                                             and NVIDIA Bug report tool log if the
                                                             same error code is seen after the run. If
                                         20 C




                                                             qualified for RMA, RMA the board or the
                                        2 IA




                                                             networking component. To RMA the
                                      71 ID




                                                             board, return the board to the integrator
                                    09 NV




                                                             for further triage. The RMA guide for
                                                             networking components is the RMA
                                 11 ah




                                                             Checklists and Support Upgrade
                                   sn




                                                             Procedures document.
                                                             (https://docs.nvidia.com/networking/displ
                                 Ki




                                                             ay/rmachecklistrev).
                           ik
                         R




MODS-          bad NVIDIA chip   IST detects bad NVIDIA      1. If the same error code is seen after the 1. REPORT_NV_BUG
xxxxxxxxx233                     chip.                       run with latest L10 Compute Diag, file an 2. RETURN_FOR_FURTHER_TRIAGE
                                                             NVBug.
                                                             2. RMA the board or the networking
                                                             component. The guide for RMA the
                                                             networking component is RMA Checklists
                                                             and Support Upgrade Procedures
                                                             (https://docs.nvidia.com/networking/displ
                                                             ay/rmachecklistrev).

MODS-          Unexpected        If running GPU Field         1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx240   result from HW    Diagnostic on single GPU,    latest NVIDIA release firmware versions.
                                 make sure 'skip_nvlink'      2. Re-test with latest L10 Compute Diag if
                                 parameter is used. If it is, not tested with the latest L10 Compute
                                 then there is possible setup Diag.
                                 issue, confirm nvlink        3. Isolate the failing unit. To isolate GPU
                                 topology is connected as     board(s), test the failing GPU board(s)


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 25
                                                                             Partner Diagnostics Error Codes and Actions


Error Code     Error Message    Explanation                  Next Steps                                  Data Center Action Category
                                expected by running:         with reported PCI id with GPU FD. To
                                nvidia-smi nvlink -s         isolate networking component(s), swap
                                                             suspect networking component(s) with
                                If NVLinks are reported as   known good parts and retest with the
                                inactive, debug NVLink       latest L10 Compute Diag.
                                issue per debug tips         4. File Software NVBug to debug and root
                                document.                    cause with dmesg, diagnostic tool logs,
                                                             and NVIDIA Bug report tool log if the
                                                             same error code is seen after the run. If
                                                             qualified for RMA, RMA the board or the
                                                             networking component. To RMA the
                                                             board, return the board to the integrator
                                                             for further triage. The RMA guide for
                                                             networking components is the RMA




                                                                                           bs
                                                             Checklists and Support Upgrade




                                                                                         La
                                                             Procedures document.
                                                             (https://docs.nvidia.com/networking/displ




                                                        03 e
                                                             ay/rmachecklistrev).




                                                      5: cl
                                                    :1 ra
MODS-          Read parameter   Re-test with latest L10      1. Check firmware versions against the     1. TRIAGE_TRAY



                                                  16 al O
xxxxxxxxx272   differs from     Compute Diagnostic.          latest NVIDIA release firmware versions.
               expected                                      2. Re-test with latest L10 Compute Diag if
                                                28 ti
                                                             not tested with the latest L10 Compute
                                              1- en

                                                             Diag.
                                            -1 fid


                                                             3. File Software NVBug to debug and root
                                          25 on



                                                             cause with dmesg, diagnostic tool logs,
                                                             and NVIDIA Bug report tool log if the
                                        20 C




                                                             same error code is seen after the run. If
                                       2 IA




                                                             qualified for RMA, RMA the board or the
                                     71 ID




                                                             networking component. To RMA the
                                   09 NV




                                                             board, return the board to the integrator
                                                             for further triage. The RMA guide for
                                11 ah




                                                             networking components is the RMA
                                  sn




                                                             Checklists and Support Upgrade
                                                             Procedures document.
                                Ki




                                                             (https://docs.nvidia.com/networking/displ
                              ik




                                                             ay/rmachecklistrev).
                         R




MODS-          HW reports       HW failure has occurred.     1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx276   wrong status                                  latest NVIDIA release firmware versions.
                                                             2. Re-test with latest L10 Compute Diag if
                                                             not tested with the latest L10 Compute
                                                             Diag.
                                                             3. Isolate the failing unit. To isolate GPU
                                                             board(s), test the failing GPU board(s)
                                                             with reported PCI ID with GPU FD. To
                                                             isolate networking component(s), swap
                                                             suspect networking component(s) with
                                                             known good parts and retest with the
                                                             latest L10 Compute Diag.
                                                             4. If the same error code is seen after the
                                                             run, RMA the board or the networking
                                                             component. To RMA the board, return the


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 26
                                                                             Partner Diagnostics Error Codes and Actions


Error Code     Error Message    Explanation                 Next Steps                                    Data Center Action Category
                                                            board to the integrator for further triage.
                                                            The RMA guide for networking
                                                            components is the RMA Checklists and
                                                            Support Upgrade Procedures document.
                                                            (https://docs.nvidia.com/networking/displ
                                                            ay/rmachecklistrev).

MODS-          FSP returned     If the plain-text log shows 1. Check firmware versions against the       1. REPORT_NV_BUG
xxxxxxxxx301   non-zero error   MNOC_LOC message, then latest NVIDIA release firmware versions. 2. PROD_FIT
               code             this error is fixed in GB NVL 2. Re-test with latest L10 Compute Diag if
                                FW 1.3 release. Otherwise, not tested with the latest L10 Compute
                                this may imply the FW hit     Diag.
                                an error.                     3. Isolate the failing GPU board(s) with
                                                              reported PCI id and test with GPU FD.
                                                              4. File Software NVBug to debug root




                                                                                            bs
                                                              cause with dmesg, diagnostic error logs,




                                                                                          La
                                                              and NVIDIA Bug report tool log attached if
                                                              the same error code is seen after the run.




                                                        03 e
                                                      5: cl
MODS-          NvLink discovered NVLink topology does not   1. Check firmware versions against the      1. TRIAGE_TRAY




                                                    :1 ra
xxxxxxxxx311   topology does not match expected topology.   latest NVIDIA release firmware versions.



                                                  16 al O
               match required                               2. Ensure GPU and NVSwitches are
               topology                                     detected on the system using lspci utility.
                                                28 ti
                                              1- en
                                                            3. Perform cold reboot i.e., full system
                                                            shutdown and manually reboot again.
                                            -1 fid


                                                            4. Reseat the tray containing the failing
                                          25 on



                                                            GPU if reboot did not resolve the issue.
                                        20 C




                                                            5. Re-install NVIDIA release driver if
                                       2 IA




                                                            rebooting and reseating did not resolve
                                                            the issue.
                                     71 ID




                                                            6. Re-test with latest L10 Compute Diag if
                                   09 NV




                                                            not tested with the latest L10 Compute
                                                            Diag.
                                11 ah




                                                            7. Isolate the failing unit. To isolate GPU
                                  sn




                                                            board(s), test the failing GPU board(s)
                                Ki




                                                            with reported PCI id with GPU FD. To
                                                            isolate networking component(s), swap
                            ik
                         R




                                                            suspect networking component(s) with
                                                            known good parts and retest with the
                                                            latest L10 Compute Diag.
                                                            8. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                                                            and NVIDIA Bug report tool log if the
                                                            same error code is seen after the run. If
                                                            qualified for RMA, RMA the board or the
                                                            networking component. To RMA the
                                                            board, return the board to the integrator
                                                            for further triage. The RMA guide for
                                                            networking components is the RMA
                                                            Checklists and Support Upgrade
                                                            Procedures document.
                                                            (https://docs.nvidia.com/networking/displ
                                                            ay/rmachecklistrev).


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                          DA-11437-001_v13 | 27
                                                                                 Partner Diagnostics Error Codes and Actions


Error Code     Error Message       Explanation                   Next Steps                                Data Center Action Category
MODS-          ECC detected a      N/A                           N/A                                       N/A
xxxxxxxxx316   correctable error
               in FB, threshold
               exceeded

MODS-          ECC detected an     Uncorrectable error has       1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx317   uncorrectable       occurred, reset for row       latest NVIDIA release firmware versions.
               error in FB         remapping to take place.      2. Power cycle to trigger row remapping.
                                                                 3. Re-test with latest L10 Compute Diag if
                                                                 not tested with the latest L10 Compute
                                                                 Diag.
                                                                 4. Isolate the failing GPU board(s) with
                                                                 reported PCI id and test with GPU FD.
                                                                 5. If the same error code is seen after the




                                                                                               bs
                                                                 run, return the board to the integrator
                                                                 for further triage.




                                                                                             La
MODS-          ECC detected a      N/A                           N/A                                       N/A




                                                           03 e
xxxxxxxxx318   correctable error




                                                         5: cl
                                                       :1 ra
               in L2, threshold




                                                     16 al O
               exceeded

MODS-          ECC detected an     An uncorrectable error has    1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
                                                   28 ti
xxxxxxxxx319   uncorrectable       occurred in the L2 cache,     latest NVIDIA release firmware versions.
                                                 1- en

               error in L2         start RMA qualification for   2. Re-test with latest L10 Compute Diag if
                                               -1 fid


                                   the GB200 module              not tested with the latest L10 Compute
                                             25 on



                                   including the failing GPU.    Diag.
                                                                 3. Isolate the failing GPU board(s) with
                                           20 C




                                                                 reported PCI ID and test with GPU FD.
                                          2 IA




                                                                 4. If the same error code is seen after the
                                        71 ID




                                                                 run, return the board to the integrator for
                                      09 NV




                                                                 further triage.

MODS-          ECC detected an     N/A                           N/A                                       N/A
                                   11 ah




xxxxxx171321   uncorrectable
                                     sn




               error in SM
                                   Ki




MODS-          ECC detected a      Rate of correctable errors 1. Check firmware versions against the        1. RETURN_FOR_FURTHER_TRIAGE
                            ik




xxxxxxxxx320   correctable error   in SM have exceeded          latest NVIDIA release firmware versions.
                          R




               in SM, threshold    threshold, start RMA         2. Re-test with latest L10 Compute Diag if
               exceeded            qualification for the GB200 not tested with the latest L10 Compute
                                   module including the failing Diag.
                                   GPU.                         3. Isolate the failing GPU board(s) with
                                                                reported PCI ID and test with GPU FD.
                                                                4. If the same error code is seen after the
                                                                run, return the board to the integrator
                                                                for further triage.

MODS-          ECC detected an     An uncorrectable error has 1. Check firmware versions against the       1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx321   uncorrectable       occurred in the SM during latest NVIDIA release firmware versions.
               error in SM         testing, start RMA           2. Re-test with latest L10 Compute Diag if
                                   qualification for the GB200 not tested with the latest L10 Compute
                                   module including the failing Diag.
                                   GPU.                         3. Isolate the failing GPU board(s) with
                                                                reported PCI ID and test with GPU FD.



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 28
                                                                              Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                 Next Steps                                    Data Center Action Category
                                                             4. If the same error code is seen after the
                                                             run, return the board to the integrator
                                                             for further triage.

MODS-          Cannot pulse fast GPU is taking too long to   1. Reset the tray and retest.              1. RECOVERY.RESET_BM
xxxxxxxxx332   enough to         either:                     2. File Software NVBug to debug root       2. REPORT_NV_BUG
               accurately make a (a) Complete the GEMM       cause with dmesg, diagnostic error log,    3. PROD_FIT
               waveform          workload, or                and NVIDIA Bug report tool log attached if
                                 (b) Report that it          the same error is seen after the L10
                                 completed the GEMM          Compute Diag run.
                                 workload.

MODS-          Buffer mismatch   Start RMA qualification for 1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx341                     the GB200 module            latest NVIDIA release firmware versions.
                                 including the failing GPU.  2. Re-test with latest L10 Compute Diag if




                                                                                             bs
                                                             not tested with the latest L10 Compute




                                                                                           La
                                                             Diag.
                                                             3. Isolate the failing GPU board(s) with




                                                         03 e
                                                             reported PCI ID and test with GPU FD.




                                                       5: cl
                                                             4. If the same error code is seen after the




                                                     :1 ra
                                                             run, return the board to the integrator



                                                   16 al O
                                                 28 ti       for further triage.

MODS-          memory not        Memory not strapped         1. Check firmware versions against the     1. TRIAGE_TRAY
                                               1- en
xxxxxxxxx351   strapped          correctly.                  latest NVIDIA release firmware versions.
                                             -1 fid


               correctly                                     2. Re-test with latest L10 Compute Diag if
                                                             not tested with the latest L10 Compute
                                           25 on




                                                             Diag.
                                         20 C




                                                             3. Isolate the failing GPU board(s) with
                                        2 IA




                                                             reported PCI ID and test with GPU FD.
                                      71 ID




                                                             4. File Software NVBug to debug and root
                                    09 NV




                                                             cause with dmesg, diagnostic tool logs,
                                                             and NVIDIA Bug report tool log if the
                                 11 ah




                                                             same error code is seen after the run.
                                   sn




MODS-          Row remapping     A row remapping failure     1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
                                 Ki




xxxxxxxxx363   failed            has occurred, start RMA     latest NVIDIA release firmware versions.
                                 qualification.              2. Re-test with latest L10 Compute Diag if
                            ik




                                                             not tested with the latest L10 Compute
                         R




                                                             Diag.
                                                             3. Isolate the failing GPU board(s) with
                                                             reported PCI ID and test with GPU FD.
                                                             4. If the same error code is seen after the
                                                             run, return the board to the integrator
                                                             for further triage.

MODS-          NVRM Generic      Ensure NV driver is fully    1. Check firmware versions against the      1. REPORT_NV_BUG
xxxxxxxxx539   falcon error      unloaded, and other          latest NVIDIA release firmware versions. 2. PROD_FIT.RESET_TRAY
                                 internal processes don't try 2. Ensure GPU are detected on the
                                 to load driver back while    system using lspci utility. Ensure loopback
                                 running GPU Field            or switches are connected.
                                 Diagnostic.                  3. Perform cold reboot i.e., full system
                                                              shutdown and manually reboot again.
                                                              4. Re-test with latest L10 Compute Diag if
                                                              not tested with the latest L10 Compute


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 29
                                                                               Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                   Next Steps                                 Data Center Action Category
                                                               Diag.
                                                               5. Isolate the failing GPU board(s) with
                                                               reported PCI id and test with GPU FD.
                                                               6. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          NVRM Detected     Memory issue detected by      1. Check firmware versions against the      1. TRIAGE_TRAY
xxxxxxxxx541   memory error      NVRM.                         latest NVIDIA release firmware versions.
                                                               2. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               3. Isolate the failing unit. To isolate GPU
                                                               board(s), test the failing GPU board(s)




                                                                                             bs
                                                               with reported PCI id with GPU FD. To




                                                                                           La
                                                               isolate networking component(s), swap
                                                               suspect networking component(s) with




                                                         03 e
                                                       5: cl
                                                               known good parts and retest with the




                                                     :1 ra
                                                               latest L10 Compute Diag.



                                                   16 al O
                                                               4. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                 28 ti
                                                               and NVIDIA Bug report tool log if the
                                               1- en

                                                               same error code is seen after the run. If
                                             -1 fid


                                                               qualified for RMA, RMA the board or the
                                           25 on



                                                               networking component. To RMA the
                                                               board, return the board to the integrator
                                         20 C




                                                               for further triage. The RMA guide for
                                        2 IA




                                                               networking components is the RMA
                                      71 ID




                                                               Checklists and Support Upgrade
                                    09 NV




                                                               Procedures document.
                                                               (https://docs.nvidia.com/networking/displ
                                 11 ah




                                                               ay/rmachecklistrev).
                                   sn




MODS-          NVRM VBIOS        It could be due to a varied   1. Check firmware versions against the     1. REPORT_NV_BUG
                                 Ki




xxxxxxxxx542   invalid or        NVRM VBIOS validation         latest NVIDIA release firmware versions. 2. PROD_FIT.RESET_TRAY
               rejected          failure. File Software NV     2. Re-test with latest L10 Compute Diag if
                            ik
                         R




                                 bug and attach dmesg,         not tested with the latest L10 Compute
                                 diagnostic error logs, NV     Diag.
                                 bug report tool log           3. Isolate the failing GPU board(s) with
                                 attached to debug root        reported PCI ID and test with GPU FD.
                                 cause.                        4. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          gnu stress test   Computation has returned      1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx582   found pixel       an incorrect answer.          latest NVIDIA release firmware versions.
               miscompares                                     2. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               3. Isolate the failing GPU board(s) with
                                                               reported PCI ID and test with GPU FD.
                                                               4. If the same error code is seen after the


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 30
                                                                                Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                  Next Steps                                 Data Center Action Category
                                                               run, return the board to the integrator
                                                               for further triage.

MODS-          NVRM not           Need to first check          1. Check firmware versions against the        (NVLink)
xxxxxxxxx597   supported          whether this error code      latest NVIDIA release firmware versions. 1. ISOLATE_TRAY
                                  happens in an NVLink-        2. Re-test with latest L10 Compute Diag if 2. TRIAGE_TRAY
                                  related test or a non-       not tested with the latest L10 Compute        3. REPORT_NV_BUG
                                  NVLink related test.         Diag.                                         (GPU)
                                  Need to check FW version.    3. If failure seen in NVLink related test     1. RETURN_FOR_FURTHER_TRIAGE
                                                               (NVLink connectivity issue), isolate the
                                                               failing tray. If it is a Compute Tray, test
                                                               with L10 Compute Diag. If it is a Switch
                                                               Tray, follow NVIDIA GB200 NVL Service
                                                               Flow User Guide Section 4.3.
                                                               4. If failure seen in non-NVLink related




                                                                                              bs
                                                               test, it could be a PCIe interface problem.




                                                                                            La
                                                               Check if GPUs are enumerated in PCIe




                                                          03 e
                                                               tree via lscpi. Reset Compute Tray to




                                                        5: cl
                                                               confirm if issue persists. If issue persists,




                                                      :1 ra
                                                               isolate the failing GPU board(s) with



                                                    16 al O
                                                               reported PCI ID and test with GPU FD.
                                                               4. File Software NVBug to debug root
                                                  28 ti
                                                               cause with dmesg, diagnostic error logs,
                                                1- en

                                                               and NVIDIA Bug report tool log attached if
                                              -1 fid


                                                               the same error code is seen after the run.
                                            25 on



MODS-          fan does not       Check cooling systems and 1. Check firmware versions against the          1. TRIAGE_TRAY
                                          20 C




xxxxxxxxx599   seem to cool the   engage with NVIDIA. Failing latest NVIDIA release firmware versions.
                                         2 IA




               chip               part qualifies for RMA only 2. Re-test with latest L10 Compute Diag if
                                  if the problem is isolated to not tested with the latest L10 Compute
                                       71 ID




                                  NVIDIA hardware.              Diag.
                                     09 NV




                                                                3. If the same error code is seen after the
                                                                run, return the board to the integrator
                                  11 ah




                                                                for further triage. This should be RMA’ed
                                    sn




                                                                only if the cooling solution is part of
                                  Ki




                                                                NVIDIA hardware. If qualify, RMA the
                                                                board or the networking component. To
                            ik
                           R




                                                                RMA the board, return the board to the
                                                                integrator for further triage. The RMA
                                                                guide for networking components is the
                                                                RMA Checklists and Support Upgrade
                                                                Procedures document.
                                                                (https://docs.nvidia.com/networking/displ
                                                                ay/rmachecklistrev).

MODS-          NVRM Timeout       Driver timeout possibly      1. Perform cold reboot i.e., full system   1. RECOVERY.RESET_BM
xxxxxxxxx603                      because system is in a bad   shutdown followed by a manual reboot.      2. REPORT_NV_BUG
                                  state.                       2. Re-test with latest L10 Compute Diag if
                                                               not already tested with the latest L10
                                                               Compute Diag.
                                                               3. File Software NVBug to debug root
                                                               cause with dmesg, diagnostic error logs,
                                                               and NVIDIA Bug report tool log attached if
                                                               the same error code is seen after the run.


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 31
                                                                                Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                   Next Steps                                   Data Center Action Category
MODS-          Interrupt request A problem with the            1. Check firmware versions against the     1. PROD_FIT.RESET_TRAY
xxxxxxxxx609   mechanism does interrupt request                latest NVIDIA release firmware versions.
               not work          mechanism.                    2. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               3. Isolate the failing GPU board(s) with
                                                               reported PCI ID and test with GPU FD.
                                                               4. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          Extra golden code One of the GPU Field          1. Check firmware versions against the      1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx614   miscompare        Diagnostic tests failed the   latest NVIDIA release firmware versions.




                                                                                               bs
                                 consistency check on          2. Re-test with latest L10 Compute Diag if
                                 expected values.              not tested with the latest L10 Compute




                                                                                             La
                                                               Diag.




                                                        03 e
                                                               3. Isolate the failing GPU board(s) with




                                                      5: cl
                                                               reported PCI ID and test with GPU FD.




                                                    :1 ra
                                                               4. If the same error code is seen after the



                                                  16 al O
                                                               run, return the board to the integrator
                                                               for further triage.
                                                28 ti
                                              1- en
MODS-          NVRM invalid      Usually indicative of a       1. Check firmware versions against the     1. REPORT_NV_BUG
                                            -1 fid


xxxxxxxxx665   parameter         SW/FW issue. Does not         latest NVIDIA release firmware versions. 2. PROD_FIT
                                 point to a system HW          2. Re-test with latest L10 Compute Diag if
                                          25 on




                                 problem.                      not already tested with the latest L10
                                        20 C




                                                               Compute Diag.
                                       2 IA




                                                               4. File Software NVBug to debug root
                                     71 ID




                                                               cause with dmesg, diagnostic error logs,
                                   09 NV




                                                               and NVIDIA Bug report tool log attached if
                                                               the same error code is seen after the run.
                                11 ah




MODS-          NVRM invalid      If error is seen after        1. Check firmware versions against the     1. REPORT_NV_BUG
                                  sn




xxxxxxxxx679   argument          running InfoROM recovery      latest NVIDIA release firmware versions. 2. PROD_FIT.RESET_TRAY
                                 tool, file Software NV bug    2. Run InfoROM recovery tool. For
                                Ki




                                 and attach dmesg,             Blackwell generation of products, please
                              ik




                                 diagnostic error logs, NV     refer to InfoROM Cleansing for RMA - User
                         R




                                 bug report tool log           Guide (NVOnline: 1120261).
                                 attached to debug root        3. Re-test with latest L10 Compute Diag if
                                 cause.                        not tested with the latest L10 Compute
                                                               Diag.
                                                               4. Isolate the failing GPU board(s) with
                                                               reported PCI ID and test with GPU FD.
                                                               5. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          NVRM invalid data GPU driver returns invalid    1. If the same error code is seen after a    1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx682                     data.                         rerun with latest L10 Compute Diag,
                                                               return the board to the integrator for
                                                               further triage.




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                               DA-11437-001_v13 | 32
                                                                              Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                  Next Steps                              Data Center Action Category
MODS-          NVRM Invalid       NVRM reports an invalid      1. Check firmware versions against the        (NVLink)
xxxxxxxxx688   State or Config    state or configuration of an latest NVIDIA release firmware versions. 1. ISOLATE_TRAY
                                  NVLink. One or more          2. Check GFM health on master NVSwitch 2. TRIAGE_TRAY
                                  NVLinks is in an invalid     by running ‘nv show cluster apps running’ 3. REPORT_NV_BUG
                                  state. Could be an issue     NVOS CLI command.                             (GPU)
                                  with the Global Fabric       3. Re-test with latest L10 Compute Diag if 1. RETURN_FOR_FURTHER_TRIAGE
                                  Manager on master            not tested with the latest L10 Compute
                                  NVSwitch.                    Diag.
                                                               4. If failure seen in NVLink related test
                                                               (NVLink connectivity issue), isolate the
                                                               failing tray. If it is a Compute Tray, test
                                                               with L10 Compute Diag. If it is a Switch
                                                               Tray, follow NVIDIA GB200 NVL Service
                                                               Flow User Guide Section 4.3.




                                                                                           bs
                                                               5. If failure seen in non-NVLink related




                                                                                         La
                                                               test, it could be a PCIe interface problem.
                                                               Check if GPUs are enumerated in PCIe




                                                         03 e
                                                       5: cl
                                                               tree via lscpi. Reset Compute Tray to




                                                     :1 ra
                                                               confirm if issue persists.



                                                   16 al O
                                                               6. Perform cold reboot i.e., full system
                                                 28 ti         shutdown and manually reboot again. If
                                                               issue persists, isolate the failing GPU
                                               1- en

                                                               board(s) with reported PCI ID and test
                                             -1 fid


                                                               with GPU FD.
                                           25 on



                                                               7. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                         20 C




                                                               NVOS tech support from master
                                        2 IA




                                                               NVSwitch and NVIDIA Bug report tool log
                                      71 ID




                                                               if the same error code persists, and the
                                    09 NV




                                                               failure is not isolated to a particular tray.

MODS-          Failed to perform An issue with hot resetting   1. Check firmware versions against the     1. RECOVERY.RESET_BM
                                 11 ah




xxxxxxxxx735   hot reset         the device via Diag. File     latest NVIDIA release firmware versions. 2. PROD_FIT
                                   sn




                                 Software NV bug and           2. Perform hot reboot, i.e. reboot the
                                 Ki




                                 attach dmesg, diagnostic      system to restore PCI config space.
                                 error logs, NV bug report     3. Perform cold reboot i.e., full system
                            ik




                                 tool log attached to debug    shutdown and manually reboot again if
                         R




                                 root cause.                   hot reboot does not resolve the issue.
                                                               4. Re-test with latest L10 Compute Diag if
                                                               not tested with the latest L10 Compute
                                                               Diag.
                                                               5. Isolate the failing GPU board(s) with
                                                               reported PCI ID and test with GPU FD.
                                                               6. File Software NVBug to debug and root
                                                               cause with dmesg, diagnostic tool logs,
                                                               and NVIDIA Bug report tool log if the
                                                               same error code is seen after the run.

MODS-          Voltage value out Voltage value is out of       1. Check firmware versions against the     1. REPORT_NV_BUG
xxxxxxxxx779   of range          range.                        latest NVIDIA release firmware versions. 2. PROD_FIT.RESET_TRAY
                                                               2. Check the input voltage to the GPU and
                                                               the system power supply.
                                                               3. Re-test with latest L10 Compute Diag if


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 33
                                                                            Partner Diagnostics Error Codes and Actions


Error Code     Error Message    Explanation                 Next Steps                                 Data Center Action Category
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            4. Isolate the failing GPU board(s) with
                                                            reported PCI ID and test with GPU FD.
                                                            5. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                                                            and NVIDIA Bug report tool log if the
                                                            same error code is seen after the run.

MODS-          Mods detected an A software error has        1. Check firmware versions against the     1. REPORT_NV_BUG
xxxxxxxxx818   assertion failure occurred.                  latest NVIDIA release firmware versions. 2. PROD_FIT
                                                            2. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            3. Isolate the failing GPU board(s) with




                                                                                         bs
                                                            reported PCI ID and test with GPU FD.




                                                                                       La
                                                            4. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,




                                                       03 e
                                                     5: cl
                                                            and NVIDIA Bug report tool log if the




                                                   :1 ra
                                                            same error code is seen after the run.



                                                 16 al O
MODS-          TLW Error        An error in the TLW         1. Check firmware versions against the      1. ISOLATE_TRAY
xxxxxxxxx936                    (Transaction Layer          latest NVIDIA release firmware versions. 2. TRIAGE_TRAY
                                               28 ti
                                             1- en
                                Wrapper) module on an       2. Re-test with latest L10 Compute Diag if 3. REPORT_NV_BUG
                                NVLink port.                not tested with the latest L10 Compute
                                           -1 fid


                                                            Diag.
                                         25 on



                                                            3. Isolate the failing tray. If it is a
                                       20 C




                                                            Compute Tray, test with L10 Compute
                                      2 IA




                                                            Diag. If it is a Switch Tray, follow NVIDIA
                                                            GB200 NVL Service Flow User Guide
                                    71 ID




                                                            Section 4.3.
                                  09 NV




                                                            4. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                               11 ah




                                                            NVOS tech support (for Switch Tray) and
                                 sn




                                                            NVIDIA Bug report tool log if the same
                               Ki




                                                            error code is seen after the run.
                           ik




MODS-          NVLINK: TREX     NVLink transmission error   1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
                           R




xxxxxxxxx937   Error            in the TREX component.      not tested with the latest L10 Compute     2. PROD_FIT
                                                            Diag.
                                                            2. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                                                            and NVIDIA Bug report tool log if the
                                                            same error code is seen after the run.

MODS-          Segfault                                     1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx999                                                not tested with the latest L10 Compute
                                                            Diag.
                                                            2. File Software NVBug to debug and root
                                                            cause with dmesg, diagnostic tool logs,
                                                            and NVIDIA Bug report tool log if the
                                                            same error code is seen after the run.

DGX-           MODS exited with Software issue              1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx001   status 1                                     not tested with the latest L10 Compute     2. PROD_FIT


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 34
                                                                              Partner Diagnostics Error Codes and Actions


Error Code     Error Message      Explanation                 Next Steps                                 Data Center Action Category
                                                              Diag.
                                                              2. File Software NVBug to debug and root
                                                              cause with dmesg, diagnostic tool logs,
                                                              and NVIDIA Bug report tool log if the
                                                              same error code is seen after the run.

DGX-           timeout            An unexpected watchdog      1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx002                      timeout during the Diag     not tested with the latest L10 Compute     2. PROD_FIT
                                  test run.                   Diag.
                                                              2. File Software NVBug to debug and root
                                                              cause with dmesg, diagnostic tool logs
                                                              and NVIDIA Bug report tool log if the
                                                              same error code is seen after the run.

DGX-           script failed to   Script failed to execute.   1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG




                                                                                           bs
xxxxxxxxx007   execute            Software issue.             not tested with the latest L10 Compute     2. PROD_FIT




                                                                                         La
                                                              Diag.
                                                              2. File Software NVBug to debug and root




                                                          03 e
                                                              cause with dmesg, diagnostic tool logs




                                                        5: cl
                                                              and NVIDIA Bug report tool log if the




                                                      :1 ra
                                                              same error code is seen after the run.



                                                    16 al O
DGX-           System setup       A setup error in system.
                                                  28 ti       1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx009   error                                          not tested with the latest L10 Compute     2. PROD_FIT
                                                1- en
                                                              Diag.
                                              -1 fid


                                                              2. File Software NVBug to debug and root
                                                              cause with dmesg, diagnostic tool logs
                                            25 on




                                                              and NVIDIA Bug report tool log if the
                                          20 C




                                                              same error code is seen after the run.
                                         2 IA




DGX-           Inventory item     Mismatch in an inventory    1. Check firmware versions against the     1. REPORT_NV_BUG
                                       71 ID




xxxxxxxxx086   mismatch           (e.g. firmware version)     latest NVIDIA release firmware versions. 2. PROD_FIT
                                     09 NV




                                  check.                      2. Re-test with latest L10 Compute Diag if
                                                              not tested with the latest L10 Compute
                                  11 ah




                                                              Diag.
                                    sn




                                                              3. File Software NVBug to debug and root
                                  Ki




                                                              cause with dmesg, diagnostic tool logs,
                                                              and NVIDIA Bug report tool log if the
                               ik




                                                              same error code is seen after the run.
                            R




DGX-           Infiniband         Infiniband check fails.     1. Re-test with latest L10 Compute Diag if 1. REPORT_NV_BUG
xxxxxxxxx111   property                                       not tested with the latest L10 Compute     2. PROD_FIT
               mismatch                                       Diag.
                                                              2. File Software NVBug to debug and root
                                                              cause with dmesg, diagnostic tool logs
                                                              and NVIDIA Bug report tool log if the
                                                              same error code is seen after the run.

DGX-           Repair action      A repair action failed.     1. Check firmware versions against the     1. REPORT_NV_BUG
xxxxxxxxx184                                                  latest NVIDIA release firmware versions. 2. PROD_FIT
                                                              2. Re-test with latest L10 Compute Diag if
                                                              not tested with the latest L10 Compute
                                                              Diag.
                                                              3. File Software NVBug to debug and root
                                                              cause with dmesg, diagnostic tool logs



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 35
                                                                             Partner Diagnostics Error Codes and Actions


Error Code     Error Message     Explanation                Next Steps                                 Data Center Action Category
                                                            and NVIDIA Bug report tool log if the
                                                            same error code is seen after the run.

DGX-           GPU health check The system might be in a    1. Perform cold reboot i.e., full system   1. RECOVERY.RESET_BM
xxxxxxxxx189   failed           bad state.                  shutdown followed by a manual reboot.      2. REPORT_NV_BUG
                                                            2. Re-test with latest L10 Compute Diag if
                                                            not tested with the latest L10 Compute
                                                            Diag.
                                                            3. File Software NVBug to debug root
                                                            cause with dmesg, diagnostic error logs,
                                                            and NVIDIA Bug report tool log attached if
                                                            the same error code is seen after the run.

DGX-           Environment       Preconditions of running   1. Check firmware versions against the     1. REPORT_NV_BUG
xxxxxxxxx190   check failed      diagnostics are not met    latest NVIDIA release firmware versions. 2. PROD_FIT




                                                                                           bs
                                                            2. Re-test with latest L10 Compute Diag if




                                                                                         La
                                                            not tested with the latest L10 Compute
                                                            Diag.




                                                         03 e
                                                            3. Isolate the failing GPU board(s) with




                                                       5: cl
                                                            reported PCI id and test with GPU FD.




                                                     :1 ra
                                                            4. File Software NVBug to debug root



                                                   16 al O
                                                            cause with dmesg, diagnostic error logs,
                                                            and NVIDIA Bug report tool log attached if
                                                 28 ti
                                               1- en
                                                            the same error code is seen after the run.
                                             -1 fid
                                           25 on




         4.3              L11 Rack Field Diagnostics Error
                                         20 C
                                        2 IA




                          Code to Action Mapping
                                      71 ID
                                    09 NV




         For “L11 Rack Field Diagnostics” related failures, look up the error code in Table 4-4 and
                                 11 ah




         follow the “Next Steps” column to address the failing system. The “Data Center Action
         Category” corresponding to each error code is also included with the corresponding
                                   sn




         action description in the following table.
                                 Ki
                              ik




         The L11 Rack Diag is intended to verify correct assembly of the rack. This includes
                         R




         verifying the NVLink connections between the Compute and Switch Trays and running
         cross-node traffic tests. The Diag also includes pulsed workload and a steady-state
         thermal workload test.

Table 4-4.        L11 Diagnostics Error Code to Action Mapping
Error Code      Error Message      Explanation              Next Steps                                Data Center Action Category
MODS-           MODS exited with MODS received a signal     File Software NVBug to debug root        1. REPORT_NV_BUG
xxxxxxxxx001    a specific status to exit                   cause with dmesg, diagnostic error
                                                            logs, and NVIDIA Bug report tool log
                                                            attached, if the same error code is seen
                                                            after the L11 Rack Diag run.

MODS-           software error     An unexpected software   1. Re-test with latest L11 Rack Diag if   1. REPORT_NV_BUG
xxxxxxxxx002                       error has occurred.      not tested with the latest L11 Rack       2. PROD_FIT


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                          DA-11437-001_v13 | 36
                                                                             Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation               Next Steps                                Data Center Action Category
                                                             Diag.
                                                             2. File Software NVBug to debug and
                                                             root cause with dmesg, diagnostic tool
                                                             logs, and NVIDIA Bug report tool log if
                                                             the same error code is seen after the
                                                             run.

MODS-           Bad command line Bad command line            1. Check Diag command line.             1. REPORT_NV_BUG
xxxxxxxxx005    argument         argument which could be 2. Re-test with latest L11 Rack Diag if     2. PROD_FIT
                                 an issue in the Diag tool not tested with the latest L11 Rack
                                 or a user error in the Diag Diag.
                                 command line.               3. If still unresolved, file Software
                                                             NVBug to debug and root cause with
                                                             dmesg, diagnostic tool logs, and NVIDIA
                                                             Bug report tool log if the same error




                                                                                           bs
                                                             code is seen after the run.




                                                                                         La
MODS-           bad parameter      Software error / bad      1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG




                                                        03 e
xxxxxxxxx008    passed to          parameter passed to       not tested with the latest L11 Rack     2. PROD_FIT




                                                      5: cl
                function           software function.        Diag.




                                                    :1 ra
                                                             2. File Software NVBug to debug and



                                                  16 al O
                                                             root cause with dmesg, diagnostic tool
                                                             logs, and NVIDIA Bug report tool log if
                                                28 ti
                                              1- en
                                                             the same error code is seen after the
                                                             run.
                                            -1 fid


MODS-           Low Bandwidth      Bandwidth measured        1. Check firmware versions against the 1. ISOLATE_TRAY
                                          25 on




xxxxxxxxx014                       during test run is lower  latest NVIDIA release firmware              2. TRIAGE_TRAY
                                        20 C




                                   than thresholds. Could be versions.                                   3. REPORT_NV_BUG
                                       2 IA




                                   an issue with RM driver   2. Re-test with latest L11 Rack Diag if
                                     71 ID




                                   or NVLink connectivity.   not tested with the latest L11 Rack
                                   09 NV




                                                             Diag.
                                                             3. Isolate the failing tray. If it is a
                                11 ah




                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                  sn




                                                             GB200 NVL Service Flow User Guide
                                Ki




                                                             Section 4.3.
                           ik




                                                             4. File Software NVBug to debug and
                         R




                                                             root cause with dmesg, diagnostic tool
                                                             logs, NVOS tech support from master
                                                             NVSwitch and NVIDIA Bug report tool
                                                             log if the same error code is seen after
                                                             the run.

MODS-           C2C bus error      Possible issue in C2C bus 1. If the same error code is seen after  1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx015                                                 the run with latest L11 Rack Diag,
                                                             return the board to the integrator for
                                                             further triage.
                                                             2. If qualified for RMA, RMA the board
                                                             or the networking component. To RMA
                                                             the board, return the board to the
                                                             integrator for further triage. The guide
                                                             for RMA the networking component is
                                                             RMA Checklists and Support Upgrade



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 37
                                                                                Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation                 Next Steps                                Data Center Action Category
                                                                Procedures
                                                                (https://docs.nvidia.com/networking/dis
                                                                play/rmachecklistrev).

MODS-           script failed to    Script failed to execute.   1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG
xxxxxxxxx021    execute                                         not tested with the latest L11 Rack     2. PROD_FIT
                                                                Diag.
                                                                2. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool
                                                                logs, and NVIDIA Bug report tool log if
                                                                the same error code is seen after the
                                                                run.

MODS-           Process signal      MODS receives a signal      1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG
xxxxxxxxx024    received            and stops.                  not tested with the latest L11 Rack     2. PROD_FIT




                                                                                             bs
                                                                Diag.




                                                                                           La
                                                                2. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool




                                                           03 e
                                                                logs, and NVIDIA Bug report tool log if




                                                         5: cl
                                                                the same error code is seen after the




                                                       :1 ra
                                                                run.



                                                     16 al O
MODS-           cannot hook         A software process or
                                                   28 ti        1. Check firmware versions against the 1. PROD_FIT.RESET_RACK
xxxxxxxxx041    interrupt           GPU state is preventing     latest NVIDIA release firmware
                                                 1- en
                                    hooking interrupts.         versions.
                                               -1 fid


                                                                2. Re-test with latest L11 Rack Diag if
                                                                not tested with the latest L11 Rack
                                             25 on




                                                                Diag.
                                           20 C




                                                                3. Isolate the failing tray. If it is a
                                          2 IA




                                                                Compute Tray, test with L10 Compute
                                        71 ID




                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                      09 NV




                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                   11 ah




                                                                4. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool
                                     sn




                                                                logs, and NVIDIA Bug report tool log if
                                   Ki




                                                                the same error code is seen after the
                             ik




                                                                run.
                          R




MODS-           Diag crashed,       Device stopped              1. Re-test with latest L11 Rack Diag if 1. PROD_FIT.RESET_TRAY
xxxxxxxxx043    timeout, or did not responding, crashed, or     not tested with the latest L11 Rack     2. REPORT_NV_BUG
                respond             timed out.                  Diag.
                                                                2. File Software NVBug to debug root
                                                                cause with dmesg, diagnostic error
                                                                logs, and NVIDIA Bug report tool log
                                                                attached if the same error code is seen
                                                                after the run.

MODS-           MODS test failed    Test fails on another       1. Isolate the failing tray. If it is a     1. ISOLATE_TRAY
xxxxxxxxx044    on a remote node    node and lead current       Compute tray, test with L10 Compute 2. TRIAGE_TRAY
                                    node exits. Triage should   Diag. If it is a switch tray, follow NVIDIA 3. REPORT_NV_BUG
                                    focus on the remote         GB200 NVL Service Flow User Guide
                                    node.                       Section 4.3.
                                                                2. File Software NVBug to debug root
                                                                cause with dmesg, diagnostic error


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                              DA-11437-001_v13 | 38
                                                                             Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation               Next Steps                                Data Center Action Category
                                                             logs, and NVIDIA Bug report tool log
                                                             attached if the same error code is seen
                                                             after the run.


MODS-           NVRM invalid                                 1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx060    param struct                                 latest NVIDIA release firmware          2. PROD_FIT.RESET_TRAY
                                                             versions.
                                                             2. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             3. File Software NVBug to debug and
                                                             root cause with dmesg, diagnostic tool
                                                             logs, and NVIDIA Bug report tool log if




                                                                                           bs
                                                             the same error code is seen after the
                                                             run.




                                                                                         La
MODS-           timeout error      Tests failed with SW      1. Check firmware versions against the 1. ISOLATE_TRAY




                                                        03 e
xxxxxxxxx077                       timeout issue and needs   latest NVIDIA release firmware              2. TRIAGE_TRAY




                                                      5: cl
                                                    :1 ra
                                   further investigation.    versions.




                                                  16 al O
                                                             2. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                28 ti
                                              1- en
                                                             3. Isolate the failing tray. If it is a
                                            -1 fid


                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                          25 on




                                                             GB200 NVL Service Flow User Guide
                                        20 C




                                                             Section 4.3.
                                       2 IA




                                                             4. File Software NVBug to debug and
                                     71 ID




                                                             root cause with dmesg, diagnostic tool
                                   09 NV




                                                             logs, and NVIDIA Bug report tool log if
                                                             the same error code is seen after the
                                11 ah




                                                             run. If qualified for RMA, RMA the
                                                             board or the networking component. To
                                  sn




                                                             RMA the board, return the board to the
                                Ki




                                                             integrator for further triage. The RMA
                           ik




                                                             guide for networking components is
                         R




                                                             the RMA Checklists and Support
                                                             Upgrade Procedures document.
                                                             (https://docs.nvidia.com/networkin
                                                             g/display/rmachecklistrev).
MODS-           CRC/Checksum       Computation has           1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx083    miscompare         returned an incorrect     latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                                   answer.                   versions.
                                                             2. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             3. Isolate the failing tray. If it is a
                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                                             GB200 NVL Service Flow User Guide
                                                             Section 4.3.
                                                             4. If the same error code is seen after

         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 39
                                                                                Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation                 Next Steps                              Data Center Action Category
                                                                the run, return the board to the
                                                                integrator for further triage.

MODS-           unexpected device Diag received an              1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx097    interrupts        unexpected interrupt          latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                                  that it considers an          versions.
                                  error.                        2. Re-test with latest L11 Rack Diag if
                                                                not tested with the latest L11 Rack
                                                                Diag.
                                                                3. Isolate the failing tray. If it is a
                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                4. If the same error code is seen after




                                                                                              bs
                                                                the run, return the board to the




                                                                                            La
                                                                integrator for further triage.




                                                        03 e
MODS-           Invalid InfoROM     N/A                         N/A                                     N/A




                                                      5: cl
xxxxxxxxx124




                                                    :1 ra
                                                  16 al O
MODS-           Vbios Certificate   An issue with the VBIOS     1. Check firmware versions against the 1. RECOVERY.RESET_SW
xxxxxxxxx127    Error               certificate.28 ti           latest NVIDIA release firmware          2. PROD_FIT
                                                                versions.
                                              1- en
                                                                2. Re-test with latest L11 Rack Diag if
                                            -1 fid


                                                                not tested with the latest L11 Rack
                                                                Diag.
                                          25 on




                                                                3. File Software NVBug to debug and
                                        20 C




                                                                root cause with dmesg, diagnostic tool
                                       2 IA




                                                                logs, and NVIDIA Bug report tool log if
                                     71 ID




                                                                the same error code is seen after the
                                   09 NV




                                                                run.

MODS-           Acceptable         Check cooling systems        1. Check firmware versions against the 1. ISOLATE_TRAY
                                11 ah




xxxxxxxxx139    temperature limits and engage with NVIDIA.      latest NVIDIA release firmware              2. TRIAGE_TRAY
                                  sn




                exceeded, or the   Failing part qualifies for   versions.
                                Ki




                thermal sensor is RMA only if the problem       2. Re-test with latest L11 Rack Diag if
                broken or          is isolated to NVIDIA        not tested with the latest L11 Rack
                            ik




                miscalibrated      hardware.                    Diag.
                         R




                                                                3. Isolate the failing tray. If it is a
                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                4. If the same error code is seen after
                                                                the run, return the board to the
                                                                integrator for further triage. This
                                                                should be RMA’ed only if the cooling
                                                                solution is part of NVIDIA hardware. If
                                                                qualify, RMA the board or the
                                                                networking component. To RMA the
                                                                board, return the board to the
                                                                integrator for further triage. The RMA
                                                                guide for networking components is



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                            DA-11437-001_v13 | 40
                                                                             Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation               Next Steps                                Data Center Action Category
                                                             the RMA Checklists and Support
                                                             Upgrade Procedures document.
                                                             (https://docs.nvidia.com/networking/dis
                                                             play/rmachecklistrev).

MODS-           NvLink bus error   NVLink is down or NVLink 1. Reseat the tray containing the failing 1. ISOLATE_TRAY
xxxxxxxxx140                       errors occurred during   GPU.                                        2. TRIAGE_TRAY
                                   NVLink testing.          2. Ensure GPU and NVSwitches are
                                                            detected on the system using lspci
                                                            utility.
                                                            3. Re-test with latest L11 Rack Diag if
                                                            not tested with the latest L11 Rack
                                                            Diag.
                                                            4. Isolate the failing tray. If it is a
                                                            Compute Tray, test with L10 Compute




                                                                                           bs
                                                            Diag. If it is a Switch Tray, follow NVIDIA




                                                                                         La
                                                            GB200 NVL Service Flow User Guide
                                                            Section 4.3.




                                                       03 e
                                                     5: cl
                                                            5. If the same error code is seen after




                                                   :1 ra
                                                            the run, return the board to the



                                                 16 al O
                                                            integrator for further triage. If qualify,
                                                            RMA the board or the networking
                                               28 ti
                                                            component. To RMA the board, return
                                             1- en

                                                            the board to the integrator for further
                                           -1 fid


                                                            triage. The RMA guide for networking
                                         25 on



                                                            components is the RMA Checklists and
                                                            Support Upgrade Procedures
                                       20 C




                                                            document.
                                      2 IA




                                                            (https://docs.nvidia.com/networkin
                                    71 ID




                                                            g/display/rmachecklistrev).
                                  09 NV




MODS-           PCI Express bus    PCIe link errors causes   1. Reseat the tray containing the failing 1. ISOLATE_TRAY
xxxxxxxxx143    error              PCIe tests to fail.       GPU.                                        2. TRIAGE_TRAY
                               11 ah




                                                             2. Ensure GPU and NVSwitches are
                                 sn




                                                             detected on the system using lspci
                               Ki




                                                             utility.
                                                             3. Re-test with latest L11 Rack Diag if
                           ik
                         R




                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             4. Isolate the failing tray. If it is a
                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                                             GB200 NVL Service Flow User Guide
                                                             Section 4.3.
                                                             5. If the same error code is seen after
                                                             the run, return the board to the
                                                             integrator for further triage. If qualified
                                                             for RMA, RMA the board or the
                                                             networking component. To RMA the
                                                             board, return the board to the
                                                             integrator for further triage. The RMA
                                                             guide for networking components is
                                                             the RMA Checklists and Support


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 41
                                                                                 Partner Diagnostics Error Codes and Actions


Error Code      Error Message        Explanation                 Next Steps                                Data Center Action Category
                                                                 Upgrade Procedures document.
                                                                 (https://docs.nvidia.com/networking/dis
                                                                 play/rmachecklistrev).

MODS-           CUDA error           One of the CUDA tests is    1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx144                         failing. File Software NV   latest NVIDIA release firmware              2. TRIAGE_TRAY
                                     bug and attach dmesg,       versions.
                                     diagnostic error logs, NV   2. Re-test with latest L11 Rack Diag if
                                     bug report tool log         not tested with the latest L11 Rack
                                     attached to debug root      Diag.
                                     cause.                      3. Isolate the failing tray. If it is a
                                                                 Compute Tray, test with L10 Compute
                                                                 Diag. If it is a Switch Tray, follow NVIDIA
                                                                 GB200 NVL Service Flow User Guide
                                                                 Section 4.3.




                                                                                               bs
                                                                 4. File Software NVBug to debug and




                                                                                             La
                                                                 root cause with dmesg, diagnostic tool
                                                                 logs, and NVIDIA Bug report tool log if




                                                          03 e
                                                        5: cl
                                                                 the same error code is seen after the




                                                      :1 ra
                                                                 run. Start RMA qualification if the same



                                                    16 al O
                                                                 error code is seen after the run.

MODS-           cuInit failed        Use updated version of      1. Check firmware versions against the 1. REPORT_NV_BUG
                                                  28 ti
                                                1- en
xxxxxxxxx145                         diag. Diags later than      latest NVIDIA release firmware          2. PROD_FIT
                                     release 1.1 should no       versions.
                                              -1 fid


                                     longer see this error       2. Re-test with latest L11 Rack Diag if
                                            25 on



                                     code.                       not tested with the latest L11 Rack
                                          20 C




                                     The resolution for this     Diag.
                                         2 IA




                                     error code is the same as   3. File Software NVBug to debug root
                                     that for 688.               cause with dmesg, diagnostic error
                                       71 ID




                                                                 logs, and NVIDIA Bug report tool log
                                     09 NV




                                                                 attached if the same error code is seen
                                                                 after the run.
                                  11 ah




MODS-           Resource in use      Resource is reserved by     1. Perform cold reboot i.e., full system 1. PROD_FIT.RESET_TRAY
                                    sn




xxxxxxxxx160                         another thread or test.     shutdown and manually reboot again.      2. REPORT_NV_BUG
                                  Ki




                                                                 2. File Software NVBug to debug and
                                ik




                                                                 root cause with dmesg, diagnostic tool
                          R




                                                                 logs, and NVIDIA Bug report tool log if
                                                                 the same error code is seen after the
                                                                 reboot.

MODS-           GFW boot             GPU firmware failed to      1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx167    reported a failure   initialize.                 latest NVIDIA release firmware            2. RECOVERY.RESET_BM
                                                                 versions.                                 3. PROD_FIT
                                                                 2. Reseat the tray containing the failing
                                                                 GPU.
                                                                 3. Perform cold reboot i.e., full system
                                                                 shutdown and manually reboot again.
                                                                 4. Ensure GPU and NVSwitches are
                                                                 detected on the system using lspci
                                                                 utility.
                                                                 5. Re-test with latest L11 Rack Diag if
                                                                 not tested with the latest L11 Rack



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                               DA-11437-001_v13 | 42
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                Next Steps                                    Data Center Action Category
                                                              Diag.
                                                              6. Isolate the failing tray. If it is a
                                                              Compute Tray, test with L10 Compute
                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                                              GB200 NVL Service Flow User Guide
                                                              Section 4.3.
                                                              7. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error
                                                              logs, and NVIDIA Bug report tool log
                                                              attached if the same error code is
                                                              seen.

MODS-           bad memory         Computation has            1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx194                       returned an incorrect      latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                                   answer.                    versions.




                                                                                              bs
                                                              2. Re-test with latest L11 Rack Diag if




                                                                                            La
                                                              not tested with the latest L11 Rack
                                                              Diag.




                                                       03 e
                                                     5: cl
                                                              3. Isolate the failing tray. If it is a




                                                   :1 ra
                                                              Compute Tray, test with L10 Compute



                                                 16 al O
                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                                              GB200 NVL Service Flow User Guide
                                               28 ti
                                                              Section 4.3.
                                             1- en

                                                              4. If the same error code is seen after
                                           -1 fid


                                                              the run, return the board to the
                                         25 on



                                                              integrator for further triage.
                                       20 C




MODS-           Could not find     Diag detected inactive     1. Check firmware versions against the (NVLink)
                                      2 IA




xxxxxxxxx216    specified device   NVLinks across GPUs. If    latest NVIDIA release firmware              1. ISOLATE_TRAY
                                   seen on all NVLinks on a   versions.                                   2. TRIAGE_TRAY
                                    71 ID




                                   GPU, could be a GPU        2. Re-test with latest L11 Rack Diag if     3. REPORT_NV_BUG
                                  09 NV




                                   specific problem.          not tested with the latest L11 Rack         (GPU)
                                                              Diag.                                       1. RETURN_FOR_FURTHER_TRIAGE
                               11 ah




                                                              3. If failure seen in NVLink related test
                                 sn




                                                              (NVLink connectivity issue), isolate the
                               Ki




                                                              failing tray. If it is a Compute Tray, test
                                                              with L10 Compute Diag. If it is a Switch
                            ik
                         R




                                                              Tray, follow NVIDIA GB200 NVL Service
                                                              Flow User Guide Section 4.3.
                                                              4. If failure seen in non-NVLink related
                                                              test, it could be a PCIe interface
                                                              problem. Check if GPUs are
                                                              enumerated in PCIe tree via lscpi. Reset
                                                              Compute Tray to confirm if issue
                                                              persists.
                                                              5. Perform cold reboot i.e., full system
                                                              shutdown and manually reboot again. If
                                                              issue persists, isolate the failing GPU
                                                              board(s) with reported PCI ID and test
                                                              with GPU FD.
                                                              6. File Software NVBug to debug and
                                                              root cause with dmesg, diagnostic tool
                                                              logs, and NVIDIA Bug report tool log if


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                                DA-11437-001_v13 | 43
                                                                                Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                 Next Steps                                Data Center Action Category
                                                               the same error code persists, and the
                                                               failure is not isolated to a particular
                                                               tray.

MODS-           pci device not     Failure with PCIe device.   1. Check firmware versions against the 1. RECOVERY.RESET_BM
xxxxxxxxx220    found              Need to isolate the         latest NVIDIA release firmware              2. PROD_FIT
                                   failure to GPU, GB200       versions.
                                   module or tray.             2. Reseat the tray containing the
                                                               failing GPU.
                                                               3. Ensure GPU and NVSwitches are
                                                               detected on the system using lspci
                                                               utility.
                                                               4. Perform cold reboot i.e., full system
                                                               shutdown and manually reboot again.
                                                               5. Re-test with latest L11 Rack Diag if




                                                                                              bs
                                                               not tested with the latest L11 Rack




                                                                                            La
                                                               Diag.




                                                         03 e
                                                               6. Isolate the failing tray. If it is a




                                                       5: cl
                                                               Compute Tray, test with L10 Compute




                                                     :1 ra
                                                               Diag. If it is a Switch Tray, follow NVIDIA



                                                   16 al O
                                                               GB200 NVL Service Flow User Guide
                                                               Section 4.3.
                                                 28 ti
                                                               7. If the same error code is seen after
                                               1- en

                                                               the run, return the board to the
                                             -1 fid


                                                               integrator for further triage.
                                           25 on



MODS-           hardware was not   Something prevented         1. Check firmware versions against the 1. ISOLATE_TRAY
                                         20 C




xxxxxxxxx229    initialized        successful hardware         latest NVIDIA release firmware              2. TRIAGE_TRAY
                                        2 IA




                                   initialization.             versions.
                                                               2. Check all the necessary power cables
                                      71 ID




                                                               are attached to the tray.
                                    09 NV




                                                               3. Re-test with latest L11 Rack Diag if
                                                               not tested with the latest L11 Rack
                                 11 ah




                                                               Diag.
                                   sn




                                                               4. Isolate the failing tray. If it is a
                                 Ki




                                                               Compute Tray, test with L10 Compute
                                                               Diag. If it is a Switch Tray, follow NVIDIA
                            ik
                         R




                                                               GB200 NVL Service Flow User Guide
                                                               Section 4.3.
                                                               5. File Software NVBug to debug and
                                                               root cause with dmesg, diagnostic tool
                                                               logs, and NVIDIA Bug report tool log if
                                                               the same error code is seen after the
                                                               run. If qualified for RMA, RMA the
                                                               board or the networking component. To
                                                               RMA the board, return the board to the
                                                               integrator for further triage. The RMA
                                                               guide for networking components is
                                                               the RMA Checklists and Support
                                                               Upgrade Procedures document.
                                                               (https://docs.nvidia.com/networking/dis
                                                               play/rmachecklistrev).




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 44
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation               Next Steps                               Data Center Action Category
MODS-           bad NVIDIA chip     IST detects bad NVIDIA    1. If the same error code is seen after 1. RETURN_FOR_FURTHER_TRIAGE
xxxxxxxxx233                        chip.                     the run with latest L11 Rack Diag,
                                                              return the board to the integrator for
                                                              further triage. If qualified for RMA,
                                                              RMA the board or the networking
                                                              component. To RMA the board, return
                                                              the board to the integrator for further
                                                              triage. The guide for RMA the
                                                              networking component is RMA
                                                              Checklists and Support Upgrade
                                                              Procedures
                                                              (https://docs.nvidia.com/networking/dis
                                                              play/rmachecklistrev).




                                                                                             bs
MODS-           Unexpected result If running GPU Field         1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx240    from HW           Diagnostic on single GPU, latest NVIDIA release firmware                 2. TRIAGE_TRAY




                                                                                           La
                                  make sure 'skip_nvlink'      versions.




                                                       03 e
                                  parameter is used. If it is, 2. Re-test with latest L11 Rack Diag if




                                                     5: cl
                                  then there is possible       not tested with the latest L11 Rack




                                                   :1 ra
                                  setup issue, confirm         Diag.



                                                 16 al O
                                  NVLink topology is           3. Isolate the failing tray. If it is a
                                  connected as expected        Compute Tray, test with L10 Compute
                                               28 ti
                                  by running:                  Diag. If it is a Switch Tray, follow NVIDIA
                                             1- en

                                  nvidia-smi nvlink -s         GB200 NVL Service Flow User Guide
                                           -1 fid


                                                               Section 4.3.
                                         25 on



                                  If NVLinks are reported      4. File Software NVBug to debug and
                                       20 C




                                  as inactive, debug NVLink root cause with dmesg, diagnostic tool
                                  issue per debug tips         logs, and NVIDIA Bug report tool log if
                                      2 IA




                                  document.                    the same error code is seen after the
                                    71 ID




                                                               run. If qualified for RMA, RMA the
                                  09 NV




                                                               board or the networking component. To
                                                               RMA the board, return the board to the
                               11 ah




                                                               integrator for further triage. The RMA
                                 sn




                                                               guide for networking components is
                               Ki




                                                               the RMA Checklists and Support
                                                               Upgrade Procedures document.
                            ik




                                                               (https://docs.nvidia.com/networking/dis
                         R




                                                               play/rmachecklistrev).

MODS-           Read parameter      Re-test with latest L11   1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx272    differs from        Rack Diagnostics.         latest NVIDIA release firmware          2. TRIAGE_TRAY
                expected                                      versions.
                                                              2. Re-test with latest L11 Rack Diag if
                                                              not tested with the latest L11 Rack
                                                              Diag.
                                                              3. File Software NVBug to debug and
                                                              root cause with dmesg, diagnostic tool
                                                              logs, and NVIDIA Bug report tool log if
                                                              the same error code is seen after the
                                                              run. If qualified for RMA, RMA the
                                                              board or the networking component.
                                                              To RMA the board, return the board to
                                                              the integrator for further triage. The


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                           DA-11437-001_v13 | 45
                                                                              Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                Next Steps                                Data Center Action Category
                                                              RMA guide for networking components
                                                              is the RMA Checklists and Support
                                                              Upgrade Procedures document.
                                                              (https://docs.nvidia.com/networking/dis
                                                              play/rmachecklistrev).

MODS-           HW reports wrong HW failure has occurred. 1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx276    status                                    latest NVIDIA release firmware              2. TRIAGE_TRAY
                                                          versions.
                                                          2. Re-test with latest L11 Rack Diag if
                                                          not tested with the latest L11 Rack
                                                          Diag.
                                                          3. Isolate the failing tray. If it is a
                                                          Compute Tray, test with L10 Compute
                                                          Diag. If it is a Switch Tray, follow NVIDIA




                                                                                           bs
                                                          GB200 NVL Service Flow User Guide




                                                                                         La
                                                          Section 4.3.
                                                          4. If the same error code is seen after




                                                       03 e
                                                     5: cl
                                                          the run, return the board to the




                                                   :1 ra
                                                          integrator for further triage. If qualified



                                                 16 al O
                                                          for RMA, RMA the board or the
                                                          networking component. To RMA the
                                               28 ti
                                                          board, return the board to the
                                             1- en

                                                          integrator for further triage. The RMA
                                           -1 fid


                                                          guide for networking components is
                                         25 on



                                                          the RMA Checklists and Support
                                                          Upgrade Procedures document.
                                       20 C




                                                          (https://docs.nvidia.com/networking/dis
                                      2 IA




                                                          play/rmachecklistrev).
                                    71 ID




MODS-           FSP returned non- If the plain-text log       1. Check firmware versions against the 1. REPORT_NV_BUG
                                  09 NV




xxxxxxxxx301    zero error code   shows MNOC_LOC              latest NVIDIA release firmware           2. PROD_FIT
                                  message, then this error    versions.
                               11 ah




                                  is fixed in GB NVL FW 1.3   2. Re-test with latest L10 Compute
                                 sn




                                  release. Otherwise, this    Diag if not tested with the latest L10
                               Ki




                                  may imply the FW hit an     Compute Diag.
                                  error.                      3. Isolate the failing GPU board(s) with
                           ik
                         R




                                                              reported PCI id and test with GPU FD.
                                                              4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error
                                                              logs, and NVIDIA Bug report tool log
                                                              attached if the same error code is seen
                                                              after the run.

MODS-           NvLink discovered NVLink topology does not 1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx311    topology does not match expected           latest NVIDIA release firmware            2. TRIAGE_TRAY
                match required    topology.                versions.
                topology                                   2. Ensure GPU and NVSwitches are
                                                           detected on the system using lspci
                                                           utility. Ensure the topology file is
                                                           correct based on the user guide.
                                                           3. Perform cold reboot i.e., full system
                                                           shutdown and manually reboot again.
                                                           4. Reseat the tray containing the failing


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                            DA-11437-001_v13 | 46
                                                                              Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation              Next Steps                                    Data Center Action Category
                                                             GPU if reboot did not resolve the issue.
                                                             5. Re-install NVIDIA release driver if
                                                             rebooting and reseating did not resolve
                                                             the issue.
                                                             6. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             7. Isolate the failing tray. If it is a
                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                                             GB200 NVL Service Flow User Guide
                                                             Section 4.3.
                                                             8. File Software NVBug to debug and
                                                             root cause with dmesg, diagnostic tool




                                                                                             bs
                                                             logs, and NVIDIA Bug report tool log if




                                                                                           La
                                                             the same error code is seen after the
                                                             run. If qualified for RMA, RMA the




                                                       03 e
                                                             board or the networking component. To




                                                     5: cl
                                                   :1 ra
                                                             RMA the board, return the board to the




                                                 16 al O
                                                             integrator for further triage. The RMA
                                                             guide for networking components is
                                                             the RMA Checklists and Support
                                               28 ti
                                             1- en
                                                             Upgrade Procedures document.
                                                             (https://docs.nvidia.com/networking/dis
                                           -1 fid


                                                             play/rmachecklistrev).
                                         25 on




MODS-           ECC detected a      N/A                      N/A                                           N/A
                                       20 C




xxxxxxxxx316    correctable error
                                      2 IA




                in FB, threshold
                                    71 ID




                exceeded
                                  09 NV




MODS-           ECC detected an     Uncorrectable error has 1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx317    uncorrectable       occurred, reset for row  latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                               11 ah




                error in FB         remapping to take place. versions.
                                 sn




                                                             2. Power cycle to trigger row
                               Ki




                                                             remapping.
                                                             3. Re-test with latest L11 Rack Diag if
                            ik
                         R




                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             4. Isolate the failing tray. If it is a
                                                             Compute Tray, test with L10 Compute
                                                             Diag. If it is a Switch Tray, follow NVIDIA
                                                             GB200 NVL Service Flow User Guide
                                                             Section 4.3.
                                                             5. If the same error code is seen after
                                                             the run, return the board to the
                                                             integrator for further triage.

MODS-           ECC detected a      N/A                      N/A                                           N/A
xxxxxxxxx318    correctable error
                in L2, threshold
                exceeded




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                               DA-11437-001_v13 | 47
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation                 Next Steps                            Data Center Action Category
MODS-           ECC detected an     An uncorrectable error      1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx319    uncorrectable       has occurred in the L2      latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                error in L2         cache, start RMA            versions.
                                    qualification for the       2. Re-test with latest L11 Rack Diag if
                                    GB200 module including      not tested with the latest L11 Rack
                                    the failing GPU.            Diag.
                                                                3. Isolate the failing tray. If it is a
                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                4. If the same error code is seen after
                                                                the run, return the board to the
                                                                integrator for further triage.




                                                                                            bs
MODS-           ECC detected an     N/A                         N/A                                   N/A




                                                                                          La
xxxxxx171321    uncorrectable




                                                       03 e
                error in SM




                                                     5: cl
                                                   :1 ra
MODS-           ECC detected a      Rate of correctable       1. Check firmware versions against the 1. ISOLATE_TRAY




                                                 16 al O
xxxxxxxxx320    correctable error   errors in SM have         latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                in SM, threshold    exceeded threshold, start versions.
                exceeded            RMA qualification for the 2. Re-test with latest L11 Rack Diag if
                                               28 ti
                                             1- en
                                    GB200 module including not tested with the latest L11 Rack
                                           -1 fid


                                    the failing GPU.          Diag.
                                                              3. Isolate the failing tray. If it is a
                                         25 on




                                                              Compute Tray, test with L10 Compute
                                       20 C




                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                      2 IA




                                                              GB200 NVL Service Flow User Guide
                                    71 ID




                                                              Section 4.3.
                                  09 NV




                                                              4. If the same error code is seen after
                                                              the run, return the board to the
                               11 ah




                                                              integrator for further triage.
                                 sn




MODS-           ECC detected an     An uncorrectable error    1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx321    uncorrectable       has occurred in the SM    latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                               Ki




                error in SM         during testing, start RMA versions.
                            ik




                                    qualification for the     2. Re-test with latest L11 Rack Diag if
                         R




                                    GB200 module including not tested with the latest L11 Rack
                                    the failing GPU.          Diag.
                                                              3. Isolate the failing tray. If it is a
                                                              Compute Tray, test with L10 Compute
                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                                              GB200 NVL Service Flow User Guide
                                                              Section 4.3.
                                                              4. If the same error code is seen after
                                                              the run, return the board to the
                                                              integrator for further triage.

MODS-           Cannot pulse fast   GPU is taking too long to   1. Reset the tray and retest.           1. RECOVERY.RESET_BM
xxxxxxxx332     enough to           either:                     2. File Software NVBug to debug root    2. REPORT_NV_BUG
                accurately make a   (a) Complete the GEMM       cause with dmesg, diagnostic error log, 3. PROD_FIT
                waveform            workload, or                and NVIDIA Bug report tool log
                                    (b) Report that it


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                          DA-11437-001_v13 | 48
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                 Next Steps                                 Data Center Action Category
                                   completed the GEMM          attached if the same error is seen after
                                   workload.                   the GPU FD run.

MODS-           Buffer mismatch    Start RMA qualification    1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx341                       for the GB200 module       latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                                   including the failing GPU. versions.
                                                              2. Re-test with latest L11 Rack Diag if
                                                              not tested with the latest L11 Rack
                                                              Diag.
                                                              3. Isolate the failing tray. If it is a
                                                              Compute Tray, test with L10 Compute
                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                                              GB200 NVL Service Flow User Guide
                                                              Section 4.3.
                                                              4. If the same error code is seen after




                                                                                             bs
                                                              the run, return the board to the




                                                                                           La
                                                              integrator for further triage.




                                                        03 e
MODS-           memory not         Memory not strapped         1. Check firmware versions against the 1. ISOLATE_TRAY




                                                      5: cl
xxxxxxxxx351    strapped correctly correctly.                  latest NVIDIA release firmware              2. TRIAGE_TRAY




                                                    :1 ra
                                                               versions.



                                                  16 al O
                                                               2. Re-test with latest L11 Rack Diag if
                                                               not tested with the latest L11 Rack
                                                28 ti
                                              1- en
                                                               Diag.
                                                               3. Isolate the failing tray. If it is a
                                            -1 fid


                                                               Compute Tray, test with L10 Compute
                                          25 on



                                                               Diag. If it is a Switch Tray, follow NVIDIA
                                        20 C




                                                               GB200 NVL Service Flow User Guide
                                       2 IA




                                                               Section 4.3.
                                                               4. File Software NVBug to debug and
                                     71 ID




                                                               root cause with dmesg, diagnostic tool
                                   09 NV




                                                               logs, and NVIDIA Bug report tool log if
                                                               the same error code is seen after the
                                11 ah




                                                               run.
                                  sn




MODS-           Row remapping      A row remapping failure     1. Check firmware versions against the 1. ISOLATE_TRAY
                                Ki




xxxxxxxxx363    failed             has occurred, start RMA     latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                           ik




                                   qualification.              versions.
                         R




                                                               2. Re-test with latest L11 Rack Diag if
                                                               not tested with the latest L11 Rack
                                                               Diag.
                                                               3. Isolate the failing tray. If it is a
                                                               Compute Tray, test with L10 Compute
                                                               Diag. If it is a Switch Tray, follow NVIDIA
                                                               GB200 NVL Service Flow User Guide
                                                               Section 4.3.
                                                               4. If the same error code is seen after
                                                               the run, return the board to the
                                                               integrator for further triage.

MODS-           NVRM generic       Ensure NV driver is fully   1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx539    falcon error       unloaded, and other         latest NVIDIA release firmware         2. PROD_FIT.RESET_TRAY
                                   internal processes don't    versions.
                                   try to load driver back     2. Ensure GPU and NVSwitches are



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                              DA-11437-001_v13 | 49
                                                                                 Partner Diagnostics Error Codes and Actions


Error Code      Error Message         Explanation               Next Steps                                    Data Center Action Category
                                      while running GPU Field   detected on the system using lspci
                                      Diagnostic.               utility.
                                                                3. Perform cold reboot i.e., full system
                                                                shutdown and manually reboot again.
                                                                4. Re-test with latest L11 Rack Diag if
                                                                not tested with the latest L11 Rack
                                                                Diag.
                                                                5. Isolate the failing tray. If it is a
                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                6. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool




                                                                                                bs
                                                                logs, and NVIDIA Bug report tool log if




                                                                                              La
                                                                the same error code is seen after the
                                                                run.




                                                        03 e
                                                      5: cl
MODS-           NVRM Detected         Memory issue detected     1. Check firmware versions against the 1. ISOLATE_TRAY




                                                    :1 ra
xxxxxxxxx541    memory error          by NVRM.                  latest NVIDIA release firmware              2. TRIAGE_TRAY



                                                  16 al O
                                                                versions.
                                                                2. Re-test with latest L11 Rack Diag if
                                                28 ti
                                                                not tested with the latest L11 Rack
                                              1- en

                                                                Diag.
                                            -1 fid


                                                                3. Isolate the failing tray. If it is a
                                          25 on



                                                                Compute Tray, test with L10 Compute
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                        20 C




                                                                GB200 NVL Service Flow User Guide
                                       2 IA




                                                                Section 4.3.
                                     71 ID




                                                                4. File Software NVBug to debug and
                                   09 NV




                                                                root cause with dmesg, diagnostic tool
                                                                logs, and NVIDIA Bug report tool log if
                                11 ah




                                                                the same error code is seen after the
                                  sn




                                                                run. If qualified for RMA, RMA the
                                                                board or the networking component. To
                                Ki




                                                                RMA the board, return the board to the
                            ik




                                                                integrator for further triage. The RMA
                         R




                                                                guide for networking components is
                                                                the RMA Checklists and Support
                                                                Upgrade Procedures document.
                                                                (https://docs.nvidia.com/networking/dis
                                                                play/rmachecklistrev).

MODS-           NVRM VBIOS            It could be due to a varied 1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx542    invalid or rejected   NVRM VBIOS validation       latest NVIDIA release firmware              2. PROD_FIT.RESET_TRAY
                                      failure.                    versions.
                                                                  2. Re-test with latest L11 Rack Diag if
                                                                  not tested with the latest L11 Rack
                                                                  Diag.
                                                                  3. Isolate the failing tray. If it is a
                                                                  Compute Tray, test with L10 Compute
                                                                  Diag. If it is a Switch Tray, follow NVIDIA
                                                                  GB200 NVL Service Flow User Guide


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                                  DA-11437-001_v13 | 50
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                 Next Steps                                Data Center Action Category
                                                               Section 4.3.
                                                               4. File Software NVBug to debug and
                                                               root cause with dmesg, diagnostic tool
                                                               logs, and NVIDIA Bug report tool log if
                                                               the same error code is seen after the
                                                               run.

MODS-           gnu stress test    N/A                         N/A                                       N/A
xxxxxxxxx582    found pixel
                miscompares

MODS-           NVRM not           Need to first check         1. Check firmware versions against the (NVLink)
xxxxxxxxx597    supported          whether this error code     latest NVIDIA release firmware              1. ISOLATE_TRAY
                                   happens in an NVLink-       versions.                                   2. TRIAGE_TRAY
                                   related test or a non-      2. Re-test with latest L11 Rack Diag if     3. REPORT_NV_BUG




                                                                                             bs
                                   NVLink related test.        not tested with the latest L11 Rack         (GPU)




                                                                                           La
                                   Need to check FW            Diag.                                       1. RETURN_FOR_FURTHER_TRIAGE
                                   version.                    3. If failure seen in NVLink related test




                                                          03 e
                                                               (NVLink connectivity issue), isolate the




                                                        5: cl
                                                               failing tray. If it is a Compute Tray, test




                                                      :1 ra
                                                               with L11 Compute Diag. If it is a Switch



                                                    16 al O
                                                               Tray, follow NVIDIA GB200 NVL Service
                                                               Flow User Guide Section 4.3.
                                                  28 ti
                                                1- en
                                                               4. If failure seen in non-NVLink related
                                                               test, it could be a PCIe interface
                                              -1 fid


                                                               problem. Check if GPUs are
                                            25 on



                                                               enumerated in PCIe tree via lscpi. Reset
                                          20 C




                                                               Compute Tray to confirm if issue
                                         2 IA




                                                               persists. If issue persists, isolate the
                                                               failing GPU board(s) with reported PCI
                                       71 ID




                                                               ID and test with GPU FD.
                                     09 NV




                                                               5. File Software NVBug to debug root
                                                               cause with dmesg, diagnostic error
                                  11 ah




                                                               logs, and NVIDIA Bug report tool log
                                    sn




                                                               attached if the same error code is seen
                                  Ki




                                                               after the run.
                            ik




MODS-           fan does not seem Check cooling systems        1. Check firmware versions against the 1. ISOLATE_TRAY
                         R




xxxxxxxxx599    to cool the chip  and engage with NVIDIA.      latest NVIDIA release firmware          2. TRIAGE_TRAY
                                  Failing part qualifies for   versions.
                                  RMA only if the problem      2. Re-test with latest L11 Rack Diag if
                                  is isolated to NVIDIA        not tested with the latest L11 Rack
                                  hardware.                    Diag.
                                                               3. Start RMA qualification if the same
                                                               error code is seen after the run and
                                                               only if the cooling solution is part of
                                                               NVIDIA hardware. If qualified for RMA,
                                                               RMA the board or the networking
                                                               component. To RMA the board, return
                                                               the board to the integrator for further
                                                               triage. The RMA guide for networking
                                                               components is the RMA Checklists and
                                                               Support Upgrade Procedures
                                                               document.


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 51
                                                                              Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation               Next Steps                                Data Center Action Category
                                                              (https://docs.nvidia.com/networking/dis
                                                              play/rmachecklistrev).

MODS-           NVRM Timeout        Driver timeout possibly   1. Perform cold reboot i.e., full system 1. RECOVERY.RESET_BM
xxxxxxxxx603                        because system is in a    shutdown followed by a manual reboot. 2. REPORT_NV_BUG
                                    bad state.                2. Re-test with latest L11 Rack Diag if
                                                              not already tested with the latest L11
                                                              Rack Diag.
                                                              3. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error
                                                              logs, and NVIDIA Bug report tool log
                                                              attached if the same error code is seen
                                                              after the run.

MODS-           Interrupt request   A problem with the        1. Check firmware versions against the 1. PROD_FIT.RESET_RACK




                                                                                           bs
xxxxxxxxx609    mechanism does      interrupt request         latest NVIDIA release firmware




                                                                                         La
                not work            mechanism.                versions.
                                                              2. Re-test with latest L11 Rack Diag if




                                                       03 e
                                                              not tested with the latest L11 Rack




                                                     5: cl
                                                              Diag.




                                                   :1 ra
                                                              3. Isolate the failing tray. If it is a



                                                 16 al O
                                                              Compute Tray, test with L10 Compute
                                                              Diag. If it is a Switch Tray, follow NVIDIA
                                               28 ti
                                             1- en
                                                              GB200 NVL Service Flow User Guide
                                                              Section 4.3.
                                           -1 fid


                                                              4. File Software NVBug to debug and
                                         25 on



                                                              root cause with dmesg, diagnostic tool
                                       20 C




                                                              logs, and NVIDIA Bug report tool log if
                                      2 IA




                                                              the same error code is seen after the
                                                              run.
                                    71 ID
                                  09 NV




MODS-           Extra golden code One of the GPU Field     1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx614    miscompare        Diagnostic tests failed  latest NVIDIA release firmware              2. RETURN_FOR_FURTHER_TRIAGE
                               11 ah




                                  the consistency check on versions.
                                  expected values.         2. Re-test with latest L11 Rack Diag if
                                 sn




                                                           not tested with the latest L11 Rack
                               Ki




                                                           Diag.
                           ik




                                                           3. Isolate the failing tray. If it is a
                         R




                                                           Compute Tray, test with L10 Compute
                                                           Diag. If it is a Switch Tray, follow NVIDIA
                                                           GB200 NVL Service Flow User Guide
                                                           Section 4.3.
                                                           4. If the same error code is seen after
                                                           the run, return the board to the
                                                           integrator for further triage.

MODS-           NVRM invalid        Usually indicative of a   1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx665    parameter           SW/FW issue. Does not     latest NVIDIA release firmware          2. PROD_FIT
                                    point to a system HW      versions.
                                    problem.                  2. Re-test with latest L11 Rack Diag if
                                                              not already tested with the latest L11
                                                              Rack Diag.
                                                              4. File Software NVBug to debug root
                                                              cause with dmesg, diagnostic error



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                            DA-11437-001_v13 | 52
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation                 Next Steps                                Data Center Action Category
                                                               logs, and NVIDIA Bug report tool log
                                                               attached if the same error code is seen
                                                               after the run.

MODS-           NVRM invalid       Invalid argument passed 1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx679    argument           to NVRM. If error is seen latest NVIDIA release firmware          2. PROD_FIT.RESET_TRAY
                                   after running InfoROM     versions.
                                   recovery tool, file       2. Run InfoROM recovery tool. For
                                   Software NV bug and       Blackwell generation of products,
                                   attach dmesg, diagnostic please refer to InfoROM Cleansing for
                                   error logs, NV bug report RMA - User Guide (NVOnline: 1120261).
                                   tool log attached to      3. Re-test with latest L11 Rack Diag if
                                   debug root cause.         not tested with the latest L11 Rack
                                                             Diag.
                                                             4. File Software NVBug to debug and




                                                                                             bs
                                                             root cause with dmesg, diagnostic tool




                                                                                           La
                                                             logs, and NVIDIA Bug report tool log if




                                                          03 e
                                                             the same error code is seen after the




                                                        5: cl
                                                             run.




                                                      :1 ra
MODS-           NVRM invalid data GPU driver returns invalid 1. If the same error code is seen after a 1. RETURN_FOR_FURTHER_TRIAGE



                                                    16 al O
xxxxxxxxx682                      data.                      rerun with latest L11 Rack Diag, return
                                                             the board to the integrator for further
                                                  28 ti
                                                1- en
                                                             triage.
                                              -1 fid


MODS-           NVRM Invalid       NVRM reports an invalid     1. Check firmware versions against the (NVLink)
xxxxxxxxx688    State or Config    state or configuration of   latest NVIDIA release firmware              1. ISOLATE_TRAY
                                            25 on




                                   an NVLink. One or more      versions.                                   2. TRIAGE_TRAY
                                          20 C




                                   NVLinks is in an invalid    2. Check GFM health on master               3. REPORT_NV_BUG
                                         2 IA




                                   state. Could be an issue    NVSwitch by running ‘nv show cluster (GPU)
                                       71 ID




                                   with the Global Fabric      apps running’ NVOS CLI command.             1. RETURN_FOR_
                                     09 NV




                                   Manager on master           3. Re-test with latest L11 Rack Diag if     FURTHER_TRIAGE
                                   NVSwitch.                   not tested with the latest L11 Rack
                                  11 ah




                                                               Diag.
                                                               4. If failure seen in NVLink related test
                                    sn




                                                               (NVLink connectivity issue), isolate the
                                  Ki




                                                               failing tray. If it is a Compute Tray, test
                           ik




                                                               with L10 Compute Diag. If it is a Switch
                         R




                                                               Tray, follow NVIDIA GB200 NVL Service
                                                               Flow User Guide Section 4.3.
                                                               5. If failure seen in non-NVLink related
                                                               test, it could be a PCIe interface
                                                               problem. Check if GPUs are
                                                               enumerated in PCIe tree via lscpi. Reset
                                                               Compute Tray to confirm if issue
                                                               persists.
                                                               6. Perform cold reboot i.e., full system
                                                               shutdown and manually reboot again. If
                                                               issue persists, isolate the failing GPU
                                                               board(s) with reported PCI ID and test
                                                               with GPU FD.
                                                               7. File Software NVBug to debug and
                                                               root cause with dmesg, diagnostic tool
                                                               logs, and NVIDIA Bug report tool log if


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                             DA-11437-001_v13 | 53
                                                                               Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation               Next Steps                                Data Center Action Category
                                                              the same error code persists, and the
                                                              failure is not isolated to a particular
                                                              tray.

MODS-           Failed to perform   Hot reset did not work.   1. Check firmware versions against the 1. RECOVERY.RESET_BM
xxxxxxxxx735    hot reset                                     latest NVIDIA release firmware              2. PROD_FIT
                                                              versions.
                                                              2. Perform hot reboot, i.e. reboot the
                                                              system to restore PCI config space.
                                                              3. Perform cold reboot i.e., full system
                                                              shutdown and manually reboot again if
                                                              hot reboot does not resolve the issue.
                                                              4. Re-test with latest L11 Rack Diag if
                                                              not tested with the latest L11 Rack
                                                              Diag.




                                                                                             bs
                                                              5. Isolate the failing tray. If it is a




                                                                                           La
                                                              Compute Tray, test with L10 Compute
                                                              Diag. If it is a Switch Tray, follow NVIDIA




                                                       03 e
                                                     5: cl
                                                              GB200 NVL Service Flow User Guide




                                                   :1 ra
                                                              Section 4.3.



                                                 16 al O
                                                              6. File Software NVBug to debug and
                                                              root cause with dmesg, diagnostic tool
                                               28 ti
                                                              logs, and NVIDIA Bug report tool log if
                                             1- en

                                                              the same error code is seen after the
                                           -1 fid


                                                              run.
                                         25 on



MODS-           Voltage value out   N/A                       N/A                                       N/A
                                       20 C




xxxxxxxxx779    of range
                                      2 IA




MODS-           Mods detected an A software error has         1. Check firmware versions against the 1. REPORT_NV_BUG
                                    71 ID




xxxxxxxxx818    assertion failure occurred.                   latest NVIDIA release firmware              2. PROD_FIT
                                  09 NV




                                                              versions.
                                                              2. Re-test with latest L11 Rack Diag if
                               11 ah




                                                              not tested with the latest L11 Rack
                                                              Diag.
                                 sn




                                                              3. Isolate the failing tray. If it is a
                               Ki




                                                              Compute Tray, test with L10 Compute
                            ik




                                                              Diag. If it is a Switch Tray, follow NVIDIA
                         R




                                                              GB200 NVL Service Flow User Guide
                                                              Section 4.3.
                                                              4. File Software NVBug to debug and
                                                              root cause with dmesg, diagnostic tool
                                                              logs, and NVIDIA Bug report tool log if
                                                              the same error code is seen after the
                                                              run.

MODS-           TLW Error           An error in the TLW       1. Check firmware versions against the 1. ISOLATE_TRAY
xxxxxxxxx936                        (Transaction Layer        latest NVIDIA release firmware          2. TRIAGE_TRAY
                                    Wrapper) module on an     versions.                               3. REPORT_NV_BUG
                                    NVLink port.              2. Re-test with latest L11 Rack Diag if
                                                              not tested with the latest L10 Compute
                                                              Diag.
                                                              3. Isolate the failing tray. If it is a
                                                              Compute Tray, test with L10 Compute



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                            DA-11437-001_v13 | 54
                                                                                 Partner Diagnostics Error Codes and Actions


Error Code      Error Message       Explanation                 Next Steps                                    Data Center Action Category
                                                                Diag. If it is a Switch Tray, follow NVIDIA
                                                                GB200 NVL Service Flow User Guide
                                                                Section 4.3.
                                                                4. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool
                                                                logs, NVOS tech support (for Switch
                                                                Tray) and NVIDIA Bug report tool log if
                                                                the same error code is seen after the
                                                                run.

DGX-            MODS exited with Software issue                 1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG
xxxxxxxxx001    status 1                                        not tested with the latest L11 Compute 2. PROD_FIT
                                                                Diag.
                                                                2. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool




                                                                                                bs
                                                                logs, and NVIDIA Bug report tool log if




                                                                                              La
                                                                the same error code is seen after the
                                                                run.




                                                           03 e
                                                         5: cl
DGX-            timeout             An unexpected watchdog 1. Re-test with latest L11 Rack Diag if 1. PROD_FIT.RESET_TRAY




                                                       :1 ra
xxxxxxxxx002                        timeout during the Diag not tested with the latest L11 Compute 2. REPORT_NV_BUG



                                                     16 al O
                                    test run.               Diag.
                                                            2. File Software NVBug to debug and
                                                   28 ti
                                                 1- en
                                                            root cause with dmesg, diagnostic tool
                                                            logs and NVIDIA Bug report tool log if
                                               -1 fid


                                                            the same error code is seen after the
                                             25 on



                                                            run.
                                           20 C




DGX-            script failed to    Script failed to execute.   1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG
                                          2 IA




xxxxxxxxx007    execute             Software issue.             not tested with the latest L11 Compute 2. PROD_FIT
                                        71 ID




                                                                Diag.
                                      09 NV




                                                                2. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool
                                   11 ah




                                                                logs and NVIDIA Bug report tool log if
                                                                the same error code is seen after the
                                     sn




                                                                run.
                                   Ki




DGX-            System setup        A setup error in system.    1. Re-test with latest L11 Rack Diag if 1. REPORT_NV_BUG
                             ik




xxxxxxxxx009    error                                           not tested with the latest L11 Rack     2. PROD_FIT
                          R




                                                                Diag.
                                                                2. File Software NVBug to debug and
                                                                root cause with dmesg, diagnostic tool
                                                                logs and NVIDIA Bug report tool log if
                                                                the same error code is seen after the
                                                                run.

DGX-            Inventory item      Mismatch in an inventory 1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx086    mismatch            (e.g. firmware version)  latest NVIDIA release firmware          2. PROD_FIT
                                    check.                   versions.
                                                             2. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             3. File Software NVBug to debug and
                                                             root cause with dmesg, diagnostic tool
                                                             logs, and NVIDIA Bug report tool log if


         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                                  DA-11437-001_v13 | 55
                                                                             Partner Diagnostics Error Codes and Actions


Error Code      Error Message      Explanation               Next Steps                              Data Center Action Category
                                                             the same error code is seen after the
                                                             run.

DGX-            Repair action      A repair action failed.   1. Check firmware versions against the 1. REPORT_NV_BUG
xxxxxxxxx184                                                 latest NVIDIA release firmware          2. PROD_FIT
                                                             versions.
                                                             2. Re-test with latest L11 Rack Diag if
                                                             not tested with the latest L11 Rack
                                                             Diag.
                                                             3. File Software NVBug to debug and
                                                             root cause with dmesg, diagnostic tool
                                                             logs and NVIDIA Bug report tool log if
                                                             the same error code is seen after the
                                                             run.




                                                                                           bs
DGX-            GPU health check   The system might be in a 1. Perform cold reboot i.e., full system 1. RECOVERY.RESET_BM




                                                                                         La
xxxxxxxxx189    failed             bad state.               shutdown followed by a manual reboot. 2. REPORT_NV_BUG
                                                            2. Re-test with latest L11 Rack Diag if




                                                        03 e
                                                            not tested with the latest L11 Compute




                                                      5: cl
                                                            Diag.




                                                    :1 ra
                                                            3. File Software NVBug to debug root



                                                  16 al O
                                                            cause with dmesg, diagnostic error
                                                            logs, and NVIDIA Bug report tool log
                                                28 ti
                                              1- en
                                                            attached if the same error code is seen
                                                            after the run.
                                            -1 fid


DGX-            Environment        Preconditions of running 1. Check firmware versions against the 1. ISOLATE_TRAY
                                          25 on




xxxxxxxxx190    check failed       diagnostics are not met latest NVIDIA release firmware               2. TRIAGE_TRAY
                                        20 C




                                                            versions.                                   3. REPORT_NV_BUG
                                       2 IA




                                                            2. Re-test with latest L11 Rack Diag if
                                     71 ID




                                                            not tested with the latest L11 Rack
                                   09 NV




                                                            Diag.
                                                            3. Isolate the failing tray. If it is a
                                11 ah




                                                            compute tray, test with L10 Compute
                                                            Diag. If it is a switch tray, follow NVIDIA
                                  sn




                                                            GB200 NVL Service Flow User Guide
                                Ki




                                                            Section 4.3.
                           ik




                                                            4. File Software NVBug to debug root
                         R




                                                            cause with dmesg, diagnostic error
                                                            logs, and NVIDIA Bug report tool log
                                                            attached if the same error code is seen
                                                            after the run.




         4.4              HGX Baseboard Diagnostics Error
                          Code to Action Mapping
         For NVIDIA HGX baseboard related failures, look up the error code in Table 4-5 and
         follow the ‘Next Steps’ column to address the failing system.




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                         DA-11437-001_v13 | 56
                                                                    Partner Diagnostics Error Codes and Actions


Table 4-5.        HGX Baseboard Diagnostics Error Code to Action Mapping
 Error Code              Test             Error Message             Explanation            Next Step
                                          'VBIOS_version': not      GPU property           Refer to “Missing GPU
 DGX-000000000110        inventory
                                          found. expected 'Y'       mismatch               Property” section.
                                          'VBIOS_version': found    GPU property
 DGX-000000000110        inventory                                                         Update GPU firmware.
                                          'Y' expected 'Z'          mismatch
                                          'VendorID': not found.    GPU property           Refer to “Missing GPU
 DGX-000000000110        inventory
                                          expected 'Y'              mismatch               Property” section.
                                          'VendorID': found 'Y'     GPU property           Refer to “Missing GPU”
 DGX-000000000110        inventory
                                          expected 'Z'              mismatch               section.
                                          'DeviceID': not found.    GPU property           Refer to “Missing GPU
 DGX-000000000110        inventory
                                          expected 'Y'              mismatch               Property” section.
                                          'DeviceID': found 'Y'     GPU property           Refer to “Missing GPU”




                                                                                bs
 DGX-000000000110        inventory
                                          expected 'Z'              mismatch               section.




                                                                              La
                                          'SSVendorID': not         GPU property           Refer to “Missing GPU
 DGX-000000000110        inventory




                                                  03 e
                                          found. expected 'Y'       mismatch               Property” section.




                                                5: cl
                                              :1 ra
                                          'SSVendorID': found 'Y'   GPU property
 DGX-000000000110        inventory                                                         Update GPU firmware.


                                            16 al O
                                          expected 'Z'              mismatch
                                          'SSDeviceID': not         GPU property           Refer to “Missing GPU
 DGX-000000000110        inventory
                                          28 ti
                                          found. expected 'Y'       mismatch               Property” section.
                                        1- en

                                          'SSDeviceID': found 'Y'   GPU property
                                      -1 fid


 DGX-000000000110        inventory                                                         Update GPU firmware.
                                          expected 'Z'              mismatch
                                    25 on




                                          'X': not found.           GPU property           Refer to “Missing GPU
                                  20 C




 DGX-000000000110        inventory
                                          expected 'Y'              mismatch               Property” section.
                                 2 IA




                                          'X': found 'Y' expected   GPU property
                               71 ID




 DGX-000000000110        inventory                                                         Update GPU firmware.
                                          'Z'                       mismatch
                             09 NV




                                                                                           Refer to “Missing
                                          'VBIOS_version': not      NVSwitch property
 DGX-000000000108        inventory                                                         NVSwitch Property”
                          11 ah




                                          found. expected 'Y'       mismatch
                                                                                           section.
                            sn




                                          'VBIOS_version': found    NVSwitch property      Update NVSwitch
                          Ki




 DGX-000000000108        inventory
                                          'Y' expected 'Z'          mismatch               firmware.
                      ik




                                                                                           Refer to “Missing
                    R




                                          'VendorID': not found.    NVSwitch property
 DGX-000000000108        inventory                                                         NVSwitch Property”
                                          expected 'Y'              mismatch
                                                                                           section.
                                          'VendorID': found 'Y'     NVSwitch property      Refer to “Missing
 DGX-000000000108        inventory
                                          expected 'Z'              mismatch               NVSwitch” section.
                                                                                           Refer to “Missing
                                          'DeviceID': not found.    NVSwitch property
 DGX-000000000108        inventory                                                         NVSwitch Property”
                                          expected 'Y'              mismatch
                                                                                           section.
                                          'DeviceID': found 'Y'     NVSwitch property      Refer to “Missing
 DGX-000000000108        inventory
                                          expected 'Z'              mismatch               NVSwitch” section.
                                                                                           Refer to “Missing
                                          'SSVendorID': not         NVSwitch property
 DGX-000000000108        inventory                                                         NVSwitch Property”
                                          found. expected 'Y'       mismatch
                                                                                           section.




    PRELIMINARY INFORMATION
    NVIDIA CONFIDENTIAL
    Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 57
                                                                   Partner Diagnostics Error Codes and Actions


Error Code              Test             Error Message             Explanation               Next Step
                                         'SSVendorID': found 'Y'   NVSwitch property         Update NVSwitch
DGX-000000000108        inventory
                                         expected 'Z'              mismatch                  firmware
                                                                                             Refer to “Missing
                                         'SSDeviceID': not         NVSwitch property
DGX-000000000108        inventory                                                            NVSwitch Property”
                                         found. expected 'Y'       mismatch
                                                                                             section.
                                         'SSDeviceID': found 'Y'   NVSwitch property         Update NVSwitch
DGX-000000000108        inventory
                                         expected 'Z'              mismatch                  firmware.
                                                                                             Refer to “Missing
                                         'X': not found.           NVSwitch property
DGX-000000000108        inventory                                                            NVSwitch Property”
                                         expected 'Y'              mismatch
                                                                                             section.
                                         'X': found 'Y' expected   NVSwitch property         Update NVSwitch
DGX-000000000108        inventory
                                         'Z'                       mismatch                  firmware.




                                                                                bs
                                                                   An unexpected
                                         'GPUNum': found 'Y'                                 Refer to “Missing GPU”




                                                                              La
DGX-000000000086        inventory                                  number of GPUs
                                         expected 'Z'                                        section.
                                                                   found.




                                                 03 e
                                               5: cl
                                                                   An unexpected




                                             :1 ra
                                         'NVSWITCHNum':                                      Refer to “Missing
DGX-000000000086        inventory                                  number of NVSwitches
                                         found 'Y' expected 'Z'                              NVSwitch” section.


                                           16 al O
                                                                   found.
                                         'HMC_FW_version': not     Unable to fetch HMC       Refer to “Custom BMC
                                         28 ti
DGX-000000000086        inventory
                                       1- en
                                         found. expected 'Y'       Firmware version          Commands” section.
                                     -1 fid


                                                                   Unexpected HMC
                                         'HMC_FW_version':
DGX-000000000086        inventory                                  Firmware version          Update HMC Firmware.
                                   25 on



                                         found 'Y' expected 'Z'
                                                                   found
                                 20 C




                                         'HMC_FW_boot_compl
                                2 IA




                                                                   Unable to fetch HMC       Refer to “Custom BMC
DGX-000000000086        inventory        ete': not found.
                              71 ID




                                                                   Boot Complete Status      Commands” section.
                                         expected 'Y'
                            09 NV




                                                                                             File NVBug for NVIDIA
                                                                                             to review for RMA
                         11 ah




                                         'HMC_FW_boot_compl
                                                                   Unexpected HMC Boot       candidacy qualification
                           sn




DGX-000000000086        inventory        ete': found 'Y'
                                                                   Complete Status           and refer to “Providing
                                         expected 'Z'
                         Ki




                                                                                             Partner Diagnostic
                                                                                             Logs” section.
                     ik
                   R




                                                                                             File NVBug for NVIDIA
                                                                                             to review for RMA
                                         'X': not found.           Unable to fetch           candidacy qualification
DGX-000000000086        inventory
                                         expected 'Y'              attribute 'X'.            and refer to “Providing
                                                                                             Partner Diagnostic
                                                                                             Logs” section.
                                         'X': found 'Y' expected   Inventory item
DGX-000000000086        inventory                                                            Update firmware.
                                         'Z'                       mismatch




   PRELIMINARY INFORMATION
   NVIDIA CONFIDENTIAL
   Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 58
                                                                     Partner Diagnostics Error Codes and Actions


Error Code              Test             Error Message           Explanation                Next Step
                                                                                            Retest with the latest
                                                                                            Partner Diagnostics. If
                                                                                            this issue still occurs,
                                                                                            file NVBug for NVIDIA
                                         FieldDiag exited with
DGX-xxxxxxxxx001        any                                      Software Error             to review for RMA
                                         status X
                                                                                            candidacy qualification.
                                                                                            Refer to “Providing
                                                                                            Partner Diagnostic
                                                                                            Logs” section.
                                                                                            File NVBug for NVIDIA
                                                                                            to review for RMA
                                                                                            candidacy qualification
DGX-xxxxxxxxxxxx        any              any                     -
                                                                                            and refer to “Providing




                                                                                 bs
                                                                                            Partner Diagnostic
                                                                                            Logs” section.




                                                                               La
                                                                                            File NVBug for NVIDIA




                                                 03 e
                                                                                            to review for RMA




                                               5: cl
                                             :1 ra
                                                                 Incorrect PCI lane         candidacy qualification
MODS-xxxxxxxx665        any              any
                                                                 width                      and refer to ““Providing


                                           16 al O
                                                                                            Partner Diagnostic
                                                                                            Logs” section.
                                         28 ti
                                       1- en

                                                                                            Refer to “Missing GPU”
                                     -1 fid


MODS-xxxxxxxx220        any              any                     PCI device not found       and “Missing NVSwitch
                                   25 on



                                                                                            Property” sections.
                                 20 C




                                                                                            File NVBug for NVIDIA
                                                                                            to review for RMA
                                2 IA




                                                                                            candidacy qualification
                              71 ID




MODS-xxxxxxxx143        any              any                     PCI Express Bus Error
                                                                                            and refer to “Providing
                            09 NV




                                                                                            Partner Diagnostic
                                                                                            Logs” section.
                         11 ah




                                                                                            Retest with the latest
                           sn




                                                                                            Partner Diagnostics. If
                         Ki




MODS-xxxxxxxx140        any              any                     NVLink Bus Error           it still fails, Start RMA
                     ik




                                                                                            qualification for
                   R




                                                                                            baseboard.
                                                                                            Retest with the latest
                                                                                            Partner Diagnostics. If
                                                                                            this issue still occurs,
                                                                                            file NVBug for NVIDIA
MODS-xxxxx248272        any              any                     Unexpected Result          to review for RMA
                                                                                            candidacy qualification.
                                                                                            Refer to “Providing
                                                                                            Partner Diagnostic
                                                                                            Logs” section.
                                                                                            Retest with the latest
                                                                 GPU/NVSwitch
                                                                                            Partner Diagnostics. If
                                                                 Interrupt request
MODS-xxxxxxxx609        any              any                                                issue persists, refer to
                                                                 mechanism does not
                                                                                            “GPU Error Codes”
                                                                 work
                                                                                            section.


   PRELIMINARY INFORMATION
   NVIDIA CONFIDENTIAL
   Debug and RAS Guide for NVIDIA Data Center Products                                   DA-11437-001_v13 | 59
                                                         Partner Diagnostics Error Codes and Actions


Error Code              Test             Error Message   Explanation            Next Step
                                                         GPU/NVSWITCH diag      Refer to “GPU Error
MODS-xxxxxxxxxxxx       any              any
                                                         failure                Codes” section.




   4.5              Troubleshooting Actions for Partner
                    Diagnostics Error Codes
   This section describes troubleshooting the Partner Diagnostics error codes.


   4.5.1            Missing GPU Property




                                                                     bs
   If the 'GPUNum' check passed, then proceed to Section 4.5.6 “Providing Partner




                                                                   La
   Diagnostic Logs.” Otherwise, proceed to Section 4.5.2 “Missing GPU.”




                                                 03 e
                                               5: cl
                                             :1 ra
   4.5.2            Missing GPU
                                           16 al O
   Confirm all GPUs are present with lspci. If so, then proceed to Section 4.5.6 “Providing
                                         28 ti
                                       1- en
   Partner Diagnostic Logs.” If not, try power-cycling the system. If the devices are still not
   present, try swapping the missing GPU module, reseating the baseboard, and updating
                                     -1 fid


   firmware. If the issue persists, start RMA qualification.
                                   25 on
                                 20 C
                                2 IA




   4.5.3            Missing NVSwitch Property
                              71 ID
                            09 NV




   If 'NVSWITCHNum' check passed, then proceed to Section 4.5.6 “Providing Partner
   Diagnostic Logs.” Otherwise, proceed to Section 4.5.4 “Missing NVSwitch.”
                         11 ah
                           sn




   4.5.4            Missing NVSwitch
                         Ki
                     ik




   Confirm that all NVSwitch are present with lspci. If so, then proceed to Section 4.5.6
                   R




   “Providing Partner Diagnostic Logs.” If not, try power-cycling the system. If the device is
   still not present, try reseating the baseboard and updating the firmware. If the issue
   persists, start RMA qualification.


   4.5.5            Custom BMC Commands
   This optional test requires system-specific commands to communicate with the BMC.
   The NVIDIA Baseboard Field Diagnostics Software Guide has instructions on how to
   provide these commands to the diag. If this BMC functionality is unavailable, the test
   can be skipped by adding "–-no_bmc" to the diag command line.




   PRELIMINARY INFORMATION
   NVIDIA CONFIDENTIAL
   Debug and RAS Guide for NVIDIA Data Center Products                       DA-11437-001_v13 | 60
                                                      Partner Diagnostics Error Codes and Actions



4.5.6            Providing Partner Diagnostic Logs
The diagnostics generates a tar ball of the log file called logs-<yyyymmdd-
hhnnss>.tgz and places this file in the /logs Baseboard Partner Diagnostics folder.
The log file name is based on the test date and timestamp in the following format:
>   logs/logs-yyyymmdd-hhnnss
>   where:
>   mm = Month
>   dd = Day
>   yy = Year
>   hh = Hours




                                                                  bs
>   nn = Minutes




                                                                La
>   ss = Seconds




                                              03 e
You can find the plain text logs of the Partner Diagnostics run in run.log. Additional




                                            5: cl
                                          :1 ra
details on the contents of the logs can be found in the NVIDIA Baseboard Field


                                        16 al O
Diagnostics Software Guide.
                                      28 ti
                                    1- en

4.6              CPU Field Diagnostics Common Error
                                  -1 fid
                                25 on




                 Code to Action Mapping
                              20 C
                             2 IA




For NVIDIA Grace CPU Field Diagnostic failures, look up the error code in Table 4-6 and
                           71 ID




follow the ‘Next Steps’ section to address the failing system.
                         09 NV
                      11 ah




Figure 4-2.         Grace CPU Partner Diagnostics Error Log
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                       DA-11437-001_v13 | 61
                                                                                Partner Diagnostics Error Codes and Actions


Table 4-6.        Grace CPU Field Diagnostics Common Error Code to Action Mapping
                                                                                                                        Data Center
     Error Code              Error Message                 Explanation                      Next Action
                                                                                                                      Action Category
MODS-xxxxxxxxx002        Software error              Generic SW Error.            1. Check firmware versions          1. REPORT_NV_BUG
                                                     Possible environment         against the latest NVIDIA           2. PROD_FIT
                                                     issue.                       released Firmware versions.
                                                                                  2. Check if the Diag tool was run
                                                                                  with sudo.
                                                                                  3. Check if MODS kernel driver is
                                                                                  installed.
                                                                                  4. If the issue persists, report
                                                                                  Software NVBug to debug root
                                                                                  cause with dmesg, diagnostic
                                                                                  error logs and NVIDIA Bug




                                                                                            bs
                                                                                  report tool logs attached.




                                                                                          La
MODS-xxxxxxxxx224        Feature is not              The tests are running on     Check the test HW platform and      TRIAGE_DEVICE




                                                           03 e
                         supported in the            a non-TH500 product.         confirm if it is a TH500 based




                                                         5: cl
                         hardware                    This error code should       product.




                                                       :1 ra
                                                     not be seen on a TH500


                                                     16 al O
                                                     product.
MODS-xxxxxxxxx612        Invalid value for Tegra     Invalid test ID or           1. Check the test command line      1. REPORT_NV_BUG
                                                   28 ti
                                                 1- en
                         configuration variable(s)   configuration parameter      used and verify the correct test    2. PROD_FIT
                                               -1 fid


                                                     provided.                    ID.
                                             25 on



                                                                                  2. If the issue persists report
                                                                                  Software NVBug to debug root
                                           20 C




                                                                                  cause with dmesg, diagnostic
                                          2 IA




                                                                                  error logs and NVIDIA Bug
                                        71 ID




                                                                                  report tool logs attached.
                                      09 NV




MODS-xxxxxxxxx774        Tegra Test Fail             The tested IP failed         1. Refer to individual tests for    REPORT_NV_BUG
                                                     unexpectedly.                further actions.
                                   11 ah




                                                                                  2. If no action is suggested for
                                     sn




                                                                                  individual tests, then report
                                   Ki




                                                                                  Software NVBug to debug root
                                                                                  cause with dmesg, diagnostic
                               ik
                             R




                                                                                  error logs and NVIDIA Bug
                                                                                  report tool logs attached.
MODS-xxxxxxxxx077        Timeout Error               Tests failed with SW         Report Software NVBug to            REPORT_NV_BUG
                                                     timeout issue and needs      debug root cause with dmesg,
                                                     further investigation.       diagnostic error logs and NVIDIA
                                                                                  Bug report tool logs attached.
For any other Error                                  Unexpected test failure      Report Software NVBug to            REPORT_NV_BUG
Codes                                                                             debug root cause with dmesg,
                                                                                  diagnostic error logs and NVIDIA
                                                                                  Bug report tool logs attached.




             PRELIMINARY INFORMATION
             NVIDIA CONFIDENTIAL
             Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 62
                                                                                        Partner Diagnostics Error Codes and Actions



                    4.7               CPU Field Diagnostics Error Code to
                                      Action Mapping
                    For NVIDIA Grace™ CPU related failures while running Partner Diagnostics, look up the
                    error code in the following table and follow the ‘Next Actions’ column to address the
                    failing system.

Table 4-7.              CPU Field Diagnostics Error Code to Action Mapping
                                                                                                                                Data Center
 Test




                 Error Code            Error Message               Explanation                      Next Action
                                                                                                                              Action Category
            MODS-0000000xx087         Failed while writing   SW issue while writing a      1. Perform a power cycle and       1. REPORT_NV_BUG




                                                                                                    bs
            (xx could be 01, 02, 03   a file                 file.                         retest.                            2. PROD_FIT.




                                                                                                  La
            or 13)                                                                         2. If the issue persists, report   RESET_DEVICE
                                                                                           software NVBug to debug the




                                                                  03 e
                                                                                           root cause with dmesg,




                                                                5: cl
                                                                                           diagnostic error logs and




                                                              :1 ra
                                                                                           NVIDIA bug report tool.


                                                            16 al O
            MODS-0000000xx128         Invalid input          Input to the test is          1. Retest with the latest Diag.    1. REPORT_NV_BUG
            (xx could be 01, 02, 03                          missing, does not match       2. If the issue persists, report   2. PROD_FIT
                                                          28 ti
                                                                                           software NVBug to debug the
                                                        1- en
            or 13)                                           the expected format or
                                                             parameter validation          root cause with dmesg,
                                                      -1 fid


                                                             failed.                       diagnostic error logs and
                                                    25 on



                                                                                           NVIDIA bug report tool.
            MODS-                     Bad parameter          Bad parameter passed to       1. Retest with the latest Diag.    1. REPORT_NV_BUG
                                                  20 C




            0000000xx008              passed to function     software function.            2. If the issue persists, report   2. PROD_FIT
                                                 2 IA




            (xx could be 01, 02, 03                                                        software NVBug to debug the
                                               71 ID




            or 13)                                                                         root cause with dmesg,
                                             09 NV




                                                                                           diagnostic error logs and
 TegraCpu




                                                                                           NVIDIA bug report tool.
                                          11 ah




            MODS-0000000xx010         Cannot open file       Cannot open specified file    1. Retest with the latest Diag.    1. REPORT_NV_BUG
                                            sn




            (xx could be 01, 02, 03                          in the test.                  2. If the issue persists, report   2. PROD_FIT
                                          Ki




            or 13)                                                                         software NVBug to debug the
                                                                                           root cause with dmesg,
                                       ik




                                                                                           diagnostic error logs and
                                      R




                                                                                           NVIDIA bug report tool.
            MODS-0000000xx236         The expected value     Data mismatch occurring       Refer to "RMA Actions".            RETURN_FOR_
            (xx could be 01, 02, 03   and the                during the test.                                                 FURTHER_TRIAGE
            or 13)                    destination
                                      memory value do
                                      not match
            MODS-0000000xx149         Specific test was      The specified test was        1. Check if the same test was      1. REPORT_NV_BUG
            (xx could be 01, 02, 03   requested to run       not executed because it       launched already and kill it.      2. PROD_FIT.
            or 13)                    but skipped            was either already in         2. If the test was not launched    RESET_DEVICE
                                                             progress or skipped due       previously, perform a power
                                                             to other conditions.          cycle and run the test again.
                                                                                           3. If the issue persists, report
                                                                                           software NVBug to debug the
                                                                                           root cause with dmesg,




                    PRELIMINARY INFORMATION
                    NVIDIA CONFIDENTIAL
                    Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 63
                                                                                 Partner Diagnostics Error Codes and Actions



                                                                                                                         Data Center
Test




            Error Code            Error Message              Explanation                     Next Action
                                                                                                                       Action Category
                                                                                    diagnostic error logs and
                                                                                    NVIDIA bug report tool.
       MODS-0000000xx160         Resource is          Resource is reserved by       1. Perform a power cycle and       1. REPORT_NV_BUG
       (xx could be 01, 02, 03   reserved by          another thread or test        run the test again.                2. PROD_FIT.
       or 13)                    another thread or                                  2. If the issue persists, report   RESET_DEVICE
                                 test                                               software NVBug to debug the
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA bug report tool
       MODS-0000000xx077         Timeout error        Unexpected test timeout       Report software NVBug to           REPORT_NV_BUG
       (xx could be 01, 02, 03                        or crash                      debug the root cause with
       or 13)                                                                       dmesg, diagnostic error logs




                                                                                             bs
                                                                                    and NVIDIA bug report tool




                                                                                           La
                                                                                    logs attached.
       MODS-0000000xx012         Failed while         SW issue while reading a      1. Perform a power cycle and       1. REPORT_NV_BUG




                                                             03 e
       (xx could be 01, 02, 03   reading a file       file.                         retest.                            2. PROD_FIT.




                                                           5: cl
                                                                                    2. If the issue persists, report




                                                         :1 ra
       or 13)                                                                                                          RESET_DEVICE
                                                                                    software NVBug to debug the


                                                       16 al O
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                     28 ti
                                                   1- en
                                                                                    NVIDIA bug report tool.
       MODS-0000000xx547         Invalid CPU          Invalid CPU Frequency         Report software NVBug to           REPORT_NV_BUG
                                                 -1 fid


       (xx could be 01, 02, 03   frequency            measured during the test.     debug the root cause with
                                               25 on




       or 13)                    measured                                           dmesg, diagnostic error logs
                                             20 C




                                                                                    and NVIDIA bug report tool
                                            2 IA




                                                                                    logs attached.
                                          71 ID




       MODS-0000000xx164         APEI Error           Detected APEI Error on        HW error detected.                 RETURN_FOR_
                                        09 NV




       (xx could be 01, 02, 03   detected             Dmesg.                        Refer to "RMA Actions".            FURTHER_TRIAGE
       or 13)
                                     11 ah




       MODS-0000000xx039         Unable to set        Unable to set the CPU         For C1 down design, refer to       RETURN_FOR_
       (xx could be 01, 02, 03   element              voltage to the specified      "CPU Isolation" action.
                                       sn




                                                                                                                       FURTHER_TRIAGE
       or 13)                                         value.                        For Grace products, refer to
                                     Ki




                                                      Possible hardware issue       Refer to "RMA Actions".
                                  ik




                                                      with voltage control.
                                 R




       MODS-0000000xx009         Can not allocate     Error happens during          1. Refer to the "Free Memory"      1. REPORT_NV_BUG
       (xx could be 01, 02, 03   memory               allocating memory.            action.                            2. PROD_FIT
       or 13)                                                                       2. If issue persists, report
                                                                                    Software NVBug to debug
                                                                                    root cause with dmesg,
                                                                                    Diagnostic error logs and
                                                                                    NVIDIA bug report tool logs
                                                                                    attached.
       MODS-0000000xx139         Thermal Sensor       CPU internal temperature      1. Verify the cooling solution     TRIAGE_DEVICE
       (xx could be 01, 02, 03   Error                limits exceeded               is working properly and re-
       or 13)                                         acceptable range.             test. Sensors could be broken.
                                                                                    2. If issue persists, start RMA
                                                                                    qualification. Refer to "RMA
                                                                                    Actions".



               PRELIMINARY INFORMATION
               NVIDIA CONFIDENTIAL
               Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 64
                                                                                       Partner Diagnostics Error Codes and Actions



                                                                                                                               Data Center
Test




                   Error Code           Error Message               Explanation                    Next Action
                                                                                                                             Action Category
              MODS-                    Tegra test fail       CPU test failure during      Report software NVBug to           REPORT_NV_BUG
              000000013774                                   execution.                   debug the root cause with
                                                                                          dmesg, diagnostic error logs
                                                                                          and NVIDIA bug report tool
                                                                                          logs attached.
              MODS-                    File does not exist   CPU related system files     1. Enable the kernel               1. REPORT_NV_BUG
              000000013011                                   not found in                 configurations related to CPU      2. RECOVERY.
                                                             /sys/devices/system/cpu/     as per NVIDIA                      RESET_BM
                                                             path.                        recommendations in "grace-
                                                                                          patch-config-guide".
                                                                                          2. Reboot the device and
                                                                                          retest.




                                                                                                   bs
                                                                                          3. If issue persists, report




                                                                                                 La
                                                                                          Software NVBug to debug
                                                                                          root cause with dmesg,




                                                                    03 e
                                                                                          Diagnostic error logs and




                                                                  5: cl
                                                                                          NVIDIA bug report tool logs




                                                                :1 ra
                                                                                          attached.


                                                              16 al O
              MODS-0000000xx236        The expected value    Data mismatch occurring      Refer to "RMA Actions".            RETURN_FOR_
              (xx could be 06 or 12)   and the               during the test.
                                                            28 ti
                                                                                                                             FURTHER_TRIAGE
                                                          1- en
                                       destination
                                       memory value do
                                                        -1 fid


                                       not match
                                                      25 on




              MODS-0000000xx216        Could not find the    Possible issue with NUMA     1. Check NUMA kernel               1. REPORT_NV_BUG
                                                    20 C




              (xx could be 06 or 12)   specified device      configuration of the         configurations in "grace-          2. RECOVERY.
                                                   2 IA




                                                             device.                      patch-config-guide".               RESET_BM
                                                 71 ID




                                                                                          2. Reboot the device and
                                               09 NV




                                                                                          retest.
                                                                                          3. If the issue persists, report
                                            11 ah




                                                                                          software NVBug to debug the
                                                                                          root cause with dmesg,
                                              sn




                                                                                          diagnostic error logs and
                                            Ki
TegraMemory




                                                                                          NVIDIA bug report tool logs
                                        ik




                                                                                          attached.
                                       R




              MODS-0000000xx164        APEI error            Detected an APEI error in    HW error detected.                 RETURN_FOR_
              (xx could be 06 or 12)                         dmesg.                       Refer to "RMA Actions".            FURTHER_TRIAGE
              MODS-                    Can not allocate      Error happens during         1. Refer to the "Free Memory"      1. REPORT_NV_BUG
              0000000xx009             memory                allocating memory.           action.                            2. PROD_FIT
              (xx could be 06 or 12)                                                      2. If issue persists, report
                                                                                          Software NVBug to debug
                                                                                          root cause with dmesg,
                                                                                          Diagnostic error logs and
                                                                                          NVIDIA bug report tool logs
                                                                                          attached.
              MODS-0000000xx240        Unexpected result     Detected HW Error in         HW error detected.                 RETURN_FOR_
              (xx could be 06 or 12)   from HW               dmesg.                       Refer to "RMA Actions".            FURTHER_TRIAGE
              MODS-                    Data mismatch         Data written and read        Refer to "RMA Actions".            RETURN_FOR_
              0000000xx773                                   back from the memory                                            FURTHER_TRIAGE
                                                             mismatch.


                      PRELIMINARY INFORMATION
                      NVIDIA CONFIDENTIAL
                      Debug and RAS Guide for NVIDIA Data Center Products                                   DA-11437-001_v13 | 65
                                                                               Partner Diagnostics Error Codes and Actions



                                                                                                                       Data Center
Test




            Error Code          Error Message               Explanation                    Next Action
                                                                                                                     Action Category
        MODS-                  Read parameter        Clink EOM measurements       Refer to "RMA Actions".            RETURN_FOR_
        000000005272           differs from          are below the threshold.                                        FURTHER_TRIAGE
                               expected
        MODS-                  Hardware was not      Clink driver is not          1. Install the recommended         1. REPORT_NV_BUG
        000000005229           initialized           initialized.                 clink driver and retest.           2. PROD_FIT
                                                                                  2. If the issue persists, report
                                                                                  software NVBug to debug the
                                                                                  root cause with dmesg,
                                                                                  diagnostic error logs and
                                                                                  NVIDIA bug report tool logs
                                                                                  attached.
        MODS-                  NVLink minion         Issue in transactions with   1. Reboot the device and           1. REPORT_NV_BUG




                                                                                           bs
        000000005198           error                 the Clink driver.            retest.                            2. RECOVERY.
                                                                                  2. If the issue persists, report




                                                                                         La
                                                                                                                     RESET_BM
                                                                                  software NVBug to debug the




                                                            03 e
                                                                                  root cause with dmesg,




                                                          5: cl
                                                                                  diagnostic error logs and




                                                        :1 ra
                                                                                  NVIDIA bug report tool logs


                                                      16 al O
                                                                                  attached.
        MODS-                  Resource is           Resource is reserved by      1. Perform a power cycle and       1. REPORT_NV_BUG
                                                    28 ti
                                                  1- en
        000000005160           reserved by           another thread or test.      run the test again.                2. PROD_FIT.
                               another thread or                                  2. If the issue persists, report   RESET_DEVICE
                                                -1 fid


                               test.                                              software NVBug to debug the
                                              25 on



                                                                                  root cause with dmesg,
Clink




                                            20 C




                                                                                  diagnostic error logs and
                                                                                  NVIDIA bug report tool
                                           2 IA




        MODS-                  Tegra test fail       Clink error flags report     Collect and share the Partner      RETURN_FOR_
                                         71 ID




        000000005774                                 error. One or more           Field Diag logs with NVIDIA.       FURTHER_TRIAGE
                                       09 NV




                                                     hardware error flags were    Refer to "RMA Actions".
                                                     detected on the Clink
                                    11 ah




                                                     links during the test.
                                      sn




        MODS-                  HW status error       Clink hardware error         Refer to "RMA Actions".            RETURN_FOR_
                                    Ki




        000000005276                                 counter is greater than 0,                                      FURTHER_TRIAGE
                                ik




                                                     or the hardware reports
                              R




                                                     an abnormal status.
        MODS-                  Data mismatch         Data written and read        Refer to "RMA Actions".            RETURN_FOR_
        000000005773                                 back from the memory                                            FURTHER_TRIAGE
                                                     mismatch.
        MODS-                  NVLink BER bus        Bit error rate observed on   Refer to "RMA Actions".            RETURN_FOR_
        000000005140           error                 the link is above the                                           FURTHER_TRIAGE
                                                     acceptable threshold.
        MODS-                  Bandwidth outside     The link bandwidth is        1. Perform a power cycle.          1. REPORT_NV_BUG
        000000005014           the range             below the acceptable         2. If issue persists, report       2. PROD_FIT.
                                                     threshold.                   Software NVBug to debug            RESET_DEVICE
                                                                                  root cause with dmesg,
                                                                                  diagnostic error logs and
                                                                                  NVIDIA Bug report tool logs
                                                                                  attached.




              PRELIMINARY INFORMATION
              NVIDIA CONFIDENTIAL
              Debug and RAS Guide for NVIDIA Data Center Products                                   DA-11437-001_v13 | 66
                                                                                Partner Diagnostics Error Codes and Actions



                                                                                                                         Data Center
Test




           Error Code          Error Message                 Explanation                     Next Action
                                                                                                                       Action Category
       MODS-                  Can not allocate         Error happens during         1. Refer to the "Free Memory"      1. REPORT_NV_BUG
       000000005009           memory                   allocating memory.           action.                            2. PROD_FIT
                                                                                    2. If issue persists, report
                                                                                    Software NVBug to debug
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA Bug report tool logs
                                                                                    attached.
       MODS-                  Invalid input            Input to the test is         1. Retest with latest Diag.        1. REPORT_NV_BUG
       000000008128                                    missing , does not match     2. If the issue persists, report   2. PROD_FIT
                                                       the expected format or       software NVBug to debug the
                                                       parameter validation         root cause with dmesg,




                                                                                             bs
                                                       failed.                      diagnostic error logs and
                                                                                    NVIDIA bug report tool logs




                                                                                           La
                                                                                    attached.




                                                           03 e
       MODS-                  Function is not          Secure partition not         1. Refer to "Secure Partition"     REPORT_NV_BUG




                                                         5: cl
       000000008003           supported                available.                   section and try again.




                                                       :1 ra
                                                     16 al O
                                                                                    2. If the issue persists, report
                                                                                    software NVBug to debug the
                                                                                    root cause with dmesg,
                                                   28 ti
                                                 1- en
                                                                                    diagnostic error logs and
                                                                                    NVIDIA bug report tool logs
                                               -1 fid


                                                                                    attached.
                                             25 on




       MODS-                  Initialization failure   Issue with C2C SW            1. Retest with the latest Diag.    REPORT_NV_BUG
                                           20 C




       000000008229                                    initialization               2. If the issue persists, report
                                          2 IA




                                                                                    software NVBug to debug the
                                        71 ID




                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                      09 NV




                                                                                    NVIDIA bug report tool logs
C2C




                                                                                    attached.
                                   11 ah




       MODS-                  Bandwidth outside        The link bandwidth is        1. Perform a power cycle.          1. REPORT_NV_BUG
                                     sn




       000000005014           the range                below the acceptable         2. If issue persists, report       2. PROD_FIT.
                                   Ki




                                                       threshold.                   Software NVBug to debug            RESET_DEVICE
                                                                                    root cause with dmesg,
                               ik
                             R




                                                                                    diagnostic error logs and
                                                                                    NVIDIA Bug report tool logs
                                                                                    attached.
       MODS-                  Tegra test fail          Sending FFA message /        1. Refer to "Secure Partition"     1. REPORT_NV_BUG
       000000008774                                    command failed.              action.                            2. PROD_FIT
                                                       Secure partition is          2. Install the correct version
                                                       unavailable.                 of arm_ffa module and retest.
                                                                                    3. If issue persists, report
                                                                                    Software NVBug to debug
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA Bug report tool logs
                                                                                    attached.
       MODS-                  HW status error          C2C HW hardware error        Refer to "RMA Actions".            RETURN_FOR_
       000000008276                                    counter is greater than 0,                                      FURTHER_TRIAGE



             PRELIMINARY INFORMATION
             NVIDIA CONFIDENTIAL
             Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 67
                                                                                 Partner Diagnostics Error Codes and Actions



                                                                                                                         Data Center
Test




           Error Code          Error Message               Explanation                       Next Action
                                                                                                                       Action Category
                                                    or if hardware reports an
                                                    abnormal status.
       MODS-                  Data mismatch         Data written and read           Refer to "RMA Actions".            RETURN_FOR_
       000000008773                                 back from the memory                                               FURTHER_TRIAGE
                                                    mismatch.
       MODS-                  Can not allocate      Error happens during            1. Refer to the "Free Memory"      1. REPORT_NV_BUG
       000000008009           memory                allocating memory.              action.                            2. PROD_FIT
                                                                                    2. If issue persists, report
                                                                                    Software NVBug to debug
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA Bug report tool logs




                                                                                             bs
                                                                                    attached.




                                                                                           La
       MODS-                  Unsupported           Secure partition not            1. Refer to "Secure Partition"     1. REPORT_NV_BUG
       000000008284           hardware              available.                      action and try again.              2. PROD_FIT




                                                           03 e
                              configuration




                                                         5: cl
                                                                                    2. If issue persists, report




                                                       :1 ra
                                                                                    Software NVBug to debug



                                                     16 al O
                                                                                    root cause with dmesg,
                                                   28 ti                            diagnostic error logs and
                                                                                    NVIDIA Bug report tool logs
                                                 1- en
                                                                                    attached.
                                               -1 fid


       MODS-                  Bandwidth outside     The link bandwidth is           Refer to "RMA Actions".            RETURN_FOR_
                                             25 on



       000000004014           the range             below the acceptable                                               FURTHER_TRIAGE
                                                    threshold.
                                           20 C




       MODS-                  PCIe bus error        AER is above the                Refer to "RMA Actions".            RETURN_FOR_
                                          2 IA




       000000004143                                 acceptable threshold.                                              FURTHER_TRIAGE
                                        71 ID




       MODS-                  HW reports wrong      Issue with PCIe link            Refer to "RMA Actions".            RETURN_FOR_
                                      09 NV




       000000004276           status                health.                                                            FURTHER_TRIAGE
       MODS-                  Hardware was not      Required hardware               1. Check if the following          1. REPORT_NV_BUG
                                   11 ah




       000000004229           initialized           modules were not                kernel configuration setting is    2. PROD_FIT
                                     sn




                                                    initialized.                    enabled and retest:
                                   Ki




                                                                                    CONFIG_TEGRA_IVC=y
                                                                                    2. If the issue persists, report
                               ik




                                                                                    software NVBug to debug the
                             R
PCIe




                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA bug report tool logs
                                                                                    attached.
       MODS-                  Software error        Invalid test configuration      1. Perform a power cycle and       1. REPORT_NV_BUG
       000000017002                                                                 run the test again.                2. PROD_FIT.
                                                                                    2. If the issue persists, report   RESET_DEVICE
                                                                                    software NVBug to debug the
                                                                                    root cause with dmesg,
                                                                                    diagnostic error logs and
                                                                                    NVIDIA bug report tool.
       MODS-                  Feature is not        Fail to find the specified      1. Check if PCI devices are        1. REPORT_NV_BUG
       000000017244           supported in the      PHY lanes.                      correctly connected to the         2. PROD_FIT.
                              hardware                                              specified PHY lanes and run        RESET_DEVICE
                                                                                    the test again.



             PRELIMINARY INFORMATION
             NVIDIA CONFIDENTIAL
             Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 68
                                                                            Partner Diagnostics Error Codes and Actions



                                                                                                                    Data Center
Test




           Error Code          Error Message               Explanation                  Next Action
                                                                                                                  Action Category
                                                                               2. Perform a power cycle and
                                                                               run the test again.
                                                                               3. If the issue persists, report
                                                                               software NVBug to debug the
                                                                               root cause with dmesg,
                                                                               diagnostic error logs and
                                                                               NVIDIA bug report tool.
       MODS-                  Read parameter        EOM validation failed      Report software NVBug to           REPORT_NV_BUG
       000000017272           differs from                                     debug the root cause with
                              expected                                         dmesg, diagnostic error logs
                                                                               and NVIDIA bug report tool
                                                                               logs attached.




                                                                                        bs
       MODS-                  Data mismatch         Data written and read      Refer to "RMA Actions".            RETURN_FOR_




                                                                                      La
       000000004773                                 back from the memory                                          FURTHER_TRIAGE
                                                    mismatch.




                                                           03 e
                                                         5: cl
       MODS-                  Unsupported           Secure partition not       1. Refer to "Secure Partition"     1. REPORT_NV_BUG




                                                       :1 ra
       000000004284           hardware              available.                 action and try again.              2. PROD_FIT



                                                     16 al O
                              configuration                                    2. If issue persists , report
                                                   28 ti                       Software NVBug to debug
                                                                               root cause with dmesg,
                                                 1- en

                                                                               diagnostic error logs and
                                               -1 fid


                                                                               NVIDIA Bug report tool logs
                                                                               attached.
                                             25 on
                                           20 C




       MODS-                  Can not allocate      Error happens during       1. Refer to the "Free Memory"      1. REPORT_NV_BUG
       000000004009           memory                allocating memory.         action.                            2. PROD_FIT
                                          2 IA




                                                                               2. If issue persists , report
                                        71 ID




                                                                               Software NVBug to debug
                                      09 NV




                                                                               root cause with dmesg,
                                                                               diagnostic error logs and
                                   11 ah




                                                                               NVIDIA Bug report tool logs
                                     sn




                                                                               attached.
                                   Ki




       MODS-                  Network error         Randomly selected          1. Rerun the test again. Since     1. REPORT_NV_BUG
                               ik




       000000004426                                 network port is being      the port selected is random,       2. PROD_FIT
                             R




                                                    used by another process.   the test should be able to pick
                                                                               a free port.
                                                                               2. If issue persists , report
                                                                               Software NVBug to debug
                                                                               root cause with dmesg,
                                                                               diagnostic error logs and
                                                                               NVIDIA Bug report tool logs
                                                                               attached.
       MODS-                  PCIe bus error        AER is above the           Refer to "RMA Actions".            RETURN_FOR_
       000000004143                                 acceptable threshold.                                         FURTHER_TRIAGE
       MODS-                  Bandwidth outside     The link bandwidth is      Refer to "RMA Actions".            RETURN_FOR_
       000000004014           the range             below the acceptable                                          FURTHER_TRIAGE
                                                    threshold.




             PRELIMINARY INFORMATION
             NVIDIA CONFIDENTIAL
             Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 69
                                                                                 Partner Diagnostics Error Codes and Actions



                                                                                                                         Data Center
Test




           Error Code          Error Message               Explanation                       Next Action
                                                                                                                       Action Category

       MODS-                  Unexpected result     Physical lane EOM status        Refer to "RMA Actions".            RETURN_FOR_
       000000004272           error                 reported is not in the                                             FURTHER_TRIAGE
                                                    acceptable threshold.
       MODS-                  Exit                  CPER test command               Report software NVBug to           1. REPORT_NV_BUG
       000000019001                                 returns non-zero exit           debug the root cause with          2. PROD_FIT
                                                    code.                           dmesg, diagnostic error logs
                                                                                    and NVIDIA bug report tool
                                                                                    logs attached.
       MODS-                  Cannot open file      Ruleset filename not            Verify the ruleset file is         1. REPORT_NV_BUG
       000000019010                                 provided.                       provided and correctly             2. PROD_FIT
                                                                                    located.




                                                                                             bs
       MODS-                  File operation was    The Cper-collect process        1. Retest with the latest Diag.    REPORT_NV_BUG
                                                                                    2. If the issue persists, report




                                                                                           La
       000000019458           interrupted by a      is terminated by a signal.
Cper




                                                                                    software NVBug to debug the
                              signal




                                                             03 e
                                                                                    root cause with dmesg,




                                                           5: cl
                                                                                    diagnostic error logs and




                                                         :1 ra
                                                                                    NVIDIA bug report tool logs



                                                       16 al O
                                                                                    attached.
       MODS-                  Unknown file error    The exit status of the          1. Retest with the latest Diag.    REPORT_NV_BUG
                                                     28 ti
                                                   1- en
       000000019483                                 process is an unknown           2. If the issue persists, report
                                                    state that is neither a         software NVBug to debug the
                                                 -1 fid


                                                    normal exit nor a signal        root cause with dmesg,
                                               25 on



                                                    termination.                    diagnostic error logs and
                                             20 C




                                                                                    NVIDIA bug report tool logs
                                                                                    attached.
                                            2 IA
                                          71 ID
                                        09 NV




             4.8              Diagnostic Error Codes
                                     11 ah
                                       sn




             The following actions help troubleshoot diagnostic error codes.
                                     Ki
                               ik




             4.8.1            Free Memory
                             R




             1. Check for available free memory and use the 'free' command to get the amount of
                free memory.
             2. If observed low free memory available,
                 a. Use 'htop' command to check if there are any high memory consuming processes
                    that can be killed before kicking off the test again.




             PRELIMINARY INFORMATION
             NVIDIA CONFIDENTIAL
             Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 70
                                                       Partner Diagnostics Error Codes and Actions



4.8.2            Secure Partition
1. To enable MODS secure partition, reboot the module.
2. During reboot go into the ‘Setup’ mode.
3. Navigate through Device Manager
    a. NVIDIA Configuration
         i.   Grace configuration
              (1) MODS Secure Partition: If checkbox is not checked, then enable it.
              (2) Reboot the module for the MODS Secure Partition to take effect.


4.8.3            RMA Actions




                                                                   bs
1. Check firmware versions against the latest NVIDIA released firmware versions.




                                                                 La
2. Retest with the latest version of the Grace Partner Diagnostics (Field) if not using
   the latest version.




                                              03 e
                                            5: cl
3. Start RMA qualification if the same error is seen after the previous steps and reruns.




                                          :1 ra
4.8.4            CPU Isolation          16 al O
                                      28 ti
                                    1- en

1. Further isolation is needed to identify if the error is caused by the CPU or other
                                  -1 fid


   system components.
                                25 on




2. If isolated to a faulty CPU, refer to “RMA Actions.”
                              20 C
                             2 IA




4.8.5            Providing Partner Diagnostic Logs
                           71 ID
                         09 NV




The diagnostics generates a tarball of the log file called logs-<yyyymmdd-hhnnss>.tgz
                      11 ah




and places this file in the /logs Partner Diagnostics folder. The log file name is based on
the test date and timestamp in the following format: logs/logs-yyyymmdd-hhnnss
                        sn
                      Ki




where:
                  ik




    •    mm = Month
                R




    •    dd = Day
    •    yy = Year
    •    hh = Hours
    •    nn = Minutes
    •    ss = Seconds
You can find the plain text logs of the partner diagnostic run in run.log. Additional details
on the contents of the logs can be found in the NVIDIA Baseboard Field Diagnostic
Software Guide.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                        DA-11437-001_v13 | 71
Chapter 5.                         Extended Utility
                                   Diagnostic Error Codes



When the Extended Utility Diagnostic (EUD) is run, it will show the results of the run on




                                                                 bs
the console and output it to the corresponding .log file. Faulty systems will cause the




                                                               La
diagnostic to fail, and it will display ‘FAIL’ along with error codes and error messages for




                                              03 e
the failing tests on the console and at the end of the .log file. Extended Utility Diagnostic




                                            5: cl
can be run in two different variants: Opportunistic EUD and GPU EUD Field Diagnostics.




                                          :1 ra
                                        16 al O
Error codes provide insight into the cause of the failure and could be used to infer steps
required to address the failure. Refer to Section 5.1 “GPU EUD Error Code to Action
                                      28 ti
Mapping,” to learn more about the common measures to address the failure per error
                                    1- en

code seen after running the specific variant of EUD.
                                  -1 fid
                                25 on



The “GPU EUD Field Diagnostics” provides exhaustive coverage of the hardware and may
qualify faulty parts for RMA. It runs for roughly 10 hours, regressing all the available
                              20 C




power states, and extensively tests compute, memory, high-speed I/O, and performance
                             2 IA




of the system. GPU EUD Field Diagnostics should be used for exhaustive coverage, that
                           71 ID




is when the hardware is intermittently failing and must repair or qualify faulty hardware
                         09 NV




for RMA.
                      11 ah




The Opportunistic EUD runs for roughly 30 minutes and targets a small set of tests. It
                        sn




can be run in between workloads to check the system's health. The Opportunistic EUD
                      Ki




will catch failures related to silent data corruption.
                  ik




Look up the error code in Table 5-2 and follow the “Next Steps” column to address the
                R




failing system.



5.1              GPU EUD Error Code to Action
                 Mapping
Look up the error code in Table 5-2 and follow the “Next Steps” column to address the
failing system. The GPU EUD will catch failures related to silent data corruption and
identify parts for the RMA process. The Data Center Action Category corresponding to
each error code is also included with the corresponding action description in Table 5-1.



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 72
                                                                      Extended Utility Diagnostic Error Codes


Table 5-1.          Data Center Action to Data Center Description Mapping – GPU
                    EUD
 Data Center Action Category               Data Center Action Description
 N/A                                       Not applicable.
 PROD_FIT                                  System is production ready if the error is not seen again.
 PROD_FIT.RESET_DEVICE                     Reset failing device aka hot reset failing device. The system is then
                                           production ready.
 RECOVERY                                  Running additional tools can get the system back in production.
 RECOVERY.RESET_BM                         Restart bare metal aka cold reboot the system. Running additional
                                           tools can get the system back in production.
 RECOVERY.RESET_SW                         Warm reboot the system aka reload latest supported installed
                                           firmware / driver. Running additional tools can get the system




                                                                             bs
                                           back in production.




                                                                           La
 RECOVERY.RUN_INFOROM                      Run InfoROM recovery tool. Running additional tools can get the
                                           system back in production.




                                              03 e
                                            5: cl
 REPORT_NV_BUG                             Report Software NVBug to debug root cause with dmesg,




                                          :1 ra
                                           diagnostic error logs, and NVIDIA Bug report tool log attached.



                                        16 al O
 RMA_BOARD                                 Take the failing board out of production and start RMA
                                           qualification for failing board.
                                      28 ti
                                    1- en
 RETURN_FOR_FURTHER_TRIAGE                 Take the failing tray or board out of production and return the
                                  -1 fid


                                           failing tray or board to the integrator for further triage and
                                           possible RMA.
                                25 on




 RMA_DEVICE                                For NVIDIA Hopper™ products, take the failing device out of
                              20 C




                                           production and start RMA qualification for failing device.
                             2 IA




                                           For Blackwell products, take the failing board out of production
                           71 ID




                                           and start RMA qualification for failing device.
                         09 NV




                                           Note that RMA decisions must involve the integrator. Datacenter
                                           actions may involve returning the component to the integrator
                      11 ah




                                           and may possibly translate to RMA following further testing and
                        sn




                                           investigation done by the integrator.
                      Ki




 TRIAGE_BOARD                              Take the failing board out of production and follow next action
                  ik




                                           steps for that error code. If qualified for RMA, RMA the board. To
                R




                                           RMA the board, return the board to the integrator for further
                                           triage.
 TRIAGE_DEVICE                             For NVIDIA Hopper products, take the failing device out of
                                           production and follow next action steps for that error code. If
                                           qualified for RMA, RMA the device.
                                           For Blackwell products, take the failing board out of production
                                           and follow next action steps for that error code. If qualified for
                                           RMA, RMA the device




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 73
                                                                                Extended Utility Diagnostic Error Codes


Table 5-2.       GPU EUD Error Code to Action Mapping
                Error                                                                                  Data Center Action
 Error Code     Message            Explanation                 Next Steps                              Category
 xxxxxxxxx002   software error     An unexpected               1. Re-test with latest GPU EUD if       1. REPORT_NV_BUG
                                   software error has          not tested with the latest GPU          2. PROD_FIT
                                   occurred.                   EUD.
                                                               2. File Software NVBug to debug
                                                               and root cause with dmesg,
                                                               diagnostic tool logs, and NVIDIA
                                                               Bug report tool log if the same
                                                               error code is seen after running
                                                               GPU EUD.
 xxxxxxxxx008   Bad parameter      Software error / bad        1. Re-test with latest GPU EUD if       1. REPORT_NV_BUG
                passed to          parameter passed to         not tested with the latest GPU          2. PROD_FIT




                                                                                       bs
                function           software function.          EUD.




                                                                                     La
                                                               2. File Software NVBug to debug




                                                        03 e
                                                               and root cause with dmesg,




                                                      5: cl
                                                               diagnostic tool logs, and NVIDIA




                                                    :1 ra
                                                               Bug report tool log if the same



                                                  16 al O
                                                               error code is seen after running
                                                               GPU EUD.
                                                28 ti
                                              1- en
 xxxxxxxxx021   script failed to   File Software NVBug         1. Re-test with latest GPU EUD if       1. REPORT_NV_BUG
                execute            and attach dmesg,           not tested with the latest GPU          2. PROD_FIT
                                            -1 fid


                                   diagnostic error logs,      EUD.
                                          25 on



                                   NVBug report tool log,      2. File Software NVBug to debug
                                        20 C




                                   to debug and root           and root cause with dmesg,
                                       2 IA




                                   cause.                      diagnostic tool logs, and NVIDIA
                                     71 ID




                                                               Bug report tool log, if the same
                                                               error code is seen after running
                                   09 NV




                                                               GPU EUD.
                                11 ah




 xxxxxxxxx060   NVRM invalid       This could be caused by     1. Check firmware versions              1. REPORT_NV_BUG
                                  sn




                param struct       varied NVRM assertion       against the latest NVIDIA release       2. PROD_FIT.RESET_DEVICE
                                   failure. File Software      firmware versions.
                                Ki




                                   NVBug and attach            2. Re-test with latest GPU EUD if
                           ik




                                   dmesg, diagnostic error     not tested with the latest GPU
                         R




                                   logs, NVBug report tool     EUD.
                                   log, to debug and root
                                                               3. File Software NVBug to debug
                                   cause.
                                                               root cause with dmesg, diagnostic
                                                               error logs, and NVIDIA Bug report
                                                               tool log attached, if the same error
                                                               code is seen after the GPU EUD
                                                               run.
 xxxxxxxxx077   timeout error      Follow the triage flow      1. Check firmware versions              1. TRIAGE_DEVICE
                                   to diagnose/repair root     against the latest NVIDIA release
                                   cause.                      firmware versions.
                                                               2. Re-test with latest GPU EUD if
                                                               not tested with the latest GPU
                                                               EUD.




         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 74
                                                                               Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
                                                              3. Follow Triage Flow (NVOnline:
                                                              1091416) if the same error code is
                                                              seen after the GPU EUD run.
xxxxxxxxx083   CRC/Checksum       Computation has             1. Check firmware versions              1. RETURN_FOR_
               miscompare         returned an incorrect       against the latest NVIDIA release       FURTHER_TRIAGE
                                  answer.                     firmware versions.
                                                              2. Re-test with latest GPU EUD if
                                                              not tested with the latest GPU
                                                              EUD.
                                                              3. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.




                                                                                      bs
xxxxxxxxx097   Unexpected         Diag received an            1. Check firmware versions              1. RETURN_FOR_




                                                                                    La
               device             unexpected interrupt        against the latest NVIDIA release       FURTHER_TRIAGE
               interrupts         that it considers an        firmware versions.




                                                      03 e
                                                    5: cl
                                  error. It could be a        2. Re-test with latest GPU EUD if




                                                  :1 ra
                                  MMU fault during a          not tested with the latest GPU


                                                16 al O
                                  CUDA test, which is         EUD.
                                  indicative of a GPU
                                                              3. Start RMA qualification if the
                                              28 ti
                                  hardware issue.
                                            1- en
                                                              same error code is seen after the
                                                              GPU EUD run.
                                          -1 fid
                                        25 on



xxxxxxxxx124   Invalid            InfoROM corruption has      1. Check firmware versions              1. TRIAGE_DEVICE
               InfoROM            occurred. Recover           against the latest NVIDIA release
                                      20 C




                                  InfoROM by running          firmware versions.
                                     2 IA




                                  InfoROM recovery tool.      2. Run InfoROM recovery tool. For
                                   71 ID




                                                              Blackwell generation of products,
                                 09 NV




                                                              please refer to InfoROM Cleansing
                                                              for RMA - User Guide (NVOnline:
                              11 ah




                                                              1120261).
                                sn




                                                              3. Re-test with latest GPU EUD if
                              Ki




                                                              not tested with the latest GPU
                                                              EUD.
                          ik
                        R




                                                              4. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.
xxxxxxxxx127   Vbios              An issue with the VBIOS     1. Check firmware versions              1. RECOVERY.RESET_SW
               Certificate        certificate.                against the latest NVIDIA release       2. PROD_FIT
               Error                                          firmware versions.
                                                              2. Re-test with latest GPU EUD if
                                                              not tested with the latest version.
                                                              3. File Software NVBug to debug
                                                              root cause with dmesg, diagnostic
                                                              error logs, and NVIDIA Bug report
                                                              tool log attached, if the same error
                                                              code is seen after the GPU EUD
                                                              run.



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 75
                                                                                Extended Utility Diagnostic Error Codes


               Error                                                                                   Data Center Action
Error Code     Message            Explanation                  Next Steps                              Category
xxxxxxxxx139   Acceptable         Possible issue with          1. Check firmware versions              1. TRIAGE_DEVICE
               temperature        cooling systems. Check       against the latest NVIDIA release
               limits exceeded    cooling systems and          firmware versions.
               or the thermal     engage with NVIDIA.          2. Re-test with latest GPU EUD if
               sensor is          Failing part qualifies for   not tested with the latest version.
               broken or          RMA only if the problem
                                                               3. Start RMA qualification if the
               miscalibrated      is isolated to NVIDIA
                                                               same error code is seen after the
                                  hardware.
                                                               run and only if the cooling solution
                                                               is part of NVIDIA hardware.
xxxxxxxxx140   NvLink bus         NVLink is down or            1. Reseat the failing GPU.              1. TRIAGE_DEVICE
               error              NVLink errors occurred       2. Ensure GPU and NVSwitches are
                                  during NVLink testing.       detected on the system using




                                                                                       bs
                                  Follow to triage flow if     lspci utility.




                                                                                     La
                                  same error code is seen
                                                               3. Re-test with latest GPU EUD if
                                  after running latest




                                                      03 e
                                                               not tested with the latest GPU




                                                    5: cl
                                  GPU EUD.
                                                               EUD.




                                                  :1 ra
                                                               4. Follow RMA Triage Flow


                                                16 al O
                                                               (NVOnline: 1091416) if the same
                                                               error code is seen after the GPU
                                              28 ti
                                            1- en
                                                               EUD run.
                                          -1 fid


xxxxxxxxx143   PCI Express        PCIe link errors cause       1. Reseat the failing GPU               1. TRIAGE_DEVICE
               bus error          PCIe tests to fail.
                                        25 on



                                                               2. Ensure GPU and NVSwitches are
                                                               detected on the system using
                                      20 C




                                                               lspci utility.
                                     2 IA




                                                               3. Re-test with latest GPU EUD if
                                   71 ID




                                                               not tested with the latest GPU
                                 09 NV




                                                               EUD.
                                                               4. Follow RMA Triage Flow
                              11 ah




                                                               (NVOnline: 1091416) if the same
                                sn




                                                               error code is seen after the GPU
                              Ki




                                                               EUD run.
                          ik




xxxxxxxxx144   CUDA error         One of the CUDA tests        1. Check firmware versions              1. TRIAGE_DEVICE
                        R




                                  is failing. File Software    against the latest NVIDIA release
                                  NVBug and attach             firmware versions.
                                  dmesg, diagnostic error      2. Re-test with latest GPU EUD if
                                  logs, NVBug report tool      not tested with the latest GPU
                                  log, to debug and root       EUD.
                                  cause.
                                                               3. File Software NVBug to debug
                                                               root cause with dmesg, diagnostic
                                                               error logs, and NVIDIA Bug report
                                                               tool log attached, if the same error
                                                               code is seen after the GPU EUD
                                                               run.
xxxxxxxxx194   bad memory         Computation has              1. Check firmware versions              1. RETURN_FOR_
                                  returned an incorrect        against the latest NVIDIA release       FURTHER_TRIAGE
                                  answer.                      firmware versions.



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                        DA-11437-001_v13 | 76
                                                                               Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
                                                              2. Re-test with latest GPU EUD if
                                                              not tested with the latest GPU
                                                              EUD.
                                                              3. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.
xxxxxxxxx220   PCIe device not    Failure with PCIe           1. Check firmware versions              1. RECOVERY.RESET_BM
               found              device. Need to isolate     against the latest NVIDIA release       2. PROD_FIT
                                  the failure to GPU or       firmware versions.
                                  baseboard.                  2. Reseat failing GPU.
                                                              3. Ensure GPU and NVSwitches are
                                                              detected on the system using




                                                                                         bs
                                                              lspci utility.




                                                                                       La
                                                              4. Perform cold reboot i.e., full




                                                      03 e
                                                              system shutdown and manually




                                                    5: cl
                                                              reboot again.




                                                  :1 ra
                                                              5. Re-test with latest GPU EUD if


                                                16 al O
                                                              not tested with the latest GPU
                                                              EUD.
                                              28 ti
                                            1- en
                                                              6. Start RMA qualification if the
                                                              same error code is seen after the
                                          -1 fid


                                                              GPU EUD run.
                                        25 on




xxxxxxxxx229   Hardware was       Something prevented         1. Check firmware versions              1. TRIAGE_DEVICE
                                      20 C




               not initialized    successful hardware         against the latest NVIDIA release
                                     2 IA




                                  initialization.             firmware versions.
                                   71 ID




                                                              2. Re-test with latest GPU EUD if
                                 09 NV




                                                              not tested with the latest GPU
                                                              EUD.
                              11 ah




                                                              3. Follow Triage Flow (NVOnline:
                                sn




                                                              1091416) if the same error code is
                              Ki




                                                              seen after the GPU EUD run.
                           ik




xxxxxxxxx240   Unexpected         If running GPU EUD on       1. Check firmware versions              1. TRIAGE_DEVICE
                        R




               result from HW     a single GPU, make sure     against the latest NVIDIA release
                                  the 'skip_nvlink'           firmware versions.
                                  parameter is used. If it    2. Re-test with latest GPU EUD if
                                  is, then there is a         not tested with the latest GPU
                                  possible setup issue,       EUD.
                                  confirm the NVLink
                                                              3. Follow RMA Triage Flow
                                  topology is connected
                                                              (NVOnline: 1091416) if the same
                                  as expected by running:
                                                              error code is seen after the GPU
                                  nvidia-smi nvlink -s        EUD run.
                                  If NVLink connections
                                  are reported as inactive,
                                  debug NVLink issue.
xxxxxxxxx272   Read               File Software NV bug        1. Check firmware versions              1. TRIAGE_DEVICE
               parameter          and attach dmesg,           against the latest NVIDIA release
                                  diagnostic error logs,      firmware versions.

        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 77
                                                                               Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
               differs from       NV bug report tool log,     2. Re-test with latest GPU EUD if
               expected           to debug root cause.        not tested with the latest GPU
                                                              EUD.
                                                              3. File Software NVBug to debug
                                                              root cause with dmesg, diagnostic
                                                              error logs, and NVIDIA Bug report
                                                              tool log attached, if the same error
                                                              code is seen after the run.
xxxxxxxxx276   HW reports         Hardware failure has        1. Check firmware versions              1. RETURN_FOR_
               wrong status       occurred.                   against the latest NVIDIA release       FURTHER_TRIAGE
                                                              firmware versions.
                                                              2. Re-test with latest GPU EUD if




                                                                                      bs
                                                              not tested with the latest GPU




                                                                                    La
                                                              EUD.
                                                              3. Start RMA qualification if the




                                                      03 e
                                                    5: cl
                                                              same error code is seen after the




                                                  :1 ra
                                                              run.



                                                16 al O
MODS-          Power is above     Power is too high           1. Re-test with latest GPU EUD if       1. REPORT_NV_BUG
xxxxxxxxx280   specified limit                                not already tested with the latest      2. PROD_FIT
                                              28 ti
                                                              GPU EUD.
                                            1- en

                                                              2. File Software NVBug to debug
                                          -1 fid


                                                              root cause with dmesg, diagnostic
                                        25 on




                                                              error logs, and NVIDIA Bug report
                                      20 C




                                                              tool log attached if the same error
                                     2 IA




                                                              code is seen after the run.
                                   71 ID




MODS-          Power is below     Power is too low            1. Re-test with latest GPU EUD if       1. REPORT_NV_BUG
                                 09 NV




xxxxxxxxx288   specified limit                                not already tested with the latest      2. PROD_FIT
                                                              GPU EUD.
                              11 ah




                                                              2. File Software NVBug to debug
                                sn




                                                              root cause with dmesg, diagnostic
                              Ki




                                                              error logs, and NVIDIA Bug report
                          ik




                                                              tool log attached if the same error
                        R




                                                              code is seen after the run.

xxxxxxxxx311   NVLink             NVLink topology does        1. Check firmware versions              1. TRIAGE_DEVICE
               discovered         not match expected          against the latest NVIDIA release
               topology does      topology.                   firmware versions.
               not match                                      2. Ensure GPU and NVSwitches are
               required                                       detected on the system using
               topology                                       lspci utility.
                                                              3. Perform cold reboot i.e., full
                                                              system shutdown and manually
                                                              reboot again.
                                                              4. Reseat failing GPU if reboot did
                                                              not resolve the issue.




        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 78
                                                                              Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
                                                              5. Re-install NVIDIA release driver
                                                              if rebooting and reseating the GPU
                                                              did not resolve the issue.
                                                              6. Re-test with latest GPU EUD if
                                                              not tested with the latest GPU
                                                              EUD.
                                                              7. Run HGX diagnostic mentioned
                                                              in the Triage Flow (NVOnline:
                                                              1091416) if the same error code is
                                                              seen after the GPU EUD run.
xxxxxxxxx317   ECC detected       Uncorrectable error         1. Check firmware versions              1. TRIAGE_DEVICE
               an                 seen in the frame           against the latest NVIDIA release




                                                                                      bs
               uncorrectable      buffer, reset the GPU       firmware versions.




                                                                                    La
               error in FB        for row remapping to        2. Power cycle the GPU to trigger
                                  take place, follow the      row remapping.




                                                      03 e
                                  triage flow if same




                                                    5: cl
                                                              3. Re-test with latest GPU EUD if




                                                  :1 ra
                                  failure signature is seen
                                                              not tested with the latest GPU



                                                16 al O
                                  after retesting with
                                                              EUD.
                                  latest GPU EUD.
                                                              4. Follow RMA Triage Flow
                                              28 ti
                                            1- en
                                                              (NVOnline: 1091416) if the same
                                                              error code is seen after the GPU
                                          -1 fid


                                                              EUD run.
                                        25 on




xxxxxxxxx319   ECC detected       Uncorrectable error         1. Check firmware versions              1. TRIAGE_DEVICE
                                      20 C




               an                 seen in the L2 cache,       against the latest NVIDIA release
                                     2 IA




               uncorrectable      reset for row               firmware versions.
                                   71 ID




               error in L2        remapping to take           2. Power cycle GPU to trigger row
                                 09 NV




                                  place, then retest with     remapping.
                                  latest GPU FD.
                                                              3. Re-test with latest GPU EUD if
                              11 ah




                                                              not tested with the latest GPU
                                sn




                                                              EUD.
                              Ki




                                                              4. Start RMA qualification if the
                                                              same error code is seen after the
                          ik
                        R




                                                              GPU EUD run.
xxxxxx171321   ECC detected       Uncorrectable error         1. Check firmware versions              1. RETURN_FOR_
               an                 seen in the SM while        against the latest NVIDIA release       FURTHER_TRIAGE
               uncorrectable      running T171, reset the     firmware versions.
               error in SM        GPU for row remapping       2. Power cycle GPU to trigger row
                                  to take place, follow the   remapping.
                                  triage flow if same
                                                              3. Re-test with latest GPU EUD if
                                  failure signature is seen
                                                              not tested with the latest GPU
                                  after retesting with
                                                              EUD.
                                  latest GPU EUD.
                                                              4. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.




        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 79
                                                                              Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
xxxxxxxxx320   ECC detected a     Rate of correctable         1. Check firmware versions              1. TRIAGE_DEVICE
               correctable        errors seen in the SM       against the latest NVIDIA release
               error in SM,       have exceeded               firmware versions.
               threshold          threshold. Follow the       2. Power cycle GPU to trigger row
               exceeded           RMA triage flow if same     remapping.
                                  failure signature is seen
                                                              3. Re-test with latest GPU EUD if
                                  after re-testing with
                                                              not tested with the latest GPU
                                  latest GPU EUD.
                                                              EUD.
                                                              4. Follow Triage Flow (NVOnline:
                                                              1091416) if the same error code is
                                                              seen after the run.
xxxxxxxxx321   ECC detected       Uncorrectable error         1. Check firmware versions              1. TRIAGE_DEVICE




                                                                                      bs
               an                 seen in the SM. Follow      against the latest NVIDIA release




                                                                                    La
               uncorrectable      the RMA triage flow if      firmware versions.
               error in SM        same failure signature




                                                      03 e
                                                              2. Power cycle GPU to trigger row




                                                    5: cl
                                  is seen after retesting     remapping.




                                                  :1 ra
                                  with latest GPU EUD.
                                                              3. Re-test with latest GPU EUD if


                                                16 al O
                                                              not tested with the latest GPU
                                                              EUD.
                                              28 ti
                                            1- en
                                                              4. Follow Triage Flow (NVOnline:
                                          -1 fid


                                                              1091416) if the same error code is
                                                              seen after the run.
                                        25 on




xxxxxxxxx341   Buffer             Start RMA qualification     1. Check firmware versions              1. RETURN_FOR_
                                      20 C




               mismatch           for baseboard including     against the latest NVIDIA release       FURTHER_TRIAGE
                                     2 IA




                                  the exact SXMs.             firmware versions.
                                   71 ID




                                                              2. Re-test with latest GPU EUD .
                                 09 NV




                                                              3. Start RMA qualification if the
                                                              same error code is seen after the
                              11 ah




                                                              run.
                                sn




xxxxxxxxx363   Row remapping      A row remapping failure     1. Check firmware versions              1. RETURN_FOR_
                              Ki




               failed             has occurred.               against the latest NVIDIA release       FURTHER_TRIAGE
                          ik




                                                              firmware versions.
                        R




                                                              2. Re-test with latest GPU EUD if
                                                              not tested with the latest GPU
                                                              EUD.
                                                              3. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.
xxxxxxxxx539   NVRM generic       This could be caused by     1. Check firmware versions              1. REPORT_NV_BUG
               falcon error       various NVRM generic        against the latest NVIDIA release       2. PROD_FIT.RESET_DEVICE
                                  failures. File Software     firmware versions.2. Re-test with
                                  NVBug and attach            latest GPU EUD if not tested with
                                  dmesg, diagnostic error     the latest GPU EUD.
                                  logs and NVBug report       3. File Software NVBug to debug
                                  tool log, to debug and      and root cause with dmesg,
                                  root cause.                 diagnostic tool logs, and NVIDIA


        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 80
                                                                                Extended Utility Diagnostic Error Codes


               Error                                                                                   Data Center Action
Error Code     Message            Explanation                  Next Steps                              Category
                                                               Bug report tool log, if the same
                                                               error code is seen after running
                                                               GPU EUD.
xxxxxxxxx541   NVRM               This could be caused by      1. Check firmware versions              1. TRIAGE_DEVICE
               detected           various NVRM memory          against the latest NVIDIA release
               memory error       failures. File Software      firmware versions.
                                  NVBug and attach             2. Re-test with latest GPU EUD if
                                  dmesg, diagnostic error      not tested with the latest GPU
                                  logs and NVBug report        EUD.
                                  tool log, to debug and
                                                               3. File Software NVBug to debug
                                  root cause.
                                                               and root cause with dmesg,
                                                               diagnostic tool logs, and NVIDIA




                                                                                       bs
                                                               Bug report tool log, if the same




                                                                                     La
                                                               error code is seen after running
                                                               GPU EUD.




                                                      03 e
                                                    5: cl
xxxxxxxxx542   NVRM VBIOS         NVRM VBIOS validation        1. Check firmware versions              1. REPORT_NV_BUG




                                                  :1 ra
               invalid or         failure.                     against the latest NVIDIA release       2. PROD_FIT.RESET_DEVICE



                                                16 al O
               rejected           File Software NVBug          firmware versions.
                                  and attach dmesg,
                                              28 ti            2. Re-test with latest GPU EUD if
                                  diagnostic error logs,       not tested with the latest GPU
                                            1- en

                                  NV bug report tool log       EUD.
                                          -1 fid


                                  attached to debug root
                                                               3. File Software NVBug to debug
                                  cause.
                                        25 on



                                                               root cause with dmesg, diagnostic
                                      20 C




                                                               error logs, and NVIDIA Bug report
                                                               tool log attached, if the same error
                                     2 IA




                                                               code is seen after the GPU EUD
                                   71 ID




                                                               run.
                                 09 NV




xxxxxxxxx582   GPU stress         Computation has              1. Check firmware versions              1. RETURN_FOR_
                              11 ah




               test found         returned an incorrect        against the latest NVIDIA release       FURTHER_TRIAGE
               pixel              answer.                      firmware versions.
                                sn




               miscompares                                     2. Re-test with latest GPU EUD if
                              Ki




                                                               not tested with the latest GPU
                          ik




                                                               EUD.
                        R




                                                               3. Start RMA qualification if the
                                                               same error code is seen after the
                                                               run.
xxxxxxxxx599   Fan does not       Possibly an issue with       1. Check firmware versions              1. TRIAGE_DEVICE
               seem to cool       cooling systems.             against the latest NVIDIA release
               the chip           Failing part qualifies for   firmware versions.
                                  RMA only if the problem      2. Re-test with latest GPU EUD if
                                  is isolated to NVIDIA        not tested with the latest GPU
                                  hardware.                    EUD.
                                                               3. Start RMA qualification if the
                                                               same error code is seen after the
                                                               run and only if the cooling solution
                                                               is part of NVIDIA hardware.




        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                        DA-11437-001_v13 | 81
                                                                               Extended Utility Diagnostic Error Codes


               Error                                                                                  Data Center Action
Error Code     Message            Explanation                 Next Steps                              Category
xxxxxxxxx614   Extra golden       One of the EUD tests        1. Check firmware versions              1. RETURN_FOR_
               code               failed the consistency      against the latest NVIDIA release       FURTHER_TRIAGE
               miscompare         check on expected           firmware versions.
                                  values.                     2. Re-test with latest GPU EUD if
                                                              not tested with the latest GPU
                                                              EUD.
                                                              3. Start RMA qualification if the
                                                              same error code is seen after the
                                                              GPU EUD run.
xxxxxxxxx679   NVRM invalid       This could be caused by     1. Check firmware versions              1. REPORT_NV_BUG
               argument           various NVRM assertion      against the latest NVIDIA release       2. PROD_FIT.
                                  failures. File Software     firmware versions.                      RESET_DEVICE




                                                                                      bs
                                  NVBug and attach            2. Re-test with latest GPU EUD if




                                                                                    La
                                  dmesg, diagnostic error     not tested with the latest GPU
                                  logs and NVBug report       EUD.




                                                       03 e
                                                     5: cl
                                  tool log, to debug and
                                                              3. File Software NVBug to debug




                                                   :1 ra
                                  root cause.
                                                              and root cause with dmesg,


                                                 16 al O
                                                              diagnostic tool logs, and NVIDIA
                                                              Bug report tool log attached, if the
                                               28 ti
                                                              same error code is seen after the
                                             1- en

                                                              GPU EUD run.
                                           -1 fid


xxxxxxxxx779   Voltage value      The input voltage           1. Check firmware versions              1. REPORT_NV_BUG
                                         25 on




               out of range       supply to the GPU is        against the latest NVIDIA release       2. PROD_FIT.
                                       20 C




                                  out of specification.       firmware versions.                      RESET_DEVICE
                                      2 IA




                                  Please check the            2. Check the input voltage to the
                                    71 ID




                                  system power supply         GPU and the system power supply.
                                  and try again.              3. Re-test with latest GPU EUD if
                                  09 NV




                                                              not tested with the latest GPU
                                                              EUD.
                               11 ah




                                                              4. File Software NVBug to debug
                                 sn




                                                              root cause with dmesg, diagnostic
                               Ki




                                                              error logs, and NVIDIA Bug report
                          ik




                                                              tool log attached, if the same error
                        R




                                                              code is seen after the GPU EUD
                                                              run.
xxxxxxxxx818   MODS               This could be the result    1. Check firmware versions              1. REPORT_NV_BUG
               detected an        of unexpected chip          against the latest NVIDIA release       2. PROD_FIT
               assertion          configuration,              firmware versions.
               failure            programming error,          2. Re-test with latest GPU EUD if
                                  hardware fault or           not tested with the latest GPU
                                  failure. File Software      EUD.
                                  NVBug and attach
                                                              3. File Software NVBug to debug
                                  dmesg, diagnostic error
                                                              and root cause with dmesg,
                                  logs, NVBug report tool
                                                              diagnostic tool logs, and NVIDIA
                                  log to debug and root
                                                              Bug report tool log attached, if the
                                  cause.
                                                              same error code is seen after
                                                              running GPU EUD.



        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 82
                                                                             Extended Utility Diagnostic Error Codes



    5.2              CPU EUD Related Error Code to
                     Action Mapping
    For CPU EUD related failures, look up the error code in Table 5-3 and follow the Next
    Steps column to address the failing system.

Table 5-3.        CPU EUD Related Error Code to Action Mapping
 Error Code         Error Message             Explanation                             Next Steps
 xxxxxxxxx002       Software Error            Unexpected software errors              Re-test with the latest version of
                                                                                      EUD. If it still fails, file a Software
                                                                                      NVBug with log files.




                                                                                    bs
 xxxxxxxxx005       Bad Command Line          Input argument is not supported,        Check the supported argument




                                                                                  La
                    Argument                  or the test suite name is incorrect     and try again. It supports the
                                                                                      following test suite names:




                                                  03 e
                                                                                      - RmaFull




                                                5: cl
                                              :1 ra
                                                                                      - Opportunistic



                                            16 al O
                                                                                      - Trickle
 xxxxxxxxx008       Bad Parameter             [2,3,4,8,9,11] Invalid parameter        [2,3,4,8,9,11] Re-test with the
                                          28 ti
                                              passed to function                      latest version of CPU EUD. If it
                                        1- en

                                                                                      still fails, file a Software NVBug
                                      -1 fid


                                                                                      with log files.
                                    25 on




 xxxxxxxxx009       Cannot Allocate           [9] Failed to allocate memory           [9] Ensure free memory size is
                                  20 C




                    Memory                                                            sufficient for test.
                                 2 IA




 xxxxxxxxx012       File Read Error           [1] Tarball file for test is damaged    [1] Re-download the EUD package
                               71 ID




                                                                                      and try again.
                             09 NV




 xxxxxxxxx023       Could Not Compile File    [1] Failed to compile file              [1] Check if gcc and md5sum are
                                                                                      installed on the system, or check
                          11 ah




                                                                                      if CPU hardware is damaged.
                            sn




 xxxxxxxxx077       Timeout Error             Test timeout                            Collect and share the logs with
                          Ki




                                                                                      NVIDIA.
                      ik




 xxxxxxxxx084       Cannot Parse File         [11] Config file parse error            [11] Re-test with the latest
                    R




                                                                                      version of EUD. If it still fails, file a
                                                                                      Software NVBug with log files.
 xxxxxxxxx087       File Write Error          [11] Failed while writing config        [11] Check free disk space and
                                              file                                    ensure file can be written.
 xxxxxxxxx128       Invalid Input             [5] Incorrect input file causes         [5,7,9] Check the test HW
                                              exec pipe error                         platform and re-test with the
                                              [7] Failed to read from lspci           latest version of EUD.
                                              command
                                              [9] Failed to get pattern data or
                                              test mode
 xxxxxxxxx130       Invalid Test Input        [11] Attempting to map                  [11] Re-test with the latest
                                              inaccessible Cpu coreId                 version of EUD. If it still fails, file a
                                                                                      Software NVBug with log files.



    PRELIMINARY INFORMATION
    NVIDIA CONFIDENTIAL
    Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 83
                                                                           Extended Utility Diagnostic Error Codes


Error Code         Error Message             Explanation                            Next Steps
xxxxxxxxx139       Thermal Sensor Error      [11] Acceptable temperature            [11] Check the fan or thermal
                                             limits exceeded the threshold, or      sensor status.
                                             the thermal sensor is broken or is
                                             not calibrated
xxxxxxxxx149       Specific Test Not Run     [1-8] The test is already running,     [1-8] Ensure only one EUD
                                             so skip this request is skipped        instance is running.
xxxxxxxxx150       No Test Run               No tests were run                      Assign valid test IDs to run the
                                                                                    tests.
xxxxxxxxx160       Resource In Use           [1,4,6,8] No thread is created for     [1,4,6,8] Test again after the
                                             the test                               hardware resource is available.
xxxxxxxxx164       APEI Error                APEI error detected                    Check the APEI info from dmesg
                                                                                    for more details.




                                                                                    bs
xxxxxxxxx216       Device Not Found          [4,6,8] Cannot find available          [4,6,8] Check the system




                                                                                  La
                                             memory node. Try running test 8        configuration for NUMA.
                                             on the system with single NUMA




                                                 03 e
                                             node




                                               5: cl
                                             :1 ra
xxxxxxxxx220       PCI Device Not Found      [7] Cannot find PCIe device            [7] Check PCIe device installation



                                           16 al O
                                                                                    state.
xxxxxxxxx236       Memory to Memory          [4,6,8] The expected value and         [4,8] Check if DRAM hardware is
                                         28 ti
                                       1- en
                   Result Not Match          the destination memory value do        damaged.
                                             not match
                                     -1 fid


                                                                                    [6] Check if CPU caches
                                                                                    (L1/L2/L3) is damaged.
                                   25 on




xxxxxxxxx229       Hardware Was Not          [11] Init function has not been        [11] Re-test with the latest
                                 20 C




                   Initialized               called before testing                  version of EUD. If it still fails, file a
                                2 IA




                                                                                    Software NVBug with log files.
                              71 ID




xxxxxxxxx240       Hardware Error            Memory ECC errors are detected         Check if hardware is damaged.
                            09 NV
                         11 ah




xxxxxxxxx276       Hardware Status Error     [7] Mismatch between PCIe host         [7] Check PCIe device installation
                           sn




                                             & device                               state.
                                             [10] PCIe link retraining failed       [10] Check PCIe device hardware
                         Ki




                                                                                    status.
                     ik
                   R




xxxxxxxxx510       Test Cannot Run           The tests are running on a non-        Check the test HW platform.
                                             TH500 product
xxxxxxxxx612       Tegra Cfg Invalid         [11] Invalid value for                 [11] Re-test with the latest
                   Value                     configuration variables                version of EUD. If it still fails, file a
                                                                                    Software NVBug with log files.
xxxxxxxxx709       Unsupported Device        Test is not supported on this          Check the test HW platform.
                                             system
xxxxxxxxx719       Parameter Mismatch        [5] Expected system                    [5] Check the system
                                             configurations do not match            configuration.




   PRELIMINARY INFORMATION
   NVIDIA CONFIDENTIAL
   Debug and RAS Guide for NVIDIA Data Center Products                                      DA-11437-001_v13 | 84
                                                                        Extended Utility Diagnostic Error Codes


Error Code         Error Message             Explanation                         Next Steps
xxxxxxxxx773       Data Mismatch             [1] MD5 values are different        [1] Check if CPU hardware is
                                             between CPU cores                   damaged.
                                             [5] Expected system                 [5] Check the system
                                             configurations do not match         configuration.
                                             [9] Pattern data and input data     [9] Check if DRAM hardware is
                                             are different                       damaged.
xxxxxxxxx774       Tegra Test Failure        [11] Decompressed compiling         [11] Check if tarball is installed on
                                             data failed                         the system or check if CPU
                                                                                 hardware is damaged.



   5.2.1            List of Tests




                                                                                 bs
   The following list corresponds to the tests mentioned in Table 5-3.




                                                                               La
   >   [1] Compile Test




                                                 03 e
   >   [2] CPU Stress Test




                                               5: cl
                                             :1 ra
   >   [3] CPU Stress Test with Pulse Loading


                                           16 al O
   >   [4] Basic Memory Stress Test
   >   [5] Inventory Test
                                         28 ti
                                       1- en

   >   [6] CPU Cache Stress Test
                                     -1 fid


   >   [7] PCIe Link Cap Status Check Test
                                   25 on




   >   [8] Numa Memory Stress Test
                                 20 C




   >   [9] Full Memory Sweep Test
                                2 IA
                              71 ID




   >   [10] PCIe Link Retraining Test
                            09 NV




   >   [11] CPU DVFS Workload Test
                         11 ah
                           sn
                         Ki
                     ik
                   R




   PRELIMINARY INFORMATION
   NVIDIA CONFIDENTIAL
   Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 85
Chapter 6.                         ECC and Error
                                   Containment



This chapter describes the different ECC and error containment scenarios. Debug steps




                                                                            bs
are provided to triage reported ECC-related issues. If applicable, in-band and out-of-




                                                                          La
band telemetry were identified to assist partners to triage the associated error scenario.




                                              03 e
Internal data corruption in DRAM (or bit flips) can crash or cause data corruption in




                                            5: cl
                                          :1 ra
workloads. The bit flips can be caused by electrical or magnetic interference inside a


                                        16 al O
computer system. At a higher altitude, there is also a higher possibility of bit flips
through neutron ray.
                                      28 ti
                                    1- en

With Error Correction Code (ECC) memory enabled, this can correct single-bit errors and
                                  -1 fid


flag double bit errors. This is in exchange for a small amount of memory reserved for
                                25 on



ECC purposes.
                              20 C




ECC error containment in NVIDIA data center GPUs attributes errors to specific GPU
                             2 IA




processes and instances (MIG) and prevents errors from impacting other processes or
                           71 ID




instances. With row remapping, a hardware-based process to replace a faulty memory
                         09 NV




row with a spare one. No holes in physical address space are visible to any software.
                      11 ah




The following table lists different ECC error sources, GPU state, and recommended
action that should be taken by partners.
                        sn




For further information on NVIDIA GPU Memory Error Management, visit
                      Ki




https://docs.nvidia.com/deploy/a100-gpu-mem-error-mgmt/index.html.
                    ik
                R




Table 6-1.          ECC Error Containment
 Error Source                 GPU State                          Flag              Recommended Action
 Multi-bit errors             Dynamically offline affected       Row remapping     Continue running jobs on
                              memory. GPU is fully functional    pending bit       the GPU / launching new
                                                                 asserted.         jobs
 Multi-bit errors affecting   Entire GPU impacted; no new        Reset pending     Immediate GPU reset
 entire GPU                   CUDA jobs can be launched
 Multi-bit errors affecting   One MIG partition is impacted      Drain and reset   Drain work on other GPU
 selected MIG partition       and at least 1/7 GPU is not                          partitions and reset the
                              functional. Other MIG partitions                     GPU
                              continue running workloads




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 86
Chapter 7. Thermal Issues



The following sections describe the different GPU thermal issue scenarios. Debug steps
are provided to triage reported thermal issues. If applicable, in-band and out-of-band
telemetry were identified to assist partners to triage the associated error scenario.




                                                              bs
Refer to Section 12.5 “Thermal Issue” in Chapter 12 “Debug and Triage.”




                                                            La
                                              03 e
                                            5: cl
7.1              Thermal Hardware Slowdown

                                          :1 ra
                                        16 al O
Thermal failsafe controller will initiate thermal hardware slowdown when the GPU
temperature has reached the thermal slowdown temperature (TLIMIT is equal or less than
                                      28 ti
                                    1- en

-2). The GPU clock is cut in half (2x hardware slowdown) in hardware to prevent thermal
                                  -1 fid


runaway. Hardware slowdown (0x08) reason code will be generated when the NVIDIA
                                25 on



GPU Boost™ clock optimization is unable to contain the GPU temperature to within the
                              20 C




maximum operating temperature and triggers a 2x hardware slowdown to the GPU
                             2 IA




clock.
                           71 ID
                         09 NV




7.2              Thermal Hardware Shutdown and
                      11 ah




                 OVERT Event
                        sn
                      Ki
                  ik




When a GPU over temperature event occurs, a corresponding THERM_OVERT signal will
                R




be asserted to alert the user of the over-temperature condition. The THERM_OVERT is a
signal driven by the onboard FPGA to notify BMC of the thermal event. System BMC
should check which device has exceeded its maximum temperature by using “SMBPBI
Opcode B0H – Get OVERT Info” and log the information. Once the OVERT reason has
been logged, system BMC is expected to shut off power to the baseboard within 1
second of the interrupt assertion to avoid component damage.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 87
                                                                             Thermal Issues



7.3              Thermal Issue Caused by TIM and
                 Thermal Solutions for Partner Cooled
                 SKUs
When a partner cooled GPU over temperature event occurs, partners are advised to
inspect and review their TIM and thermal solutions installation. Partners are advised to
review their die pressure and TIM specifications for the specific GPU products. For
NVIDIA HGX products, partners can use the “HGX Thermal Solutions Checklist” to verify
the NVIDIA specifications against their TIM and thermal solutions.




                                                               bs
                                                             La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                   DA-11437-001_v13 | 88
Chapter 8. System Power Checks



The following sections describe the different GPU power issue scenarios. Debug steps
are provided to triage reported power issues. If applicable, in-band and out-of-band
telemetry were identified to assist partners to triage the associated error scenario.




                                                              bs
                                                            La
8.1              Unable to Reach Maximum TGP



                                              03 e
                                            5: cl
                                          :1 ra
If the GPU is unable to reach the maximum TGP defined for the product, users can use

                                        16 al O
the NVSMI utility to check both the enforced power limit for the GPU:
                                      28 ti
                                    1- en
nvidia-smi -q -d POWER
                                  -1 fid


The enforced power limit for the GPU should match the default power limit. If the
                                25 on




enforced power limit is lower than the default power limit, the GPU is considered power
                              20 C




capped and therefore will not be allowed to reach the maximum TGP. Users can reset
                             2 IA




the enforced power limit to the default power limit by using the NVSMI utility:
                           71 ID
                         09 NV




nvidia-smi -pl [power limit]
                      11 ah
                        sn




8.2              Unable to Reach Maximum GPU
                      Ki
                  ik




                 Clocks
                R




If the GPU is unable to reach the maximum GPU clocks defined for the product, users
can use the NVSMI utility to check both the application clock limits for the GPU:

nvidia-smi -q -d CLOCK


If the maximum clocks are lower than the maximum clocks allowed for the product,
users can reset the clock by using the NVSMI utility:

nvidia-smi -rgc



Furthermore, if Programmable EDP was reduced by user, this may also limit the
maximum clocks that the product is able to reach. To check and to reset the current

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 89
                                                                                  System Power Checks


Programmable EDP setting, user can either access through the SMBPBI or NVFlash
utility. In addition, on the NVIDIA Hopper HGX 8-GPU, Redfish can also be used to get
and to set the EDPp scaling factor.


8.2.1            Redfish for Programmable EDPp
The Redfish for Programmable EDPp can be used to get and to set the Programmable
EDP set point. This command allows users to query and control the programmable EDPp
thresholds by specifying a percentage scaling value. This can be used to program an
EDPp limit without necessarily lowering the current TGP limit. IP address and exact
Redfish may be different from the following examples.
# To read back current value “EDPpPercent” curl -X GET
http://192.168.31.1/redfish/v1/Systems/HGX_Baseboard_0/Processors/GPU_SXM_1/EnvironmentMetrics




                                                                         bs
                                                                       La
# To set programmable EDP to 100% curl -X PATCH




                                              03 e
http://192.168.31.1/redfish/v1/Systems/HGX_Baseboard_0/Processors/GPU_SXM_1/EnvironmentMetrics -d




                                            5: cl
'{ "Oem": { "Nvidia": {"EDPpPercent": { "SetPoint": 100} } } }'




                                          :1 ra
8.2.2                                   16 al O
                 SMBPBI for Programmable EDPp
                                      28 ti
                                    1- en

The Programmable EDPp can be set using an OOB channel SMBPBI protocol. This
                                  -1 fid


command allows users to query and control the programmable EDPp thresholds by
                                25 on




specifying a percentage scaling value. This can be used to program an EDPp limit
                              20 C




without necessarily lowering the current TGP limit.
                             2 IA
                           71 ID




Table 8-1.          SMBPBI for Programmable EDPp Commands
                         09 NV




 Specification              Value
                      11 ah




 Opcode                     10h – Submit/Poll Asynchronous Request
                        sn




 Arg1                       11h – Get/Set Programmable EDPp scaling factor
                      Ki




 Arg2                       Refer to the NVIDIA SMBus Post-Box interface for GPUs NVOnline: 1001187
                  ik
                R




8.2.3            NVFlash for Programmable EDPp
NVFlash can be used to change the programmable EDPp scaling factor using the
following set of commands. The following example shows how to configure power policy
limits for GPU0. The change through NVFlash is persistent across reboots.
To change the programmable EDPp scaling factor, progMultRated setting for the TGP
power policy must be specified as a percentage in decimal format.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                              DA-11437-001_v13 | 90
                                                                   System Power Checks


To add a power policy limit in milliwatts:
/> ./nvflash --addpp TGP progMultRated <value>

Where <value> is,
    value = 0.9 for 10% reduction in EDP
    value = 0.7 for 30% reduction in EDP


To delete a power policy limit for programmable EDPp:
/> ./nvflash --delpp TGP progMultRated




8.3              Checking Power Brake




                                                            bs
Power brake is used to reduce peak and continuous power draw during emergency




                                                          La
situations by reducing NVSwitch bandwidth to 1/4 and GPU clock to 25% of normal
clock. Power brake can be asserted by using an external signal PWR_BRAKE_N or through




                                              03 e
                                            5: cl
the baseboard FPGA. If the GPU or NVSwitch is unable to reach the target clock or




                                          :1 ra
bandwidth, partners should confirm if Power Brake status is asserted using SMBPBI


                                        16 al O
Opcode 0xF5 “Get Power Brake State” by reviewing the clock throttle reason 0x80 “HW
Power Brake Slowdown.” Or in-band with nvidia-smi -q for the “HW Power Brake
                                      28 ti
                                    1- en
Slowdown” field.
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                DA-11437-001_v13 | 91
         Chapter 9.                          PCI Express Hardware
                                             Error and GPU Falling off
                                             the Bus Scenarios




                                                                                        bs
                                                                                      La
         The following table shows the different “PCIe Hardware Error” scenarios. Available in-




                                                       03 e
         band and out-of-band telemetry can be used to correlate the PCIe error report with an




                                                     5: cl
         error scenario. Depending on the specific error scenario, the SMBPBI server may not be




                                                   :1 ra
         operational or may be partially available.

                                                 16 al O
                                               28 ti
Table 9-1.         PCIe Error Scenarios
                                             1- en
                                           -1 fid


                                   SMBPBI
                                         25 on



 Error Scenario                    Server State   In-Band Telemetry                     Out-of-Band Telemetry
                                       20 C




 PCIe Surprise Link Down           Server not     Link status of DSP of PCIe Switch    Link status of the PCIe Retimer
                                      2 IA




 (SLD) without Downstream          operational    connected to GPU                     connected to the GPU (Instructions
                                    71 ID




 Port Containment (DPC)                           Link status of the PCIe Retimer      in Section 14.1 “Checking PCIe
                                                                                       Retimer Link Status Corresponding
                                  09 NV




 This case covers multiple                        connected to the GPU
 error scenarios related to                                                            to SXM”)
                                                  PCIe AER message for SLD in
                               11 ah




 SXM VR/Cap fault that                            dmesg log                            PCIe SLD event logged in BMC
 causes the GPU to shut
                                 sn




                                                  XID 79 message in dmesg log
 down
                               Ki




 PCIe Link Down due to             Server not     Link status of DSP of PCIe Switch    Link status of the PCIe Retimer
                              ik




 Downstream Port                   operational    connected to GPU                     connected to the GPU (Instructions
                         R




 Containment (if enabled)                         Link status of the PCIe Retimer      in Section 14.1 “Checking PCIe
                                                  connected to the GPU                 Retimer Link Status Corresponding
                                                                                       to SXM”)
                                                  PCIe DPC message in dmesg log
                                                                                       PCIe DPC event logged in BMC
                                                  XID 79 message in dmesg log
                                                                                       System Event Log (SEL)
                                                                                       GPU PCIe Correctable and
                                                                                       Uncorrectable Error Count logged in
                                                                                       BMC System Event Log (if applicable)
 GPU shutdown due to               Server not     Link status of DSP of PCIe Switch    Link status of the PCIe Retimer
 THERM_OVERT                       operational    connected to GPU                     connected to the GPU (Instructions
                                                  Link status of the PCIe Retimer      in Section 14.1 “Checking PCIe
                                                  connected to the GPU                 Retimer Link Status Corresponding
                                                                                       to SXM”)
                                                  XID 79 message in dmesg log



         PRELIMINARY INFORMATION
         NVIDIA CONFIDENTIAL
         Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 92
                                                  PCI Express Hardware Error and GPU Falling off the Bus Scenarios


                               SMBPBI
Error Scenario                 Server State     In-Band Telemetry                     Out-of-Band Telemetry
                                                                                      THERM_OVERT event in BMC System
                                                                                      Event Log (SEL)
                                                                                      SXM THERM_OVERT status
                                                                                      (Instructions in Section 14.1
                                                                                      “Checking PCIe Retimer Link Status
                                                                                      Corresponding to SXM”)
GPU shutdown for unknown       Server not       Link status of DSP of PCIe Switch     Read SXM presence, power good and
reason                         operational      connected to GPU                      reset status (Instructions in Section
                                                Link status of the PCIe Retimer       14.2 “Checking for SXM PWR_GOOD
                                                connected to the GPU                  Status”)

                                                XID 79 message in dmesg log          Link status of the PCIe Retimer
                                                                                     connected to the GPU (Instructions




                                                                                      bs
                                                                                     in Section 14.1 “Checking PCIe




                                                                                    La
                                                                                     Retimer Link Status Corresponding
                                                                                     to SXM”)




                                                     03 e
                                                   5: cl
                                                                                     FPGA register table dump




                                                 :1 ra
                                                                                     (Instructions in Section 14.5



                                               16 al O
                                                                                     “Downloading FPGA Register Table”)
                                                                                     ERoT logs (Instructions in Section
                                             28 ti
                                                                                     14.6 “Downloading ERoT Logs”)
                                           1- en

                                                                                     PCIe Retimer LTSSM logs
                                         -1 fid


                                                                                     (Instructions in Section 14.7
                                       25 on



                                                                                     “Downloading PCIe Retimer LTSSM
                                     20 C




                                                                                     Log”)
                                    2 IA




GPU VR issue                   Server not       Link status of DSP of PCIe Switch    HMC Event for GPU Power Good
                                  71 ID




                               operational      connected to GPU                     state change/fault (Instructions in
                                09 NV




                                                Link status of the PCIe Retimer      Section 14.2 “Checking for SXM
                                                connected to the GPU                 PWR_GOOD Status”)
                             11 ah




                                                XID 79 message in dmesg log (if      Host BMC System Event Log (SEL)
                               sn




                                                MPS issue was triggered at           with I2C1_ALERT triggered and
                                                                                     pointing to abnormal PWR_GOOD
                             Ki




                                                runtime)
                                                                                     state change (This alert will not be
                         ik




                                                                                     cleared until power good is achieved).
                       R




                                                                                     Link status of the PCIe Retimer
                                                                                     connected to the GPU (Instructions
                                                                                     in Section 14.1 “Checking PCIe
                                                                                     Retimer Link Status Corresponding
                                                                                     to SXM”).
                                                                                     Check for SXM PWR_GOOD status
                                                                                     (Instructions in Section 14.2
                                                                                     “Checking for SXM PWR_GOOD
                                                                                     Status”)
GPU in recovery mode           Server not       PCIe sub-system device ID changes     Link status of the PCIe Retimer
                               operational      when the GPU goes into recovery       connected to the GPU (Instructions
                                                mode                                  in Section 14.1 “Checking PCIe
                                                DEVICE_ID in recovery mode is         Retimer Link Status Corresponding
                                                0x2300                                to SXM”)



       PRELIMINARY INFORMATION
       NVIDIA CONFIDENTIAL
       Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 93
                                                   PCI Express Hardware Error and GPU Falling off the Bus Scenarios


                                 SMBPBI
Error Scenario                   Server State     In-Band Telemetry                      Out-of-Band Telemetry
                                                  FLR, MSI-X, and SR-IOV capabilities    SPDM Index 43 provides information
                                                  are disabled and not advertised in     regarding to AP Boot Status, which
                                                  the PCIe Capabilities Register         can be used to determine AP state.
ERoT fault                       Server not       Host OS will not be able to discover   Check for ERoT Fatal Error
                                 operational      any GPU and no XID will be reported    (Instructions in Section 14.4
                                                                                         “Checking for ERoT Fatal Error
                                                                                         Status”)
                                                                                         Check for SXM PWR_GOOD status
                                                                                         (Instructions in Section 14.2
                                                                                         “Checking for SXM PWR_GOOD
                                                                                         Status”)
                                                                                         Link status of the PCIe Retimer




                                                                                         bs
                                                                                         connected to the GPU (Instructions




                                                                                       La
                                                                                         in Section 14.1 “Checking PCIe
                                                                                         Retimer Link Status Corresponding




                                                      03 e
                                                                                         to SXM”)




                                                    5: cl
                                                  :1 ra
ERoT keeping GPU in reset        Server not       Host OS will not be able to            Check for ERoT Fatal Error



                                                16 al O
state                            operational      discovery any GPU and no XID will      (Instructions in Section 14.4
                                                  be reported                            “Checking for ERoT Fatal Error
                                              28 ti
                                                                                         Status”)
                                            1- en

                                                                                         SPDM Index 43 provides information
                                          -1 fid


                                                                                         regarding to AP Boot Status, which
                                        25 on



                                                                                         can be used to determine AP state.
                                      20 C




                                                                                         ERoT logs (Instructions in Section
                                     2 IA




                                                                                         14.6 “Downloading ERoT Logs”)
                                   71 ID




                                                                                         FPGA register table dump
                                 09 NV




                                                                                         (Instructions in the “Downloading
                                                                                         FPGA Register Table” section)
                              11 ah




Retimer failures                 SMBPBI may       If the failure happens at runtime:     PCIe Retimer LTSSM logs
                                sn




                                 be operational   XID 79 message in dmesg log            (Instructions in Section 14.7
                                                                                         “Downloading PCIe Retimer LTSSM
                              Ki




                                                  PCIe AER message in dmesg log
                                                                                         Log”)
                            ik




                                                  If the failure happens at boot time:
                                                                                         GPU PCIe Correctable and
                        R




                                                  Host OS will not be able to discover   Uncorrectable Error Count logged in
                                                  any GPU and no XID will be reported    BMC System Event Log (if applicable)
                                                  nvidia-bug-report to capture host
                                                  OS state




        PRELIMINARY INFORMATION
        NVIDIA CONFIDENTIAL
        Debug and RAS Guide for NVIDIA Data Center Products                                   DA-11437-001_v13 | 94
Chapter 10. NVLink Error Scenarios



The following table shows the different “NVLink Hardware Error” scenarios. Available in-
band and out-of-band telemetry can be used to correlate the XID error report with an
error scenario. “NVLink Error” can be caused by NVLink initialization faults, incorrect




                                                                              bs
software configuration, unexpected internal hardware faults, and poor signal quality on




                                                                            La
NVLink.




                                               03 e
For further information on NVLink health monitoring, refer to the NVIDIA NVLink Health




                                             5: cl
Monitoring Application Note (NVOnline: 1087258).




                                           :1 ra
                                         16 al O
        Note: Content within this chapter is mainly applicable to NVIDIA systems using NVLink4
                                       28 ti
        and older generations of NVLink.
                                     1- en
                                   -1 fid
                                 25 on




Table 10-1.         NVLink Error Debug and Triage Scenarios
                               20 C
                              2 IA




 Error Scenario                    In-Band Telemetry                        Out-of-Band Telemetry
                            71 ID




 NVLink Initialization Fault       “NVLink: Failed to train link # to       NVLink state through SMBPBI
                          09 NV




                                   remote PCI:B.D.F” message in dmesg
                                   log.
                       11 ah




                                   NVLink state using NVSMI/DCGM
                         sn




                                   Inspect kernel logs for any system
                       Ki




                                   errors before NVLink initialization
                   ik




                                   failure.
                R




 Incorrect Software                “NVLink MINION: link # interrupts        NVLink state through SMBPBI
 Configuration                     disabled due to fatal MINON error”
                                   message in dmesg log.
                                   NVLink state using NVSMI/DCGM
                                   Inspect kernel logs for any system
                                   errors before XID 74 error message.
 Unexpected Internal               “NVLink: fatal error detect on link #”   NVLink state through SMBPBI
 Hardware Fault                    message in dmesg log.                    NVLink Flit CRC, Replay, Recovery
                                   NVLink state using NVSMI/DCGM            and CRC error counters via
                                   NVLink Flit CRC, Replay, Recovery, and   SMBPBI.
                                   CRC error counters using
                                   NVSMI/DCGM.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 95
                                                                                      NVLink Error Scenarios


 Error Scenario                    In-Band Telemetry                         Out-of-Band Telemetry
                                   Inspect kernel logs for any system
                                   errors before SXID and XID error
                                   messages.
 Poor Signal Quality               SXID and XID error message in dmesg       NVLink state through SMBPBI
                                   log.                                      NVLink Flit CRC, Replay, Recovery
                                   NVLink Flit CRC, Replay, Recovery, and    and CRC error counters via
                                   error counters using NVSMI/DCGM           SMBPBI.
                                   NVLink state using NVSMI/DCGM
 NVLink ECC Correction             Drivers provide ECC correction counts     NVLink state through SMBPBI
                                   across each NVLink lane. ECC is a         NVLink Flit CRC, Replay, Recovery
                                   transparent BER correction scheme         and Data CRC error counters via
                                   that has no impact on performance.        SMBPBI.
                                   The information contained within




                                                                               bs
                                   these registers are for informational




                                                                             La
                                   purposes only, and high counts within
                                   these registers do not suggest a link




                                               03 e
                                             5: cl
                                   issue, as any data that escapes ECC




                                           :1 ra
                                   will get flagged as FLIT CRC.



                                         16 al O
                                   NVLink devices that exhibit an
                                   excessively high rate of ECC correction
                                       28 ti
                                   will trigger an SXID 20009 in dmesg.
                                     1- en

                                   When encountering this non-fatal
                                   -1 fid


                                   SXID, partner is advised to run
                                 25 on



                                   additional diagnostic tests (GPU Field
                               20 C




                                   Diagnostic) to determine if there is an
                                   underlying hardware problem.
                              2 IA
                            71 ID
                          09 NV
                       11 ah
                         sn
                       Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                   DA-11437-001_v13 | 96
Chapter 11. Checking NVLink State
            with In-Band and Out-of-
            Band Tools




                                                                      bs
                                                                    La
This chapter provides partners and customers instructions on how to obtain the in-band




                                              03 e
telemetry using NVSMI and DCGM commands. The NVLink telemetry can be used to




                                            5: cl
assist in the analysis and triage of XID and SXID error scenarios described in the




                                          :1 ra
previous chapter.

                                        16 al O
                                      28 ti
        Note: Content within this chapter is mainly applicable to NVIDIA systems using NVLink4
                                    1- en

        and older generations of NVLink.
                                  -1 fid
                                25 on
                              20 C
                             2 IA




11.1             Checking for NVLink State
                           71 ID
                         09 NV




The following NVSMI and DCGM command can be used to check the NVLink state
status. The NVLink status information can be used for further analysis of NVLink related
                      11 ah




error scenarios.
                        sn
                      Ki




11.1.1           NVSMI
                  ik
                R




1. User can run the following command to check the NVLink state.
    nvidia-smi nvlink -s

2. Checking return status:
    GPU<#>: NVIDIA Graphics Device (UUID: <GPU # UUID>)
    Link<#>: <Link speed GB/s>

If NVLink is up, the maximum link speed will be reported.
If the link is down, the link speed will be reported as inactive.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                         DA-11437-001_v13 | 97
                                                  Checking NVLink State with In-Band and Out-of-Band Tools



11.1.2           DCGM
1. User can run the following command to check the NVLink state.
    dcgmi nvlink --link-status

2. Checking return status:
    +----------------------+
    | NvLink Link Status |
    +----------------------+
    GPUs:
        gpuId <X>:
            <U or D for each link>
    Key: Up=U, Down=D, Disabled=X, Not Supported=_




                                                                           bs
11.1.3           SMBPBI for NVLink State Status




                                                                         La
The following SMBPBI opcode can be used to check the NVLink state status. The NVLink




                                              03 e
                                            5: cl
status information can be used for further analysis of NVLink related error scenarios.




                                          :1 ra
                                        16 al O
Query NVLink Information:
Opcode = 0x1A
                                      28 ti
Arg1 = 0x01
                                    1- en
                                  -1 fid


Return:
                                25 on




Bitmap of the first 32 NVLink states, where each bit encodes the state of the corresponding NVLink.
                              20 C




0 – NVLink is down
                             2 IA




1 – NVLink is up
                           71 ID
                         09 NV




Opcode 0x1A in the command corresponds to the SMBPBI Opcode 1Ah “QUERY NVLINK
INFORMATION.” Full details of this SMBPBI Opcode 1Ah can be referenced from the
                      11 ah




SMBus Post Box Interface (SMBPBI) For GPUs Application Note (NVOnline: 1001187).
                        sn
                      Ki




11.1.4           Checking for NVLink Error Counters
                  ik
                R




The following NVSMI and DCGM commands can be used to check the NVLink error
counters, including:
>   NVLink Replay Error status
>   Recovery Error status
>   Flit CRC Error status
The NVLink error counters information can be used for further analysis of NVLink
related error scenarios.


11.1.5           NVSMI
User can run the following command to check the NVLink error counters.
nvidia-smi nvlink -e

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 98
                                                  Checking NVLink State with In-Band and Out-of-Band Tools



11.1.6           NVML API
User can the follow NVML API to check the NVLink error counters.
nvmlDeviceGetNvLinkErrorCounter



11.1.7           SMBPBI for NVLink Error Counters
The following SMBPBI opcode can be used to check the NVLink error counters. The
NVLink error counters information can be used for further analysis of NVLink related
error scenarios.

Query NVLink Information:
Opcode = 0x1A
Arg1 =




                                                                           bs
0x03 (NVLink Replay Error Count)




                                                                         La
0x04 (NVLink Recovery Error Count)




                                              03 e
0x05 (NVLink Flit CRC Error Count)




                                            5: cl
                                          :1 ra
Arg2 = NVLink Index (NVLink Index = 0xFF will provide aggregate error count of all links)

Return:
                                        16 al O
                                      28 ti
                                    1- en

Error count for the provided NVLink Index in Arg2
                                  -1 fid
                                25 on




Opcode 0x1A in the command corresponds to the SMBPBI Opcode 1Ah “QUERY NVLINK
                              20 C




INFORMATION.” Full details of this SMBPBI Opcode 1Ah can be referenced from the
                             2 IA




SMBus Post Box Interface (SMBPBI) For GPUs Application Note (NVOnline: 1001187).
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 99
Chapter 12. Debug and Triage



The following sections describe the triage checklist for baseboard, GPU, and NVSwitch
errors. In addition, this triage checklist provides further guidance on additional telemetry
and debug logs, which must be captured for firmware update, PCIe enumeration and




                                                                 bs
booting, thermal, NVQual, and Field Diag issues.




                                                               La
                                              03 e
                                            5: cl
12.1             Baseboard Debug

                                          :1 ra
                                        16 al O
When gathering and reporting an NVIDIA HGX baseboard issue, customers and partners
are required to follow the triage checklist and provide relevant debug information as
                                      28 ti
                                    1- en

follows (in addition to the standard issue reporting and logging guidelines):
                                  -1 fid


>   Summary of the issue and the number of devices impacted (GPU, NVSwitch, FPGA,
                                25 on




    ERoT, and HMC).
                              20 C




>   Describe whether the issue is isolated to a specific device and slot.
                             2 IA




>   Provide information on the number of baseboards and components affected.
                           71 ID




>   Can the system or device recover after a power cycle or reset.
                         09 NV




>   Provide the last known state of the system before failure (for example, was the
                      11 ah




    system running a specific workload or application).
                        sn




>   Provides all firmware versions being used (GPU, NVSwitch, FPGA, ERoT, and HMC).
                      Ki




>   List all software versions being used (example: NVIDIA GPU driver, fabric manager,
                  ik




    NVIDIA® CUDA®, and DCGM).
                R




>   Provides relevant debug logs from Field Diag.
>   Software and firmware versions installed on the platform, including FRU information.
>   Detailed steps on reproduction of the hardware error or issue.
>   Frequency of the production and information regarding whether the issue reported
    is an isolated issue or affecting multiple systems.
>   Hardware sample version (for example. ES, QS, PS, or other sample type).




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                    DA-11437-001_v13 | 100
                                                                           Debug and Triage



12.2             Out-of-Band Debug
The following list provides detailed out-of-band telemetry to be captured when
baseboard, GPU, or NVSwitch error occurs. Customers and partners are required to
provide relevant debug information as follows (in addition to the standard issue
reporting and logging guidelines):
>   Confirm if out-of-band communication is functional for baseboard, GPU, NVSwitch,
    and FPGA.
>   Capture GPU SMBPBI Opcodes
    •   02H – Get Temperature
    •   F1H – Get Power Supply Status
    •   F3H – Get PCIe Reset Status




                                                               bs
>   Capture FPGA and Baseboard Devices SMBPBI Opcodes




                                                             La
    •   02H – Get Temperature




                                              03 e
    •   04H – Get Power




                                            5: cl
                                          :1 ra
    •   B0H – Get OVERT Information


                                        16 al O
    •   B1H – Get I2C-1 GPU Interrupt Information
        B2H – Get I2C-2 Onboard Device Interrupt Information
                                      28 ti
    •
                                    1- en

    •   B3H – Get HSC Device Alert Information
                                  -1 fid


    •   B5H – Get Clock Output Enable Status
                                25 on




    •   BBH – Get GPU Presence and Power Status
                              20 C




        F1H – Get Power Supply Status
                             2 IA




    •
                           71 ID




    •   F2H – Assert/De-assert Device PCIe Fundamental Reset State
                         09 NV




    •   F3H – Get PCIe Reset Status
>   Capture NVSwitch SMBPBI Opcodes
                      11 ah
                        sn




    •   02H – Get Temperature
                      Ki




    •   18H – Query Miscellaneous NVSwitch State Flags
                  ik




    •   21H – Query PCIe Link Status and Error Counts
                R




12.3             Firmware Update Issue
When gathering and reporting a firmware update issue, customers and partners are
required to follow the triage checklist and provide relevant debug information as follows
(in addition to the standard issue reporting and logging guidelines):
>   Ensure firmware write-protection and BMC polling are disabled.
>   Provide NVFlash, HMC, or ERoT firmware update logs.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 101
                                                                            Debug and Triage



12.4             PCIe Enumeration and Non-Booting
                 Issue
When gathering and reporting a PCIe enumeration and non-booting issue, customers
and partners are required to follow the triage checklist and provide relevant debug
information as follows (in addition to the standard issue reporting and logging
guidelines):
>   Confirm ERoT has successfully booted and provide relevant ERoT logs if there is an
    ERoT boot failure.
>   Provide partner’s power-up sequence measurements and verify that power-on
    sequencing steps are being adhered.
>   Verify all power rail status and reference clock status.




                                                                 bs
>   Verify PCIe reset and enumeration sequencing steps are being adhered.




                                                               La
>   Confirm any component and connector damage to the baseboard and SXMs.




                                              03 e
                                            5: cl
>   Verify PCIe link status in upstream retimer components and PCIe switches.




                                          :1 ra
12.5             Thermal Issue          16 al O
                                      28 ti
                                    1- en
                                  -1 fid


When gathering and reporting a thermal issue, customers and partners are required to
                                25 on



follow the triage checklist and provide relevant debug information as follows (in addition
                              20 C




to the standard issue reporting and logging guidelines):
                             2 IA




>   Review GPU clock event reason, if any. For a complete list of “Clock Event Reason
                           71 ID




    Codes and Description,” refer to the NVIDIA GPU Boost Overview for Data Center
                         09 NV




    Products (NVOnline: 1100183).
>   0x08 HW Slowdown
                      11 ah
                        sn




>   0x40 HW Thermal Shutdown
                      Ki




>   0x80 HW Power Brake Slowdown
                  ik




>   0x20 Clock Optimized for Thermal (previously noted as SW Thermal Slowdown).
                R




>   Provide details on which components were impacted by the thermal issue.
>   Provide and confirm if OVERT is triggered (SMBPBI Opcode B0H).
>   Confirm and inspect if heat sink and cooling solutions are installed, seated, and
    operated correctly. Particularly if “HW Slowdown,” “Thermal Shutdown,” “Power
    Brake,” or “SW Thermal Slowdown” events have occurred.
>   Confirm and review thermal interface material (TIM) used and installation steps for
    partner cooled product SKUs.
>   Provide details on the operating environment at the time of failure.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                   DA-11437-001_v13 | 102
Chapter 13. Issue Reporting Guidelines



The following sections describe the standard issue reporting and telemetry logging
guidelines. When customers and partners report an issue, the following platform
information and telemetry logging information described in this section should be




                                                               bs
provided to NVIDIA.




                                                             La
                                              03 e
                                            5: cl
13.1             Hardware and Software Platform

                                          :1 ra
                                        16 al O
                 Information          28 ti
                                    1- en

When gathering and reporting a hardware issue, customers and partners are required to
                                  -1 fid


provide the following information regarding the platform:
                                25 on




>   Software and firmware versions installed on the platform, including FRU information.
                              20 C




>   Detailed steps on reproduction of the hardware error or issue.
                             2 IA




>   Frequency of the production and information regarding whether the issue reported
                           71 ID




    is an isolated issue or affecting multiple systems.
                         09 NV




>   Hardware sample version (for example. ES, QS, PS, or other sample type).
                      11 ah
                        sn




13.2             NVDebug for Datacenter Products
                      Ki
                  ik
                R




The NVIDIA NVDebug tool can be deployed on management or head servers in GB NVL
systems and other NVIDIA data center products. In GB NVL systems, the tool
implements a wrapper to aggregate compute, NVSwitch, and BMC logs across racks in
the Data Center. It provides an easy-to-use, customizable, and scalable approach to
collecting necessary logs across multiple racks and complex array of subcomponents. In
cases where a focused investigation is needed on a subset of nodes in GB NVL or other
NVIDIA rack systems, the tool can be used to retrieve the necessary logs from the same
nodes of interest.
Customers are strongly encouraged to collect NVDebug logs and attaching the same to
NVBugs while reaching out to NVIDIA for support.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 103
                                                                     Issue Reporting Guidelines


Figure 13-1         NVDebug Tool in GB NVL Systems Overview




                                                                bs
                                                              La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah




For further information, please refer to NVOnline: 1109504 NVIDIA Debug Tool for
                        sn




Datacenter Products (NVDebug). The NVDebug Tool User’s Guide is included in the
                      Ki




package under the same posting.
                  ik
                R




13.2.1           Collecting Rack-level Logs in GB NVL Systems
The NVDebug tool can be used to collect logs from all the trays of the GB200 NVL rack.
The tool supports and performs the full rack-level log collection simultaneously from
each Compute Node and NVSwitch node.
To collect the full GB200 NVL rack log collection, please use the following steps:
1. Create a separate Compute Node config.yaml and separate NVSwitch node
   nvswitch_config.yaml file from NVDebug package.
2. Update the PLATFORM parameter in the Compute Node config to arm64 and in the
   Switch Tray config to NVSwitch.
3. Make other modifications as needed based on the NVDebug Tool User’s Guide.


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                    DA-11437-001_v13 | 104
                                                                  Issue Reporting Guidelines


    Here is an example of the config guide for the Switch Node (nvswitch_config.yaml).




    Here is an example of the config file for the Compute Node (compute_config.yaml).




                                                              bs
                                                            La
                                              03 e
4. Update and create a DUT object for each compute and Switch node in the




                                            5: cl
                                          :1 ra
   dut_config.yaml file with DUT specific IP and access credentials.


                                        16 al O
5. For the compute nodes, set the NodeType to Compute and the ConfigFileToUse as
   the Compute Tray config file.
                                      28 ti
                                    1- en
6. For the NVSwitch node, set the NodeType to SwitchTray and ConfigFileToUse as the
                                  -1 fid


   Switch Tray config.
                                25 on




    Here is an example with two compute nodes and one switch node.
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                 DA-11437-001_v13 | 105
                                                                          Issue Reporting Guidelines


7. Run NVDebug without specifying the credentials or the platform because this
   information will be picked up from the config files.
        $ ./nvdebug
        Multiple DUTs found. Ignoring CLI DUT details
        Log directory created at /tmp/nvdebug_logs_02_10_2024_14_33_05
        Starting collection for DUT gb200-compute-tray-1
        Starting collection for DUT gb200-compute-tray-2
        Starting collection for DUT gb200-switch-tray-1
        gb200-switch-tray-1: [14:33:06] Unknown platform. User provided platform type: NVSwitch
        gb200-switch-tray-1: [14:33:06] BMC IP: None
        Log collection has started for gb200-switch-tray-1
        gb200-compute-tray-2: [14:33:07] Identified system as Model: P3809, Partno: 699-13809-0404-
        600, Serialno:1583124820340
        gb200-compute-tray-2: [14:33:07] User provided platform type: arm64
        gb200-compute-tray-2: [14:33:07] BMC IP: XXXX




                                                                     bs
        Log collection has started for gb200-compute-tray-2




                                                                   La
        gb200-compute-tray-1: [14:33:08] Identified system as Model: P3809, Partno: 699-13809-0404-




                                               03 e
        600, Serialno:1583124820254




                                             5: cl
        gb200-compute-tray-1: [14:33:08] User provided platform type: arm64




                                           :1 ra
        gb200-compute-tray-1: [14:33:08] BMC IP: XXXX


                                         16 al O
        Log collection has started for gb200-compute-tray-1
        gb200-switch-tray-1: [14:37:11] Log collection is now complete
                                       28 ti
                                     1- en
        gb200-switch-tray-1: [14:37:11] Log collection took 4m 5.34s
                                   -1 fid


        gb200-compute-tray-1: [14:40:19] Log collection is now complete
        gb200-compute-tray-1: [14:40:19] Log collection took 7m 11.21s
                                 25 on




        DUT gb200-compute-tray-1 completed.
                               20 C




        gb200-compute-tray-2: [14:40:20] Log collection is now complete
                              2 IA




        gb200-compute-tray-2: [14:40:20] Log collection took 7m 12.77s
                            71 ID




        DUT gb200-compute-tray-2 completed.
                          09 NV




        DUT gb200-switch-tray-1 completed.
                       11 ah
                         sn




    A log zip file is created at /tmp/nvdebug_logs_02_10_2024_14_33_05.zip. The
                       Ki




    log output will have a subfolder for each DUT that was specified in the dut_config
    file.
                   ik
                 R




13.3              System Event Logs and Telemetry
                  Logging
In addition to providing NVIDIA the hardware and software platform information when
an issue occurs, customers and partners are required to following the set of standard
telemetry and logs to NVIDIA:
>   Host OS logs
    •     lspci logs
    •     Kernel dmesg syslog
    •     Fabric manager log

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                         DA-11437-001_v13 | 106
                                                                   Issue Reporting Guidelines


    •   BMC system event log
>   nvidia-bugs-report and nvidia-smi -q logs
>   Field Diag logs
>   Device dumps through Redfish or I2C (FPGA, ERoT, and HMC).
>   Device dumps through Redfish (Retimer).
>   Log collection through Redfish or I2C (Self-test, LTSSM, HW Info, FW Inventory, and
    Health Check).
>   Baseboard telemetry logging through SMBPBI.
    •   Power good and voltage regulators status
    •   Reference clock status
    •   SXM presence status
        Device interrupts




                                                              bs
    •




                                                            La
    •   Thermal alerts
>   GPU telemetry logging through SMBPBI.




                                              03 e
                                            5: cl
    •   PCIe recovery counter




                                          :1 ra
                                        16 al O
    •   PCIe correctable and uncorrectable error counters
    •   PCIe NAK received and sent counter
                                      28 ti
                                    1- en
    •   PCIe equalization parameters
                                  -1 fid


>   NVSwitch telemetry logging through SMBPBI.
                                25 on




    •   PCIe recovery counter
                              20 C




    •   PCIe correctable and uncorrectable error counters
                             2 IA




    •   PCIe NAK received and sent counter
                           71 ID




    •   PCIe equalization parameters
                         09 NV




>   Retimer telemetry logging through SMBPBI.
                      11 ah




>   PCIe equalization parameters
                        sn




For best practices on reporting issue through NVOnline, refer to NVOnline Partner Portal
                      Ki




Guidelines (NVOnline: 1106532).
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 107
Chapter 14. Out-of-Band Telemetry
            through Redfish



This chapter provides partners and customers with instructions on how to obtain out-of-




                                                                  bs
band telemetry using HMC and Redfish commands. The out-of-band telemetry can




                                                                La
assist in the analysis and triage of XID and SXID error scenarios described in the




                                              03 e
previous section.




                                            5: cl
                                          :1 ra
                                        16 al O
14.1             Checking PCIe Retimer Link Status
                                      28 ti
                                    1- en

                 Corresponding to SXM
                                  -1 fid
                                25 on




The following Redfish command can be used to obtain the PCIe Retimer Link Status
                              20 C




from each of the eight SXMs from the HMC:
                             2 IA
                           71 ID




curl
                         09 NV




http://192.168.31.1/redfish/v1/Fabrics/HGX_PCIeRetimerTopology_[0-7]/Switches/PCIeRetimer_[0-
7]/Ports/DOWN_0
                      11 ah




The output would indicate if the PCIe Link Status, for example, an ActiveWidth=0 and
                        sn




CurrentSpeedGbps=0 would indicate the PCIe Link Down status:
                      Ki
                  ik




“ActiveWidth”:0
                R




“CurrentSpeedGbps”:0


Figure 14-1 shows a full example output of the PCIe Retimer Link Status from HMC. The
example shows that the current retimer link status is operational and running at PCIe
x16 at Gen5 speed.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 108
                                                           Out-of-Band Telemetry through Redfish


Figure 14-1.        Output of PCIe Retimer Link Status through Redfish Example




                                                                  bs
                                                                La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en

14.2             Checking for SXM PWR_GOOD
                                  -1 fid
                                25 on




                 Status
                              20 C
                             2 IA




The following Redfish command can be used to obtain the SXM PWR_GOOD status from
                           71 ID




the HMC:
                         09 NV




curl -X POST
                      11 ah




http://192.168.31.1/redfish/v1/Managers/HGX_BMC_0/Actions/Oem/NvidiaManager.SyncOOBRawCommand -d
                        sn




'{"TargetType" : "Baseboard" ,"TargetInstanceId" : 0, "Opcode" : "B1" , "Arg1" : "00", "Arg2" :
                      Ki




"00"}'
                  ik
                R




Opcode 0xB1 in the command corresponds to the SMBPBI Opcode B1h “GET GPU/EROT
INTERRUPT INFO.” Full details of this SMBPBI Opcode B1h can be referenced from the
SMBus Post Box Interface (SMBPBI) For NVIDIA Baseboards Application Note (NVOnline:
1030060).
Figure 14-2 shows an example output from the Redfish command. Bit 8 through 15 in
the “DataOut” output represents the PWR_GOOD status for SXMs 1 through 8. A value of
1b indicates that there is an issue with the PWR_GOOD status, and a value of 0b
indicates that PWR_GOOD status is normal.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 109
                                                           Out-of-Band Telemetry through Redfish


Figure 14-2.        Output of SXM PWR_GOOD Status through Redfish Example




                                                                  bs
                                                                La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid



14.3             Checking for SXM THERM_OVERT
                                25 on
                              20 C




                 Status
                             2 IA
                           71 ID
                         09 NV




The following Redfish command can be used to obtain the SXM THERM_OVERT status
from the HMC:
                      11 ah
                        sn




curl -X POST
http://192.168.31.1/redfish/v1/Managers/HGX_BMC_0/Actions/Oem/NvidiaManager.SyncOOBRawCommand -d
                      Ki




'{"TargetType" : "Baseboard" ,"TargetInstanceId" : 0, "Opcode" : "B0" , "Arg1" : "00", "Arg2" :
                  ik




"00"}'
                R




Opcode 0xB0 in the command corresponds to the SMBPBI Opcode B0h “GET OVERT
INFO.” Full details of this SMBPBI Opcode B0h can be referenced from the SMBus Post
Box Interface (SMBPBI) For NVIDIA Baseboards Application Note (NVOnline: 1030060).
Bit 0 through 7 in the “DataOut” field of the Redfish command response represent the
THERM_OVERT status for SXMs 1 through 8. A value of 1b indicates that the
corresponding SXM has an over-temperature issue.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 110
                                                           Out-of-Band Telemetry through Redfish



14.4             Checking for ERoT Fatal Error Status
The following Redfish command can be used to obtain the ERoT Fatal Error status from
the HMC:

curl -X POST
http://192.168.31.1/redfish/v1/Managers/HGX_BMC_0/Actions/Oem/NvidiaManager.SyncOOBRawCommand -d
'{"TargetType" : "Baseboard" ,"TargetInstanceId" : 0, "Opcode" : "B1" , "Arg1" : "80", "Arg2" :
"00"}'


Opcode 0xB1 in the command corresponds to the SMBPBI Opcode B1h “GET GPU/EROT
INTERRUPT INFO.” Full details of this SMBPBI Opcode B1h can be referenced from the
SMBus Post Box Interface (SMBPBI) For NVIDIA Baseboards Application Note (NVOnline:
1030060).




                                                                  bs
The following figure shows an example output from the Redfish command. Bit 0 through




                                                                La
7 in the “DataOut” output represents the ERoT Error status for SXMs 1 through 8. A




                                              03 e
value of 1b indicates that there is an ERoT Fatal Error status, and a value of 0b indicates




                                            5: cl
                                          :1 ra
that ERoT status is normal.

Figure 14-3.
                                        16 al O
                    Output of SXM ERoT Fatal Error Status through Redfish Example
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 111
                                                           Out-of-Band Telemetry through Redfish



14.5             Downloading FPGA Register Table
The following Redfish command can be used to download the FPGA register table dump
using HMC. This FPGA register table dump can be provided to NVIDIA for further
analysis of error scenario.
1. Initiate the FPGA register dump collection.
    curl -X POST
    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Actions/LogService.Collect
    DiagnosticData/ -d '{"DiagnosticDataType":"OEM",
    "OEMDiagnosticDataType":"DiagnosticType=FPGA"}'

2. Check the task completion progress.
    curl -X GET http://${HMC_IP}/redfish/v1/TaskService/Tasks/{task_id}




                                                                  bs
3. Download the FPGA register dump after TaskState becomes “Complete.”




                                                                La
    curl -X GET
    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Entries/1/attachment --




                                              03 e
                                            5: cl
    output /tmp/fpga-report.tar.xz




                                          :1 ra
14.6             Downloading ERoT Logs  16 al O
                                      28 ti
                                    1- en
                                  -1 fid


The following Redfish command can be used to download the ERoT logs using HMC.
                                25 on



These ERoT logs can be provided to NVIDIA for further analysis of error scenario.
                              20 C




1. Initiate the ERoT dump collection.
                             2 IA




    curl -X POST
                           71 ID




    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Actions/LogService.Collect
    DiagnosticData/ -d '{"DiagnosticDataType":"OEM", "OEMDiagnosticDataType":"DiagnosticType=EROT"}
                         09 NV




2. Check the task completion progress.
                      11 ah




    curl -X GET http://${HMC_IP}/redfish/v1/TaskService/Tasks/{task_id}
                        sn
                      Ki




3. Download the ERoT logs after TaskState becomes “Complete.”
                  ik




    curl -X GET
                R




    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Entries/{entry_id}/attachm
    ent --output erot_dump_1.tar.xz




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                       DA-11437-001_v13 | 112
                                                           Out-of-Band Telemetry through Redfish



14.7             Downloading PCIe Retimer LTSSM
                 Log
The following Redfish command can be used to download the PCIe Retimer LTSSM log
using HMC. This PCIe Retimer LTSSM log can be provided to NVIDIA for further analysis
of error scenario.
1. Initiate the PCIe Retimer LTSSM log dump collection.
    curl -X POST
    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Actions/LogService.Collect
    DiagnosticData/ -d '{"DiagnosticDataType":"OEM",
    "OEMDiagnosticDataType":"DiagnosticType=RetLTSSM"}'

2. Check the task completion progress.




                                                                  bs
    curl -X GET http://${HMC_IP}/redfish/v1/TaskService/Tasks/{task_id}




                                                                La
                                              03 e
3. Download the PCIe Retimer LTSSM log after TaskState becomes “Complete.”




                                            5: cl
    curl -X GET




                                          :1 ra
    http://${HMC_IP}/redfish/v1/Systems/HGX_Baseboard_0/LogServices/Dump/Entries/1/attachment --


                                        16 al O
    output /tmp/retimer.tar.xz        28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                       DA-11437-001_v13 | 113
Chapter 15. Reliability, Availability, and
            Serviceability




15.1             Error Counters and Thresholds




                                                                           bs
                                                                         La
This section provides guidance and error counters that can be used to assess the health




                                              03 e
of the NVIDIA GPU system. When a particular error threshold is exceeded, NVIDIA




                                            5: cl
                                          :1 ra
recommends partners review any XID and SXID messages that have been generated by


                                        16 al O
following the Server RAS Catalog (NVOnline: 1116117). NVIDIA GPU and NVIDIA HGX
Field Diagnostics tools can be used to determine if the system is eligible for RMA.
                                      28 ti
                                    1- en

For NVIDIA Hopper HGX baseboard products, additional information on telemetry data
                                  -1 fid


to capture, in-band, and out-of-band APIs available to retrieve health metrics can be
                                25 on



referenced from the NVIDIA Hopper HGX 8-GPU Telemetry Playbook (NVOnline: 1093241)
                              20 C
                             2 IA




Table 15-1.         Error Counters and Thresholds
                           71 ID




 Error Counter                       Threshold        Next Steps
                         09 NV




 GPU PCIe Fatal Error (GPU-PCI-      >0               Review any XID and SXID error messages using the
                      11 ah




 ERR-CTR-FATAL)                                       “XID error to Action Mapping” in the previous section.
                        sn




                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
                      Ki




 GPU PCIe Non-Fatal Error (GPU-      >0               Review any XID and SXID error messages using the
                  ik
                R




 PCI-ERR-CTR-NON-FATAL)                               “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
 GPU PCIe Unsupported Request        >0               Review system topology, external system queries and
 (GPU-PCI-ERR-CTR-UNSUPP-                             bus scans.
 REQ)                                                 Review any XID and SXID error messages using the
                                                      “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
 GPU PCIe Recovery (GPU-PCI-         TxRecovery > 2   Review any XID and SXID error messages using the
 ERR-CTR-RECOVERY)                                    “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                DA-11437-001_v13 | 114
                                                                    Reliability, Availability, and Serviceability


 Error Counter                       Threshold        Next Steps
 GPU Row Remapping Failure           Binary 1 =       GPU and HGX Field Diagnostics is recommended if this
 (GPU-ROW-REMAP-FAILED)              Failed           error is persistent and reproducible
 GPU ECC Uncorrectable Error         >1               Review any XID and SXID error messages using the
 (ECC-ERR-CTR-UCE)                                    “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
 GPU ECC Correctable Error           No limit         Review any XID and SXID error messages using the
 (ECC-ERR-CTR-CE)                                     “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
 NVSwitch PCIe Correctable           > 19 per 10      Review any XID and SXID error messages using the
 Error (NVSWITCH-PCI-ERR-CTR-        minutes          “XID error to Action Mapping” in the previous section.




                                                                            bs
 CORR)                                                GPU and HGX Field Diagnostics is recommended if this




                                                                          La
                                                      error is persistent and reproducible




                                              03 e
 NVSwitch PCIe Fatal Error           >0               Review any XID and SXID error messages using the




                                            5: cl
 (NVSWITCH-PCI-ERR-CTR-                               “XID error to Action Mapping” in the previous section.




                                          :1 ra
 FATAL)                                               GPU and HGX Field Diagnostics is recommended if this


                                        16 al O
                                                      error is persistent and reproducible
 NVSwitch PCIe Non-Fatal Error       >0               Review any XID and SXID error messages using the
                                      28 ti
                                    1- en
 (NVSWITCH-PCI-ERR-CTR-NON-                           “XID error to Action Mapping” in the previous section.
                                  -1 fid


 FATAL)                                               GPU and HGX Field Diagnostics is recommended if this
                                25 on



                                                      error is persistent and reproducible
                              20 C




 NVSwitch PCIe Unsupported           >0               Review any XID and SXID error messages using the
 Request (NVSWTICH-PCI-ERR-                           “XID error to Action Mapping” in the previous section.
                             2 IA




 CTR-UNSUPP-REQ)
                           71 ID




                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
                         09 NV




 NVSwitch PCIe Recovery              TxRecovery: >    Review any XID and SXID error messages using the
                      11 ah




 (NVSWTICH-PCI-ERR-CTR-              2                “XID error to Action Mapping” in the previous section.
 RECOVERY)
                        sn




                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible
                      Ki




 NVSwitch ECC Correctable Error      No Limit         Review any XID and SXID error messages using the
                  ik
                R




 (NVSWTICH-ECC-ERR-CTR-CE)                            “XID error to Action Mapping” in the previous section.
                                                      GPU and HGX Field Diagnostics is recommended if this
                                                      error is persistent and reproducible




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 115
Chapter 16. ConnectX-7 Platforms



This chapter lists the different monitoring measures and debug steps relevant to the
ConnectX-7 platforms.




                                                               bs
                                                             La
16.1             ConnectX-7 Thermal Issues



                                              03 e
                                            5: cl
The following subsections are the different thermal issue scenarios encountered in




                                          :1 ra
ConnectX-7 (CX-7). Debugging steps are listed to address reported thermal issues.

                                        16 al O
Where applicable, in-band and out-of-band telemetry have been identified to aid
partners in diagnosing the associated error scenarios.
                                      28 ti
                                    1- en
                                  -1 fid


16.1.1           Thermal Warnings
                                25 on
                              20 C




ConnectX-7 firmware initiates thermal warnings, triggering a hardware slowdown when
                             2 IA




the ASIC reaches the thermal warning threshold. This is indicated by the assertion of a
                           71 ID




corresponding THERM_warning signal, alerting the user to the over-temperature
                         09 NV




condition.
                      11 ah




16.1.2           Thermal Hardware Shutdown and OVERT
                        sn
                      Ki




                 Event
                  ik
                R




Upon reaching the thermal shutdown threshold, the ASIC asserts a THERM_SHUTDN
signal to notify the user of the over-temperature condition. A message is sent to the
driver, prompting the firmware to initiate the shutdown process for the ASIC.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                  DA-11437-001_v13 | 116
                                                                          ConnectX-7 Platforms



16.2             ConnectX-7 Debug Steps
Following are the CX-7 debug steps for the data center products.


16.2.1           ASIC Thermal Warning Message
Perform the following debug steps when the following ASIC thermal warning message is
received by dmsg:
mlx5_core 0000:41:00.1: temp_warn:171:High temperature on sensors with bit set 2 8000 0000 0000
0000

Debug Steps:
1. To read and verify the high temperature, run:




                                                                  bs
    mget_temp -d [device name]




                                                                La
2. Perform a visual inspection.




                                              03 e
3. Ensure that the airflow direction aligns with the product specifications.




                                            5: cl
4. Verify that fans are operating at the expected performance level.




                                          :1 ra
                                        16 al O
5. Replace the faulty NIC with a functioning one from another slot in the server and
   observe if the issue persists with the NIC.
                                      28 ti
                                    1- en
6. If the problem persists in the same server slot, investigate the airflow within that
   slot.
                                  -1 fid
                                25 on



7. Replace the cards between servers; if the failed card functions properly in another
   server, investigate the airflow within the original failing server. If the issue occurs
                              20 C




   wherever the NIC is installed, initiate an RMA process.
                             2 IA
                           71 ID
                         09 NV




16.2.2           Transceiver Thermal Warning Message
                      11 ah




Perform the following debug steps when the following a transceiver thermal warning
                        sn




message is received by dmesg:
                      Ki




mlx5_core 0000:33:00.0: Port module event[error]: module 0, Cable error, High Temperature
                  ik




mlx5_core 0000:41:00.1: temp_warn:171:High temperature on sensors with bit set 2 8000 0000 0000
                R




0000

Debug Steps:
1. Run:
    mlxlink -d [device]      -m
2. Verify that fans are operating at the anticipated performance level.
3. It is possible that a defective transceiver is causing the issue. Replace the transceiver
   and check if issue is resolved.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 117
                                                                        ConnectX-7 Platforms



16.3             ConnectX-7 Power
If the power of the transceiver exceeds the supported power of the port, the link will be
disabled.
Run the following command to identify the reason:
mlxlink -d [device]

Ensure that the transceiver being used is supported. For a list of validated and
supported cables, refer to: NVIDIA Adapter Cards Firmware Release Notes




                                                                bs
                                                              La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                   DA-11437-001_v13 | 118
Chapter 17. BlueField-3 Platforms



This chapter highlights the advanced functionalities of the NVIDIA BlueField-3 Data
Processing Unit (DPU) and Super Network Interface Cards (Super NIC), focusing on
Reliability, Availability, and Serviceability (RAS) aspects. The BlueField-3 platforms




                                                                  bs
integrate a suite of RAS features aimed at improving system reliability, minimizing




                                                                La
downtime, and facilitating maintenance tasks. The following commands are used for
monitoring and debugging critical BlueField-3 (BF-3) components.




                                              03 e
                                            5: cl
                                          :1 ra
        Note: The BMC, eMMC, NVMe SSD, ERoT, and 1G OOB interfaces are relevant to BlueField-3


                                        16 al O
        platforms only when the Arm cores are activated.
                                      28 ti
                                    1- en
                                  -1 fid



17.1             OS Dump
                                25 on
                              20 C




The sysinfo.snapshot tool is designed to capture a snapshot of all configuration details
                             2 IA




and relevant information concerning both the server and the NVIDIA boards. It conducts
                           71 ID




a thorough scan of the system, providing information on the current settings of the
                         09 NV




operating system, networking, and hardware components.
                      11 ah




Run the tool on both the server host OS and the BlueField Arm OS to check for driver
                        sn




errors, assertions, PCIe, and network errors.
                      Ki




# first, ssh to the Host server OS
                  ik
                R




Sysinfo.snapshot.py

# Second, ssh to the ARM OS

Sysinfo.snapshot.py

# Output example
localhost:~# sysinfo-snapshot.py
Sysinfo-snapshot is still in process...please wait till completed successfully
Gathering the information may take a while, especially in large networks
Your patience is appreciated
------------------------------------------------------------

Running sysinfo-snapshot has ended successfully!


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 119
                                                                           BlueField-3 Platforms


Temporary destination directory is /tmp/
Out file name is /tmp/sysinfo-snapshot-v3.7.6-bu-fae4-bf3-20240312-103303.tgz

/tmp/sysinfo-snapshot-v3.7.6-bu-fae4-bf3-20240312-103303.tgz:
amber_info
bu-fae4-bf3-20240312-103303.html
cables
commands_txt_output
devlink
dmesg
dmidecode
ecn
err_messages:
         dummy_functions        - contains all not found commands




                                                                  bs
         dummy_paths            - contains all not existing internal files (/paths)
         dummy_external_paths   - contains all not existing external files (/paths)




                                                                La
etc_udev_rulesd                 - contains all files under /etc/udev/rules.d




                                              03 e
ethtool_S                       - contains all files which are generated from invoking ethtool -S




                                            5: cl
<interface>




                                          :1 ra
firmware                        - contains all firmware files (mst dump files and commands outputs)


                                        16 al O
journal
lib_udev_rulesd                 - contains all files under /lib/udev/rules.d
                                      28 ti
                                    1- en

libvma.conf
                                  -1 fid


lshw
                                25 on



pcie_files
performance_tuning_analyze.html
                              20 C




pkglist
                             2 IA




show_irq_affinity_all
                           71 ID




sr_iov.html
                         09 NV




trace
var_log_dmesg
                      11 ah




var_log_syslog
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 120
                                                                            BlueField-3 Platforms



17.2             DDR
The following table lists the BlueField-3 platforms DDR.

Table 17-1.         DDR
 Action                                 Command
 Collect the DDR temperature            # ssh to the ARM OS
                                        modprobe mlxbf-ptm
                                        cd /sys/kernel/debug/mlxbf-ptm/monitors/status/
                                        cat ddr_temp
 Check the RShim for DDR errors         # From the ARM OS:
 through the Arm OS                     bfrshlog




                                                                      bs
 Check the RShim for DDR errors         # From the Host OS:




                                                                    La
 through the Host server OS             echo "DISPLAY_LEVEL 2" > /dev/rshim0/misc cat




                                              03 e
                                        /dev/rshim0/misc




                                            5: cl
                                          :1 ra
17.3             BMC                    16 al O
                                      28 ti
                                    1- en

The following table lists the BlueField-3 platforms BMC.
                                  -1 fid
                                25 on




Table 17-2.         BMC
                              20 C
                             2 IA




 Action                          Command
                           71 ID




 Get BMC version                 #Using redfish
                         09 NV




                                 curl -k -u root:'<password>' -X GET
                                 https://<bmc_ip>/redfish/v1/UpdateService/FirmwareInventory
                      11 ah




                                 /BMC_Firmware | jq -r ' .Version'
                        sn




                                 #From BMC CLI
                      Ki




                                 cat /etc/os-release
                   ik
                R




 Get BMC diagnostic data         # Using redfish
                                 # Start diagnostic data task
                                 curl -k -u root:'<password>' -H 'Content-Type:
                                 application/json' -X POST -d
                                 '{"DiagnosticDataType":"Manager"}' https://<BMC
                                 IP>/redfish/v1/Managers/Bluefield_BMC/LogServices/Dump/Acti
                                 ons/LogService.CollectDiagnosticData


                                 #check the <Id> and then Monitor unit generation progress
                                 curl -k -u root:'<password>' -H 'Content-Type:
                                 application/json' -X GET   https://<BMC
                                 IP>/redfish/v1/TaskService/Tasks/<Id>
                                 # Once "TaskState": "Completed",




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                       DA-11437-001_v13 | 121
                                                                                 BlueField-3 Platforms


 Action                          Command
                                 # Check the "Payload":"Location:
                                 /redfish/v1/Managers/Bluefield_BMC/LogServices/Dump/Entries
                                 /<Entry Id>"
                                 # Download the BMC logs
                                 curl -k -u root:'<password>' -H 'Content-Type:
                                 application/json' -X GET https://<BMC
                                 IP>/redfish/v1/Managers/Bluefield_BMC/LogServices/Dump/Entr
                                 ies/<Entry Id>/attachment --output <output file>
 Collect dmesg                   # From the BMC CLI
                                 dmesg > <output file>
 Detect the I2C devices          # From the BMC CLI
 connected to the BMC            i2cdetect -y <i2c bus number>




                                                                      bs
                                                                    La
17.4                USB



                                                03 e
                                              5: cl
                                            :1 ra
The following table lists the BlueField-3 platforms USB.

                                          16 al O
                                        28 ti
Table 17-3.         USB
                                      1- en
                                    -1 fid


 Action                          Command
                                  25 on



 Check USB interface             # From the BMC CLI, verify 22dc device exists
                                20 C




                                 lsusb
                               2 IA
                             71 ID




17.5                eMMC
                           09 NV
                        11 ah




The following table lists the BlueField-3 platforms eMMC.
                          sn
                        Ki




Table 17-4.         eMMC
                    ik
                 R




 Action                                      Command
 Collect eMMC lifecycle logs                 # ssh to the ARM OS
 1. Download the "Collect eMMC
 Lifetime Tool" via NVOnline #1113192.       # Compile
 2. Compile the file.                        Gcc eMMC_LTM_demo.c -o eMMC_LTM
 3. Run the tool.
                                             # Run the tool
                                             ./eMMC_LTM




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                            DA-11437-001_v13 | 122
                                                                                   BlueField-3 Platforms



17.6             NVMe SDD
The following table lists the BlueField-3 platforms NVMe SSD.

Table 17-5.         NVMe SSD
 Action                          Command
 Run data monitoring using       # ssh to the ARM OS
 the smartontools

                                 apt install smartontools


                                 smartctl --all /dev/nvme0




                                                                          bs
                                 # Output example




                                                                        La
                                 root@bu-fae4-bf3-1:~# smartctl --all /dev/nvme0




                                              03 e
                                 smartctl 7.2 2020-12-30 r5155 [aarch64-linux-5.15.0-1032-bluefield]




                                            5: cl
                                          :1 ra
                                 (local build)




                                        16 al O
                                 Copyright (C) 2002-20, Bruce Allen, Christian Franke,
                                 www.smartmontools.org
                                      28 ti
                                    1- en
                                  -1 fid


                                 === START OF INFORMATION SECTION ===
                                25 on




                                 Model Number:                       MTFDHBL128TDP
                              20 C




                                 Serial Number:                      22443C22C214
                             2 IA




                                 Firmware Version:                   MU05
                           71 ID




                                 PCI Vendor/Subsystem ID:            0x1344
                         09 NV




                                 IEEE OUI Identifier:                0x00a075
                      11 ah




                                 Total NVM Capacity:                 128,035,676,160 [128 GB]
                        sn




                                 Unallocated NVM Capacity:           0
                      Ki




                                 Controller ID:                      0
                  ik




                                 NVMe Version:                       1.3
                R




                                 Number of Namespaces:               4
                                 Local Time is:                      Tue Mar 12 12:25:30 2024 UTC
                                 Firmware Updates (0x12):            1 Slot, no Reset required
                                 Optional Admin Commands (0x001f):   Security Format Frmw_DL
                                 NS_Mngmt Self_Test
                                 Optional NVM Commands (0x0055):     Comp DS_Mngmt Sav/Sel_Feat
                                 Timestmp
                                 Log Page Attributes (0x06):         Cmd_Eff_Lg Ext_Get_Lg
                                 Maximum Data Transfer Size:         64 Pages
                                 Warning   Comp. Temp. Threshold:    115 Celsius
                                 Critical Comp. Temp. Threshold:     123 Celsius




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                             DA-11437-001_v13 | 123
                                                                                          BlueField-3 Platforms


 Action                          Command
                                 Supported Power States
                                 St Op      Max       Active    Idle   RL RT WL WT       Ent_Lat   Ex_Lat
                                  0 +      6.00W      300.00W     -    0    0   0   0        500      500
                                  1 +      6.00W          -       -    1    1   1   1        500      500
                                  2 +      6.00W          -       -    2    2   2   2        500      500
                                  3 -    0.2270W          -       -    3    3   3   3       5000   10000
                                  4 -    0.0130W          -       -    4    4   4   4      10000   50000


                                 === START OF SMART DATA SECTION ===
                                 SMART overall-health self-assessment test result: PASSED




                                                                             bs
                                 SMART/Health Information (NVMe Log 0x02)




                                                                           La
                                 Critical Warning:                      0x00
                                 Temperature:                           34 Celsius




                                              03 e
                                            5: cl
                                 Available Spare:                       100%




                                          :1 ra
                                 Available Spare Threshold:             10%


                                        16 al O
                                 Percentage Used:
                                      28 ti                             11%
                                 Data Units Read:                       19,174,769 [9.81 TB]
                                    1- en

                                 Data Units Written:                    16,561,766 [8.47 TB]
                                  -1 fid


                                 Host Read Commands:                    2,106,598,041
                                25 on




                                 Host Write Commands:                   1,896,538,679
                              20 C




                                 Controller Busy Time:                  8,555
                             2 IA




                                 Power Cycles:                          109
                           71 ID




                                 Power On Hours:                        4,413
                         09 NV




                                 Unsafe Shutdowns:                      85
                      11 ah




                                 Media and Data Integrity Errors:       0
                        sn




                                 Error Information Log Entries:         0
                      Ki




                                 Warning   Comp. Temperature Time:      0
                  ik




                                 Critical Comp. Temperature Time:       0
                R




                                 Temperature Sensor 1:                  34 Celsius


                                 Error Information (NVMe Log 0x01, 16 of 64 entries)
                                 No Errors Logged




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                     DA-11437-001_v13 | 124
                                                                                        BlueField-3 Platforms



17.7             Power and Thermal
The following table lists the BlueField-3 platforms power and thermal.

Table 17-6.          BF-3 Power and Thermal
 Action                          Command
 Collect the BlueField-3 SoC     # ssh to the ARM OS
 temperature:                    mget_temp -d <mst dev>
 Check for thermal/power         # ssh to the ARM OS
 throttling events of the Arm    Modprobe mlxbf-ptm
 temperature:
                                 cd /ys/kernel/debug/mlxbf-ptm/monitors/status/
                                 cat thermal_throttling_event_count




                                                                             bs
                                 cat power_throttling_event_count




                                                                           La
                                              03 e
                                 # ARM core power (PCIe goldfingers)




                                            5: cl
                                 cat vr0_power




                                          :1 ra
                                        16 al O
                                 # NIC and misc power (ATX)
                                 cat vr1_power
                                      28 ti
                                    1- en
                                  -1 fid



17.8             ERoT
                                25 on
                              20 C
                             2 IA




The following table lists the BlueField-3 platforms ERoT.
                           71 ID




Table 17-7.          ERoT
                         09 NV




 Action                Command
                      11 ah




 Collect CEC           # ssh to the Host OS
                        sn




 firmware version      curl -k -u root:'<password>' -X GET
                      Ki




                       https://<bmc_ip>/redfish/v1/UpdateService/FirmwareInventory/Bluefield_FW_ERoT | jq -r '
                    ik




                       .Version'
                R




17.9             1G OOB Interface
The following table lists the BlueField-3 platforms 1G OOB interface.
Table 17-8.          1G OOB Interface
 Action                  Command
 Collect MDIO data       # ssh to the ARM OS
                         # Clone tool from https://github.com/wkz/phytool.git and run make to build it
                         # Read MDIO standard register in the PHY using clause 22 convention
                         ./phytool read IFACE/0x3/reg> # example: ./phytool read oob_net0:/0x3/3



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 125
Chapter 18. NVIDIA Quantum-3
            Platforms



This chapter applies to Q3200 switches only.




                                                                  bs
The NVIDIA Firmware Tools (MFT) package is a set of firmware management and debug




                                                                La
tools for NVIDIA devices. This section describes MFT features, tools content and




                                              03 e
configuration. For more information on the MFT tool, refer to: NVIDIA Firmware Tools




                                            5: cl
                                          :1 ra
(MFT) Documentation.


                                        16 al O
        Note: MFT tools must only be used for debug purposes on HGX 8-GPU platforms. For Multi-
                                      28 ti
        node NVLink Switches, NVOS CLI must be used.
                                    1- en
                                  -1 fid
                                25 on




18.1             Link Monitoring
                              20 C
                             2 IA
                           71 ID




>   Checks the status of the links in normal operation. This feature ensures
                         09 NV




    comprehensive monitoring, analysis, and troubleshooting capabilities across
    different interfaces, enhancing the overall reliability and serviceability of the system.
                      11 ah




>   AmBER Tool Usage: This tool utilizes the "mlxlink" command with the "--
                        sn




    amber_collect" option to gather various chip parameters and readings. It enables the
                      Ki




    retrieval of various ASIC configurations, connectivity readings, and other relevant
                  ik




    metrics.
                R




    mlxlink -d <device> --amber_collect <output_file.csv>
>   Output Report: The tool generates an output file in CSV format containing collected
    data.
>   Detection of Problems: The report generated includes columns for Raw, Effective,
    and Symbol Bit Error Rate (BER) to facilitate the detection of issues on specific ports.
>   IB XDR KPI Values: Provides Key Performance Indicator (KPI) values for UPHY
    (Unified PHY). Refer to Table 18-1 for IB.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 126
                                                                                  NVIDIA Quantum-3 Platforms


Table 18-1.           IB XDR KPI Values
                      FEC Interleaving
 Link Type            (514,516, 30)               PLR       CRC Protected         External BER       Internal BER
 IB (1X XDR) over     2 way interleave            With      Yes                   1E-252             1E-262
 short                                            PLR
 optics/copper
 IB (1X XDR) over     4-way interleave3           No        Yes                   1E-19              1E-20
 long optics                                      PLR
 Notes:
 1The FEC interleaving scheme implemented on the physical line Power-On-Reset (POR) exclusively employs

    Symbol interleaving. Bit interleaving is reserved only for GearBox applications.
 2The targeted BER for InfiniBand (IB) of 1e-19 externally and 1e-20 internally is a sufficient request.

 3A preferred configuration involves a two-way interleave setup to mitigate Packet Loss Ratio (PLR), subject to




                                                                                bs
    characterization results. A 4-way interleave configuration lacks L1 capability.




                                                                              La
                                                03 e
                                              5: cl
If errors are detected on a link, perform a deeper, dedicated test using the PRBS test in




                                            :1 ra
test mode, as described in the following section.


                                          16 al O
                                        28 ti
                                      1- en

18.2               PRBS in Test Mode - mlxlink
                                    -1 fid
                                  25 on



The PRBS test serves to assess the quality of the link.
                                20 C
                               2 IA




          Note: Execute the following commands on both ends of the test to function properly.
                             71 ID
                           09 NV




>     Activate PRBS mode, run:
      mlxlink -d --test_mode EN
                        11 ah




          The default speed per lane is 25G and PRBS31.
                          sn




      •
                        Ki




>     Adjust default speeds using flags: --tx_rate and --rx_rate.
                    ik




>     For GB NVL systems with DC-coupled cable cartridges, use the –dc_cpl_allow option
                  R




      with mlxlink while adjusting the default speeds.
>     Tune the receiver, run:
      mlxlink -d device_name --test_mode TU
>     Check results, run:
      mlxlink -d <device_name> -c
>     Ensure successful tuning and that all lanes are locked.
>     Deactivate PRBS mode, run:
      mlxlink -d <device> --test_mode DS




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                       DA-11437-001_v13 | 127
                                                                  NVIDIA Quantum-3 Platforms



18.3             Loopback Test
If peer connectivity for PRBS testing is not available, a loopback test can detect issues
with the board or module.
Activate loopback mode using the following command:
mlxlink <device_name> -l <loopback_mode>

Where <loopback_mode> options include:
>   NO (no loopback)
>   RM (phy remote Rx-to-Tx loopback)
>   PH (internal Phy Tx-to-Rx loopback)
>   EX (external loopback, requires connector)




                                                                bs
>   LL (link layer local loopback)




                                                              La
Select the appropriate loopback mode based on your requirements.




                                              03 e
                                            5: cl
                                          :1 ra
18.4             Sideband Management
                                        16 al O
                                      28 ti
MST devices serve as hardware interfaces for accessing devices. Each interface is
                                    1- en

represented by a Linux file located at /dev/mst.
                                  -1 fid


>   PCI (configuration cycles): This mode is the most used. Example:
                                25 on




    /dev/mst/mt4123_pciconfl
                              20 C




>   PCI (direct memory access): Requires access to PCI memory. Not compatible with
                             2 IA




    Live-Fish mode (NO firmware on device). Example: /dev/mst/mt4123_pci_cr0
                           71 ID




>
                         09 NV




    Utilizing an MST device through I2C with USB involves physical bus access facilitated
    by the MTUSB USB to I2C adapter. Example: /dev/mst/mtusb-1
                      11 ah




>   Remote Access: Remote MST devices transmit access requests over a TCP/IP socket
                        sn




    to the destination device. Example: fit-I-vrt-80:23108,@dev@mst@mt4123_pciconf1
                      Ki




In-Band Access: Devices can be accessed in-band through the InfiniBand fabric.
                  ik
                R




18.5             Quantum-3 Thermal
For remote temperature readings from the ASIC on HGX-8 platforms, run the following
command:
mget_temp -d <device> -v




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                    DA-11437-001_v13 | 128
                                                              NVIDIA Quantum-3 Platforms


Example Output:
sudo mget_temp -d /dev/mst/mt54004_pciconf0
41




                                                            bs
                                                          La
                                              03 e
                                            5: cl
                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




From the switch terminal, run the command:
show temperature

This command displays both ASIC and board temperatures.
The maximum permitted threshold for NVIDIA Quantum-3 IC is 105°C on junction (Tj).
The IC shuts down at 110°C.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products               DA-11437-001_v13 | 129
                                                                    NVIDIA Quantum-3 Platforms



18.6             Quantum-3 Power
Q3200 Switch Output Example:
admin@croc-94:~$ nv show platform environment voltage
Name                             Actual (V) Maximum (V)   Minimum (V)   State
------------------------------- ---------- -----------    -----------   -----
PMIC-1-12V-VDD-ASIC1-In-1        12.25       16.00        0.00          ok
PMIC-1-ASIC1-VDD-Out-1           0.70        1.00         0.50          ok
PMIC-2-12V-HVDD-DVDD-ASIC1-In-1 12.22        16.00        0.00          ok
PMIC-2-ASIC1-DVDD-PL0-Out-2      0.84        1.00         0.59          ok
PMIC-2-ASIC1-HVDD-PL0-Out-1      1.20        1.40         1.00          ok
PMIC-3-12V-HVDD-DVDD-ASIC1-In-1 12.31        16.00        0.00          ok
PMIC-3-ASIC1-DVDD-PL1-Out-2      0.84        1.00         0.59          ok
PMIC-3-ASIC1-HVDD-PL1-Out-1      1.20        1.40         1.00          ok




                                                                    bs
PMIC-4-12V-VDD-ASIC2-In-1        12.31       16.00        0.00          ok




                                                                  La
PMIC-4-ASIC2-VDD-Out-1           0.71        1.00         0.50          ok




                                              03 e
PMIC-5-12V-HVDD-DVDD-ASIC2-In-1 12.25        16.00        0.00          ok




                                            5: cl
PMIC-5-ASIC2-DVDD-PL0-Out-2      0.83        1.00         0.59          ok




                                          :1 ra
PMIC-5-ASIC2-HVDD-PL0-Out-1      1.20        1.40         1.00          ok


                                        16 al O
PMIC-6-12V-HVDD-DVDD-ASIC2-In-1 12.31        16.00        0.00          ok
PMIC-6-ASIC2-DVDD-PL1-Out-2      0.84        1.00         0.59          ok
                                      28 ti
                                    1- en
PMIC-6-ASIC2-HVDD-PL1-Out-1      1.20        1.40         1.00          ok
PMIC-7-12V-MAIN-In-1             12.25       16.00                      ok
                                  -1 fid


PMIC-7-CEX-VDD-Out-1             1.03        1.46         0.66          ok
                                25 on




PSU-1-12V-Out                    12.27       12.95        11.00         ok
                              20 C




PSU-2-12V-Out                    12.25       12.95        11.00         ok
                             2 IA




PSU-3-12V-Out                    12.27       12.95        11.00         ok
                           71 ID




PSU-4-12V-Out                    12.27       12.95        11.00         ok
                         09 NV
                      11 ah




18.7             IBDiagnet Tool
                        sn
                      Ki




The ibdiagnet tool can be used to provide power supply data.
                  ik
                R




In the ibdiagnet2.db_csv file, search for "START_POWER_SENSORS" to find: NodeGuid,
SensorIndex, SensorName, Voltage, Current



18.8             Security
To get the life cycle secure firmware status, run:
flint -d <device> -qq q full

admin@juliet-68:~$ sudo flint -d /dev/mst/mt54004_pciconf0 -qq q full
Image type:            FS5
FW Version:            35.2014.0402
FW Release Date:       15.5.2024
Part Number:           920-9K36F-00MV-JS0_QPN_Ax


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                      DA-11437-001_v13 | 130
                                                                    NVIDIA Quantum-3 Platforms


Description:           QPN for NVIDIA Quantum-3; NVLink Tray Solution; 1U; with 72 NVLink5 Internal
Ports and 72 NVLink5 External Ports
Product Version:       35.2014.0402
Rom Info:              type=UEFI version=skipped cpu=skipped
                       type=PXE version=skipped devid=skipped cpu=skipped
                       type=NVMe version=skipped devid=skipped cpu=skipped
Description:           UID                GuidsNumber
Base GUID:             9c63c0030072b213        8
Orig Base GUID:        N/A                     8
Base MAC:              9c63c072b213            8
Orig Base MAC:         N/A                     8
Image VSD:             N/A
Device VSD:            N/A
PSID:                  MT_0000001185
Security Attributes:   N/A




                                                                  bs
Default Update Method: fw_ctrl




                                                                La
Life cycle:            PRODUCTION




                                              03 e
Secure Boot Capable:   Disabled




                                            5: cl
Encryption:            Disabled




                                          :1 ra
                                        16 al O
                                      28 ti
                                    1- en
                                  -1 fid
                                25 on
                              20 C
                             2 IA
                           71 ID
                         09 NV
                      11 ah
                        sn
                      Ki
                  ik
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                     DA-11437-001_v13 | 131
Chapter 19. Troubleshooting
            Networking Interfaces




19.1             PCIe Interface




                                                                bs
                                                              La
PCIe is used in any system for communication between different modules. Network




                                              03 e
adapters need to communicate with the CPU and memory (among other modules). This




                                            5: cl
                                          :1 ra
means that to process network traffic, the different devices communicating via the PCIe


                                        16 al O
should be well configured. When connecting the network adapter to the PCIe interface,
automatic negotiation occurs to establish the highest supported capabilities between
                                      28 ti
the network adapter and the CPU.
                                    1- en
                                  -1 fid



19.1.1           PCIe Troubleshooting
                                25 on
                              20 C




To gain deeper insights into the PCIe issue, address the following:
                             2 IA
                           71 ID




>   Description of the Issue: Provide details about the server, device, network topology,
                         09 NV




    device PSID, and any security functionalities in place.
>   Reproduction Steps: Outline the steps to replicate the issue and specify the
                      11 ah




    frequency of occurrence. If it involves a cluster, indicate the number of affected
                        sn




    nodes.
                      Ki




>   Recent Changes: Identify any alterations made before the issue arose.
                  ik




>   Special Components: Determine if there are any unique risers, switches, cables, or
                R




    repeaters in the setup.
>   Compatibility Testing: Verify if the issue persists when using another similar NVIDIA
    product.
For initial PCIe link debugging, use the mlxlink tool. For more information, refer to the
"mlxlink Utility" documented under "Debug Utilities" in the latest NVIDIA Firmware Tools
(MFT) Documentation.
To determine the PCIe link speed and width, use the following flag: --port_type PCIE.
Output Example:
PCIe Operational (Enabled) Info
-------------------------------
Depth, pcie index, node     : [Depth, pcie index, node]
Link Speed Active (Enabled) : [Freq – Gen]

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                    DA-11437-001_v13 | 132
                                                             Troubleshooting Networking Interfaces


Link Width Active (Enabled) : [Width]
To determine the physical PCIe counters, use the following flag: --port_type PCIE –c flag

Output Example:
Management PCIe Timers Counters Info
------------------------------------
dl down                         : [link down counter]

Management PCIe Performance Counters Info
-----------------------------------------
RX Errors                       : [Rx Errors]
TX Errors                       : [Tx Errors]
CRC Error dllp                  : [CRC Errors dllp]
CRC Error tlp                   : [CRC Errors tlp]
RX Errors: indicate the number of transitions to recovery required due to framing errors and CRC




                                                                    bs
(dlp and tlp) errors.




                                                                  La
TX Errors: indicate the number of transitions to recovery required due to EIEOS and TS errors.
CRC Error dllp: indicate CRC error in Data Link Layer Packets.




                                              03 e
                                            5: cl
CRC Error tlp: indicate CRC error in Transaction Layer Packet.




                                          :1 ra
19.1.2           PCIe Useful Metrics
                                        16 al O
                                      28 ti
                                    1- en

To assess the PCIe link margin through the mlxlink utility, run:
                                  -1 fid


mlxlink -d [device] --port_type PCIE --margin
                                25 on
                              20 C




19.1.3           Pass or Fail Criteria
                             2 IA
                           71 ID




The following tables list the pass or fail criteria for PCIe Gen 3.0, 4.0, and 5.0.
                         09 NV
                      11 ah




Table 19-1.         PCIe Gen 3.0
                        sn




 Last FOM                          Criteria
                      Ki




 Last FOM < 70                     Fail
                  ik
                R




 70 < Last FOM < 99                Marginal
 100 < Last FOM                    Pass


Table 19-2.         PCIe Gen 4.0
 Last FOM                          Criteria
 Last FOM < 70                     Fail
 70 < Last FOM < 99                Marginal
 100 < Last FOM                    Pass




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                        DA-11437-001_v13 | 133
                                                                       Troubleshooting Networking Interfaces


Table 19-3.          PCIe Gen 5.0
 Last FOM                          Criteria
 Last FOM < 49                     Fail
 50 < Last FOM < 69                Marginal
 70 < Last FOM                     Pass



19.1.4              Error Detection
The following table lists the common PCIe related issues.

Table 19-4.          PCIe Related Issues




                                                                              bs
 Error Type                                   Debugging Steps




                                                                            La
 PCIe link down                               Check PERST and clock PLL signals




                                              03 e
 Speed degradation                            > Check the expected card and server speed




                                            5: cl
                                              > Replace riser card




                                          :1 ra
                                        16 al O
 Width degradation                            > Check the expected card and server width
                                              > Replace PCIe slot
                                      28 ti
                                    1- en
 Server is hanging or in Non-Maskable         > Capture three MST dumps using the mtusb utility
 Interrupt (NMI)                              > Replicate the scenario in Livefish mode
                                  -1 fid
                                25 on



 Firmware assertion error                     Attempt to improve or cancel the completion timeout
                              20 C




 AER                                          Review error type
                             2 IA




 The "PCIe" term appears in dmesg             Capture sysinfo or three MST dumps
                           71 ID




 Performance issue                            Tune MaxReadReq
                         09 NV




 Signal integrity                             Check the capacitors on the card
                      11 ah
                        sn




19.1.5              Error Reporting and Logging
                      Ki




Review the Advanced Error Reporting (AER) by running the lspci –vvv command.
                    ik
                R




Table 19-5.          Error Reporting and Logging
 Error Type                    Description                                                   Unit
 ABORT                         Cancels the current pending error, if exists.                 Not applicable
 BAD_DLLP_LCRC                 Flips a bit in the LCRC of the next “error_duration” DLLPs    Packets
                               that are transmitted through the port.
 BAD_TLP_LCRC                  Flips a bit in the LCRC of the next “error_duration” TLPs     Packets
                               that are transmitted
                               through the port.
                               The packets are VDM TLPs that are sent by the port to the
                               destination BDF - “dbdf”.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 134
                                                                      Troubleshooting Networking Interfaces


 Error Type                    Description                                                   Unit
 BAD_TLP_ECRC                  Flips a bit in the ECRC of the next “error_duration” TLPs     Packets
                               that are transmitted
                               through the port.
                               The packets are VDM TLPs that are sent by the port to the
                               destination BDF - “dbdf”.
 ERR_MSG                       Sends an error signaling message to the RC.                   Packets
 MALFORMED_ TLP                Sends an “error_duration” PM_ACTIVE_STATE_NACK                Packets
                               message to the destination BDF - “dbdf” with TC=1 instead
                               of 0.
 POISONED_TLP                  Sends an “error_duration” VDMs with data to the               Packets
                               destination BDF - “dbdf” with EP = 1.
 UNEXPECTED_CPL                Sends “error_duration” completions to the destination BDF     Packets




                                                                             bs
                               - “dbdf” with 0xff tag.




                                                                           La
 ACS_VIOLATION                 Sends “error_duration” VDMs to the destination BDF -          Packets




                                              03 e
                               “dbdf” with source_bdf=0.




                                            5: cl
                                          :1 ra
 SURPRISE_LINK_DOWN            Sets a port state to DETECT.                                  Not applicable



                                        16 al O
 RECEIVER_ERROR                Sends a clock instead of data for “error_duration” usecs.     uSec
                               A value of 0 in ‘error_duration’ means that this error must
                                      28 ti
                               be toggled by the firmware as fast as possible.
                                    1- en
                                  -1 fid
                                25 on




19.2             Ethernet and InfiniBand Interfaces
                              20 C
                             2 IA




Ethernet and InfiniBand (IB) represent advanced networking technologies recognized for
                           71 ID




their high performance, primarily applied in high-performance computing (HPC)
                         09 NV




environments and data centers.
                      11 ah
                        sn




19.2.1           Ethernet and InfiniBand Troubleshooting
                      Ki




Troubleshooting the InfiniBand and Ethernet links is divided into different scenarios,
                  ik
                R




outlined in Table 19-6.


19.2.2           Link is Down
Table 19-6 lists the troubleshooting for ethernet and InfiniBand when the link is down.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 135
                                                                        Troubleshooting Networking Interfaces


Table 19-6.         Link is Down
 Interface           Troubleshooting
 Ethernet            If the link is inactive and has either never been active or was active previously but became
                     inactive, verify the following elements:
                     > Ensure that the link is properly connected on both ends.
                     > Confirm that the link is configured with the same protocol on both ends:
                       • If auto-negotiation is enabled, ensure it is activated on both sides.
                       • Disable Auto-Negotiation and manually set the speed and FEC at both ends of the
                         link.
                     > Check the output of the mlxlink tool, which is part of the MFT package. For more
                       information, refer to the "mlxlink Utility" documented under "Debug Utilities" in the
                       latest: NVIDIA Firmware Tools (MFT) Documentation
                       • Execute the mlxlink tool with the -m flag. For an example, refer to: Utility Output




                                                                               bs
                         Example




                                                                             La
                     > If possible, conduct a loopback test to determine if the link will activate. This involves
                       connecting the cable and module to two ports on the same device.




                                              03 e
                                            5: cl
                       • IMPORTANT: Be cautious as this setup may trigger a loop; ensure the ports used are




                                          :1 ra
                         NOT within the same L2 segment.



                                        16 al O
                       • If the link becomes active during the loopback test on both ends, it indicates a
                         potential interoperability issue between the link partners. Verify this scenario using a
                                      28 ti
                                    1- en
                         certified cable by referring to the network device product brief and data sheet.
                                  -1 fid


 InfiniBand          In this situation, it is important to verify the following components:
                                25 on



                     > If the interface is in the "INIT" state, ensure that OpenSM is operational in the network
                       and has a physical path (via switches) to the affected devices.
                              20 C




                     > Ensure that the link is properly connected on both ends.
                             2 IA




                     > Check the output of the mlxlink tool, which is part of the MFT package. For more
                           71 ID




                       information, refer to the "mlxlink Utility" documented under "Debug Utilities" in the
                         09 NV




                       latest
                      11 ah
                        sn




19.2.3           Link is Flapping
                      Ki




>   Reseat the cable. If this resolves the issue, refer to Error Detection to monitor the
                  ik




    link and possibly replacing the cable, as it may degrade in quality over time.
                R




>   If the interface continues to flap, try relocating the cable to a different port to
    determine if the issue persists with the cable or the port. If the issue persists with
    the cable, consider replacing it with a verified spare. For optic connections, ensure
    the optical connectors are clean and retry the link before considering replacing the
    fiber itself. If the problem recurs, it is likely that one of the transceivers is failing.
>   Use the "What-Just-Happened" feature on compatible switch systems to examine
    Layer 1 link down reasons. An example for Cumulus Linux switch OS can be found
    here, and similar features are available on SONiC and Onyx platforms.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                     DA-11437-001_v13 | 136
                                                                     Troubleshooting Networking Interfaces



19.2.4           Ethernet and InfiniBand Useful Metrics
To better understand the mlxlink utility output and for useful link debug matrics, refer
to: Understanding mlxlink Utility Output.


19.2.5           Ethernet and InfiniBand Error Detection
The following table lists the error detection for ethernet and InfiniBand interfaces.

Table 19-7.         Ethernet and InfiniBand Error Detection
 Protocol                   References
 Ethernet                   Use the What Just Happened (WJH) tool which provides real time visibility into




                                                                            bs
                            network problems. For more information, refer to What-Just-Happened in the
                            latest NVIDIA Cumulus Linux User Guide.




                                                                          La
                            Use SNMP to monitor link errors and transceiver DDMI values. For more




                                              03 e
                            information, refer to the "Simple Network Management Protocol - SNMP" in




                                            5: cl
                                          :1 ra
                            the latest NVIDIA Cumulus Linux User Guide



                                        16 al O
 InfiniBand                 Refer to the NVIDIA InfiniBand Cluster Operation and Maintenance Guide.
                                      28 ti
                                    1- en

19.2.6           Ethernet and InfiniBand Error Reporting and
                                  -1 fid



                 Logging
                                25 on
                              20 C




The following table lists the error reporting and logging for ethernet and InfiniBand
                             2 IA




interfaces.
                           71 ID
                         09 NV




Table 19-8.         Ethernet and InfiniBand Error Reporting and Logging
                      11 ah




 Protocol                   References
                        sn




 Ethernet                   For Cumulus Linux, refer to Troubleshooting Network Interfaces
                      Ki




 InfiniBand                 Refer to the "Supported Counters and Events" section, refer to the NVIDIA
                  ik




                            UFM Enterprise User Manual here
                R




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                DA-11437-001_v13 | 137
Chapter 20. Understanding the mlxlink
            Utility Output



The NVIDIA Firmware Tools (MFT) package is a set of firmware management and debug




                                                                               bs
tools for NVIDIA devices. This section describes MFT features, tools, and configuration.




                                                                             La
For more information on the MFT tool, refer to the NVIDIA Firmware Tools (MFT)




                                              03 e
Documentation.




                                            5: cl
                                          :1 ra
The mlxlink tool is used to check and debug link status and related issues. The output


                                        16 al O
includes information regarding the following aspects, each described as follows with an
output example.
                                      28 ti
                                    1- en
>   Operational Information
                                  -1 fid


>   Supported Information
                                25 on



>   Troubleshooting Information
                              20 C




>   Physical Counters and BER Information
                             2 IA




>   Module Information
                           71 ID
                         09 NV




20.1              Operational Information
                      11 ah
                        sn




The following table lists the details of the operational status of the module and
                      Ki




parameters.
                  ik
                  R




Table 20-1.         Operational Information
 Parameter                  Description
 State                      Admin status of the port.
                            > "Active": link is active
                            > "Polling": system is in the process of establishing a link
 Physical State             Represents the current state of the Layer 1 machine during the link-up
                            process.
                            > "LinkUp": Indicates successful establishment of the link
                            > "ETH_AN_FSM_ENABLE": Indicates the initiation of the link
                              establishment process
                            > "ETH_AN_FSM_ABILITY_DETECT": Signifies recognition of a link partner
                              and efforts to establish optimal link parameters


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 138
                                                                      Understanding the mlxlink Utility Output


 Parameter                  Description
                            > "ETH_AN_FSM_AN_GOOD_CHECK": Marks the conclusion of link
                              establishment with agreement on optimal parameters, signaling the
                              imminent "Link Up" status
 Speed                      Link speed
 Width                      PCIe width
 FEC                        Indicated the FEC mechanism
 Loopback Mode              Indicates if Loopback mode is activated
 Auto Negotiation           Indicates if the auto-negotiation feature is activated



Output Example:




                                                                              bs
Operational Info
----------------




                                                                            La
State                                : Active




                                              03 e
Physical state                       : LinkUp




                                            5: cl
                                          :1 ra
Speed                                : 100G



                                        16 al O
Width                                : 4x
FEC                                  : Standard RS-FEC - RS(528,514)
                                      28 ti
Loopback Mode                        : No Loopback
                                    1- en

Auto Negotiation                     : ON
                                  -1 fid
                                25 on




20.2             Supported Information
                              20 C
                             2 IA
                           71 ID




The following table provides details on the enabled link and supported cable speeds.
                         09 NV




Table 20-2.         Supported Information
                      11 ah
                        sn




 Parameter                    Description
                      Ki




 Enabled Link Speed           The speed the interface is configured for, both Onyx and Cumulus will
                  ik




                              automatically set this to the highest rate the port supports.
                R




 Supported Cable Speed        The speeds the module declares it supports based on the EEPROM.



Output Example:
Supported Info
--------------
Enabled Link Speed (Ext.)            : 0x00000200 (100G_4X)
Supported Cable Speed (Ext.)         : 0x000002f2 (100G_4X,50G_2X,40G,25G,10G,1G)




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                  DA-11437-001_v13 | 139
                                                                Understanding the mlxlink Utility Output



20.3             Troubleshooting Information
This section offers information on the link's status. The most important row is the
"Recommendation" row. Refer to Section 20.5 “Link Status Opcodes” for descriptions of
the various link status OpCodes.
Output Example:
Status Opcode                        : 0
Group Opcode                         : N/A
Recommendation                       : No issue was observed.




20.4             Physical Counters and BER




                                                                        bs
                 Information




                                                                      La
                                              03 e
This section provides information on the module, with the key focus being on the "Rx/Tx




                                            5: cl
Power Current" row seen in the below output example.




                                          :1 ra
                                        16 al O
In "R/Tx Power Current [dBm]: 2,0,0,2 [-6..8].”
>   2,0,0,2 represent the current power in dBm scale (1dBm = ~1 milliwatt), with each
                                      28 ti
                                    1- en

    value corresponding to a lane. In the case of a QSFP module, there are 4 lanes,
                                  -1 fid


    whereas an SFP module would have only 1 lane.
                                25 on



>   [-6..8] represent the scale of acceptable power values. If the current power
                              20 C




    presented in 2,0,0,2 is below the lowest scale value:
                             2 IA




>   For Rx, it indicates a lack of signal reception from the peer, often accompanied by a
                           71 ID




    recommendation of "No partner detected."
                         09 NV




>   For Tx, it suggests that no signal is being transmitted to the peer (link is disabled).
                      11 ah




If the Rx value exceeds the highest scale value, it implies that the customer should use a
                        sn




longer fiber cable or an attenuator to decrease the signal strength.
                      Ki




It is unlikely for the Tx value to surpass the highest scale value; if encountered, escalation
                  ik




is recommended.
                R




        Note: The power section is not accessible for DAC cables or optic devices lacking Digital
        Diagnostic and Monitoring (DDMI) support. In such cases, these values are derived from the
        module EEPROM.

Output Example:
Module Info
-----------
Identifier                           : QSFP28
Compliance                           : 100G AOC (Active Optical Cable) or 25GAUI C2M AOC with FEC
Cable Technology                     : 850 nm VCSEL
Cable Type                           : Active cable (active copper / optics)
OUI                                  : Other
Vendor Name                          : O-NET


PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                            DA-11437-001_v13 | 140
                                                                    Understanding the mlxlink Utility Output


Vendor Part Number                   : 1AT-3Q4M01XX-12A
Vendor Serial Number                 : 2QA-0050444
Rev                                  : 03
Wavelength [nm]                      : 850
Transfer Distance [m]                : 1
Attenuation (5g,7g,12g) [dB]         : N/A
FW Version                           : N/A
Digital Diagnostic Monitoring        : Yes
Power Class                          : 2.5 W max
CDR RX                               : ON,ON,ON,ON
CDR TX                               : ON,ON,ON,ON
LOS Alarm                            : N/A
Temperature [C]                      : 36 [-5..75]
Voltage [mV]                         : 3352.3 [2970..3630]




                                                                            bs
Bias Current [mA]                    : 6.392,6.166,6.240,6.240 [2..10]
Rx Power Current [dBm]               : 2,0,0,2 [-6..8]




                                                                          La
Tx Power Current [dBm]               : 4,2,2,2 [-6..8]




                                              03 e
                                            5: cl
                                          :1 ra
20.5              Link Status Opcodes
                                        16 al O
                                      28 ti
The following table lists the various link status Opcodes, along with their descriptions
                                    1- en

and recommended mitigation methods.
                                  -1 fid
                                25 on




Table 20-3.         Link Status Opcodes
                              20 C
                             2 IA




 Status Opcode                       Description                     Recommended Mitigation
                           71 ID




 PHY FW indication (0 - 1023):
                         09 NV




 0 – No issue observed                                               Wait 5 seconds and check again. If the
                      11 ah




                                                                     message continues, please check peer side.
                                                                     Additionally, review the mlxlink -m flag
                        sn




                                                                     output and to see if anything is suspicious
                      Ki




                                                                     (for example with transceivers. Rx power is
                  ik




                                                                     -40dbm then need to check fiber and peer
                  R




                                                                     side; example 2: Tx power -40dbm.
 1 – Port is closed by command       Port is shut down by system.    Need to check who sent the command to
                                                                     close the port and reopen it.
 2 – AN failure                      Both sides did not agree on     Debug steps:
                                     speed/FEC or DME is missing.    1) Check Tx power and Rx power from both
                                                                     sides.
                                                                     a. Low Tx power: Check transceiver issue
                                                                     b. Low Rx power: Check Tx power from peer
                                                                     side+ clean fiber and transceiver (both
                                                                     ends).
                                                                     2) Check both sides are configured
                                                                     correctly.
                                                                     a. Same speeds and FECs or that AN is fully
                                                                     enabled.

PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 141
                                                                       Understanding the mlxlink Utility Output


 Status Opcode                       Description                        Recommended Mitigation
 9 – Logical mismatch between        Did not acquire block lock         1) Check both sides are configured
 link partners                                                          correctly.
                                                                        a. Same speeds and FECs or that AN is fully
                                                                        enabled.
                                                                        2) If the issue repeats, please collect data
                                                                        from both sides and report to NVIDIA.
 10 – Logical mismatch between       Did not acquire AM lock (NO        1) Check both sides are configured
 link partners                       FEC)                               correctly.
                                                                        a. Same speeds and FECs or that AN is fully
                                                                        enabled.
                                                                        2) If the issue repeats, please collect data
                                                                        from both sides and report to NVIDIA.




                                                                               bs
 11 – Logical mismatch between       Did not get align status. AN is    1) Check both sides are configured




                                                                             La
 link partners                       done but the signal is not         correctly.
                                     locked. Very rare event.           a. Same speeds and FECs or that AN is fully




                                              03 e
                                            5: cl
                                                                        enabled.




                                          :1 ra
                                                                        2) If the issue repeats, please collect data



                                        16 al O
                                                                        from both sides and report to NVIDIA.
 12 – Logical mismatch between       FC FEC is not locked.              1) Check both sides are configured
                                      28 ti
                                    1- en
 link partners                                                          correctly.
                                  -1 fid


                                                                        a. Same speeds and FECs or that AN is fully
                                                                        enabled.
                                25 on




                                                                        2) If the issue repeats, please collect data
                              20 C




                                                                        from both sides and report to NVIDIA.
                             2 IA




 13 – Logical mismatch between       RS FEC is not locked.              1) Check both sides are configured
                           71 ID




 link partners                                                          correctly.
                         09 NV




                                                                        a. Same speeds and FECs or that AN is fully
                                                                        enabled.
                      11 ah




                                                                        2) If the issue repeats, please collect data
                        sn




                                                                        from both sides and report to NVIDIA.
                      Ki




 14 – Remote fault received                                             Wait 5 seconds and check again. If the
                  ik




                                                                        message persists, please check peer side.
                R




 15 – Bad signal integrity           Low Raw BER. Please ensure         The link is up, but with low BER it is
                                     to have it running for             indication for monitoring and review. There
                                     minimum duration before re-        are two different steps to debug- with
                                     checking.                          Symbol BER and clean Symbol BER:
                                                                        1) Wait to test again after some time and
                                                                        see it is still reoccurring.
                                                                        2) Read the mlxlink -c flag.
                                                                        3) If the Symbol BER is clear of errors, then
                                                                        we just need to monitor the port and see if
                                                                        the Raw BER and Effective BER are stable
                                                                        over time.
                                                                        4) If there are Symbol BERs then check
                                                                        Low Rx power (mlxlink -m) : Check Tx power



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 142
                                                      Understanding the mlxlink Utility Output


 Status Opcode                       Description       Recommended Mitigation
                                                       from peer side + clean fiber and transceiver
                                                       (both ends)
                                                       5) Collect SNR (electrical and optical) from
                                                       both sides:
                                                       a. Available in mlxlink -m and other tools
                                                       6) In case the link stays with low BER, test
                                                       for 125 minutes.
 16 – Cable compliance code                            1) Need to see the port speed is configured
 mismatch (protocol mismatch                           as expected with the cable.
 between cable and port)                               2) Need to see if the cable is the right one
                                                       for the port if it is as expected.
 20 – Stamping of non-NVIDIA                           Replace the cable with an NVIDIA cable.




                                                              bs
 Cables/Modules




                                                            La
 22 – Internal error                                   Not relevant for the field.




                                               03 e
 30 – Port is closed, no backplane                     1) Check the port is configured correctly:




                                             5: cl
 enabled speed over backplane                          a. Same speeds, width and FECs or that AN




                                           :1 ra
 channel                                               is fully enabled.


                                         16 al O
 31 – Port is closed, no passive                       1) Check the port is configured correctly:
 protocol enabled over passive
                                       28 ti
                                                       a. Same speeds, width and FECs or that AN
                                     1- en
 copper channel                                        is fully enabled.
                                   -1 fid


 32 – Port is closed, no active                        1) Check the port is configured correctly:
                                 25 on



 protocol enabled overactive                           a. Same speeds, width and FECs or that AN
                               20 C




 channel                                               is fully enabled.
                              2 IA




 33 – Port width does not match                        1) Check the port is configured correctly:
                            71 ID




 the port speed enabled                                a. Same speeds, width and FECs or that AN
                          09 NV




                                                       is fully enabled.
 34 – Local Speed degradation                          The link is up, but with lower speed than
                       11 ah




                                                       expected. Steps:
                         sn




                                                       1) Wait to test again after some time
                       Ki




                                                       2) Cleaning the fiber from both sides + the
                   ik




                                                       transceivers (can be delayed being a final
                R




                                                       step before escalating)
                                                       3) Look at the Tx power and Rx Power
                                                       a. Low Tx power: Check transceiver issue
                                                       b. Low Rx power: Check Tx power from peer
                                                       side+ clean fiber and transceiver (both
                                                       ends)
                                                       4) Collect SNR (electrical and optical) from
                                                       both sides.
                                                       a. Available in mlxlink -m and other tools.
                                                       5) In case the link stays with low BER, test
                                                       with PRBS.
                                                       a. See the steps in the mlxlink help flag or
                                                       in the attached excel.



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                   DA-11437-001_v13 | 143
                                                                      Understanding the mlxlink Utility Output


 Status Opcode                         Description                     Recommended Mitigation
                                                                       b. In case specific lane doesn’t lock, it might
                                                                       be transceiver, cable, fiber issue.
 35 – Remote Speed degradation                                         Review remote side status.
 36 – No Partner detected during                                       Debug steps:
 force mode.                                                           1) Check Tx power and Rx power from both
                                                                       sides.
                                                                       a. Low Tx power: Check transceiver issue
                                                                       b. Low Rx power: Check Tx power from peer
                                                                       side+ clean fiber and transceiver (both
                                                                       ends)
                                                                       2) Check both sides are configured
                                                                       correctly:




                                                                              bs
                                                                       a. Same speeds and FECs or that AN is fully




                                                                            La
                                                                       enabled.




                                              03 e
 37 – Partial link indication during                                   Debug steps:




                                            5: cl
 force mode.                                                           1) Check Tx power and Rx power from both




                                          :1 ra
                                                                       sides.


                                        16 al O
                                      28 ti                            a. Low Tx power: Check transceiver issue
                                                                       b. Low Rx power: Check Tx power from peer
                                    1- en

                                                                       side+ clean fiber and transceiver (both
                                  -1 fid


                                                                       ends)
                                25 on



                                                                       2) Check both sides are configured
                                                                       correctly:
                              20 C




                                                                       a. Same speeds and FECs or that AN is fully
                             2 IA




                                                                       enabled.
                           71 ID
                         09 NV




 38 – AN failure                       FEC mismatch during override    1) Check both sides are configured
                                                                       correctly.
                      11 ah




                                                                       a. Same speeds and FECs or that AN is fully
                        sn




                                                                       enabled.
                      Ki




 39 – AN failure                       No HCD                          1) Check both sides are configured
                                                                       correctly.
                   ik
                R




                                                                       a. Same speeds and FECs or that AN is fully
                                                                       enabled.
 42 – Bad SI, cable is configured                                      1) Check the port is configured correctly:
 to non-optimal rate                                                   a. Same speeds, width and FECs or that AN
                                                                       is fully enabled.
 51– HST speed mismatch                                                1) Check both sides are configured
                                                                       correctly.
                                                                       a. Same speeds and FECs or that AN is fully
                                                                       enabled.
                                                                       2) It seems to me that for more than that,
                                                                       collect data and report to NVIDIA.
 52 – Eq Fail                          Equalization failure            Collect logs.
                                                                       Toggle the port.



PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 144
                                                                  Understanding the mlxlink Utility Output


 Status Opcode                       Description                   Recommended Mitigation
                                                                   Reset the firmware.
 53 – Link failure due to MCB at                                   Wait for 10 seconds, and if the message is
 link up                                                           reread then share information from both
                                                                   sides and toggle the link.
 54 – PLR didn't get Rx good non                                   Wait for 10 seconds, and if the message is
 sync cell                                                         reread then share information from both
                                                                   sides and toggle the link.
 55 – PSI fatal error                                              Wait for 10 seconds, and if the message is
                                                                   reread then share information from both
                                                                   sides and toggle the link.
 57 – Signal not detected            Power in the Serdes is not    1) Wait to test again after some time.
                                     detected.                     2) Look at the Tx power and Rx Power.




                                                                          bs
                                                                   a. Low Tx power: Check transceiver issue




                                                                        La
                                                                   b. Low Rx power: Check Tx power from peer
                                                                   side+ clean fiber and transceiver (both




                                                03 e
                                              5: cl
                                                                   ends).




                                            :1 ra
                                                                   3) In case the link stays with low BER, test


                                          16 al O
                                                                   with PRBS.
                                                                   a. See the steps in the mlxlink help flag or
                                        28 ti
                                      1- en
                                                                   in the attached excel.
                                    -1 fid


 59 – Did not get module                                           1) Wait to test again after some time.
 configuration done
                                  25 on



                                                                   2) Look at the Tx power and Rx Power.
                                20 C




                                                                   a. Low Tx power: Check transceiver issue
                               2 IA




                                                                   b. Low Rx power: Check Tx power from peer
                             71 ID




                                                                   side+ clean fiber and transceiver (both
                                                                   ends).
                           09 NV




                                                                   3) In case the link stays with low BER, test
                        11 ah




                                                                   with PRBS.
                          sn




                                                                   a. See the steps in the mlxlink help flag or
                                                                   in the attached excel.
                        Ki




                                                                   4) Collet mlxlink and mstdumps and share
                   ik




                                                                   with NVIDIA.
                R




                                                                   a. In case of successful PRBS results: need
                                                                   to debug the FW.
                                                                   b. In case of low BER PRBS results: need to
                                                                   debug the Serdes.
                                                                   c. In case specific lane doesn’t lock, well it
                                                                   gets in interesting and might be
                                                                   transceiver, NIC, FW or Serdes.
 128 – Troubleshooting in                                          Wait 3 seconds and run the command
 process                                                           again.
 1023 – Info not available                                         Wait for 10 seconds, and if the message is
                                                                   reread then share information from both
                                                                   sides and run power cycle.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                DA-11437-001_v13 | 145
                                                                        Understanding the mlxlink Utility Output


 Status Opcode                       Description                         Recommended Mitigation
 1024 – Cable is unplugged           No physical transceiver             Plug transceiver. Please confirm that no
                                     detected on cage.                   one executed command simulating
                                                                         unplugged transceiver.
 1025 – Long Range for non-                                              Should not be seen. Please collect logs in
 Mellanox cable/module                                                   failed state and contact NVIDIA for
                                                                         support.
 1026 – Bus stuck (I2C Data or       Received failure on the I2C         Transceiver reset (Disable/enable), if the
 clock shorted)                      EEPROM communication line.          issue continues, please collect information
                                                                         and data, and then run power cycle.
 1027 – Bad/unsupported              Failed to read EEPROM from          Test with another approved transceiver. Id
 EEPROM                              transceiver or transceiver id is    the issue continues, please collect data and
                                     not recognized.                     share.




                                                                                bs
 1028 – Part number list             Transceiver is not permitted        Replace the cable with cable from the
                                     by vendor list.                     supported list.




                                                                              La
 1029 – Unsupported cable.           SFP transceiver is not              Replace the cable with cable from the




                                              03 e
                                     supported.                          supported list.




                                            5: cl
                                          :1 ra
 1030 – Module temperature           Transceiver temperature             Check the cable temperature and cool the



                                        16 al O
 shutdown                            exceeded allowed threshold.         environment if it is indeed too hot.
 1031 – Shorted cable                Receive over current on the         Bad transceiver, please test with a
                                      28 ti
                                    1- en
                                     transceiver.                        different transceiver.
                                  -1 fid


 1032 – Power budget exceeded        Board power budget have             Review supported power by the transceiver
                                     exceeded.                           and board INI.
                                25 on




 1033 – Management forced            Module shutdown by server           Review the server commands.
                              20 C




 down the port                       command.
                             2 IA
                           71 ID




 1034 – Module is disabled by        Transceiver admin status is         Enable admin status.
 command                             disabled.
                         09 NV




 1035 – System Power is              Power drawn from the system         Check system power input. Could be a
                      11 ah




 Exceeded therefore the module       is above supply, which              system platform issue.
 is powered off                      resulted in power throttling in
                        sn




                                     module.
                      Ki




 1036 - Module’s PMD type is not     Transceiver type not                Replace transceiver.
                  ik




 enabled (see PMTPS)                 supported.
                R




 1040 – pcie system power slot       PCIe device required more           Hardware issue on host system. Only
 Exceeded                            power than what the slot if         applicable to NICs. Not applicable to NVIDIA
                                     capable of.                         Switch devices.
 1042 – Module state machine         Module CMIS state machine           Reset transceiver and replace if problem
 fault                               returned fault for state            repeats.
                                     transition.
 1043 – Module’s stamping                                                Replace the cable with an NVIDIA cable.
 speed degeneration
 1044 – Module’s stamping            HDR speed is not supported          Replace the cable with an NVIDIA cable.
 speed degeneration
 1045 – Module’s stamping            EDR speed is not supported          Replace the cable with an NVIDIA cable.
 speed degeneration




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                    DA-11437-001_v13 | 146
                                                                    Understanding the mlxlink Utility Output


 Status Opcode                       Description                     Recommended Mitigation
 1046 – Module’s stamping            FDR10 speed is not supported    Replace the cable with an NVIDIA cable.
 speed degeneration
 1047 – Modules DataPath FSM         Failed to configure speed       Wait for 10 seconds, and if the message is
 fault                               (application) by transceiver    reread.
 1048 – Modules DataPath FSM         Failed to activate speed        Wait for 10 seconds, and if the message is
 fault                               (application) by transceiver    reread then share information from both
                                                                     sides and run power cycle.
 1050 – Module Boot Error            Module failed to boot. No       Reset transceiver and replace if problem
                                     response with I2C bus.          repeats.
 1051 – Module Boot Error            Module failed to boot. No       Reset transceiver and replace if problem
                                     response with I2C bus.          repeats.
 1052 – Module Boot Error            Module failed to boot. No       Reset transceiver and replace if problem




                                                                            bs
                                     response with I2C bus.          repeats.




                                                                          La
 1053 – Module Boot Error            Module failed to boot. No       Reset transceiver and replace if problem




                                              03 e
                                     response with I2C bus.          repeats.




                                            5: cl
 1054 – Module Forced to Low         Module was set to low power     Check byte 26, bit 6, page 0x0. Ensure it is




                                          :1 ra
 Power by command                    by command (EEPROM write        not set.


                                        16 al O
                                     or GPIO).
                                      28 ti
 CPO only (1055 – 1059)
                                    1- en

 1055 – ELS laser fiber is           Applicable to systems with
                                  -1 fid


 contaminated                        CPO only.
                                25 on




 1056 – ELS laser fiber              Applicable to systems with
                              20 C




                                     CPO only.
                             2 IA




 1057 – ELS unplugged                Applicable to systems with
                           71 ID




                                     CPO only.
                         09 NV




 1058 – ELS fatal indication         Applicable to systems with
                                     CPO only.
                      11 ah




 1059 – ELS temperature error        Applicable to systems with
                        sn




                                     CPO only.
                      Ki




 Core/Driver (2048 - 3071)
                  ik
                R




 2048 – MPR Violation (Under 64                                      Wait for 10 seconds, and if the message is
 bytes between two starts)                                           reread then share information from both
                                                                     sides and run power cycle.




PRELIMINARY INFORMATION
NVIDIA CONFIDENTIAL
Debug and RAS Guide for NVIDIA Data Center Products                                 DA-11437-001_v13 | 147
 Notice
 This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality
 of a product. NVIDIA Corporation (“NVIDIA”) makes no representations or warranties, expressed or implied, as to the accuracy or completeness
 of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for
 the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use.
 This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.
 NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any
 time without notice.
 Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.
 NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless
 otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (“Terms of Sale”). NVIDIA
 hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product
 referenced in this document. No contractual obligations are formed either directly or indirectly by this document.
 NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment,
 nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or
 property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications
 and therefore such inclusion and/or use is at customer’s own risk.
 NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all




                                                                                                       bs
 parameters of each product is not necessarily performed by NVIDIA. It is customer’s sole responsibility to evaluate and determine the
 applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer,




                                                                                                     La
 and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customer’s
 product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or




                                                          03 e
                                                        5: cl
 requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which
 may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product




                                                      :1 ra
 designs.



                                                    16 al O
 No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under
 this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use
                                                  28 ti
 such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the
                                                1- en
 patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights
 of NVIDIA.
                                              -1 fid


 Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration
                                            25 on



 and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.
 THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER
                                          20 C




 DOCUMENTS (TOGETHER AND SEPARATELY, “MATERIALS”) ARE BEING PROVIDED “AS IS.” NVIDIA MAKES NO WARRANTIES, EXPRESSED,
                                         2 IA




 IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF
 NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO
                                       71 ID




 EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL,
                                     09 NV




 PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE
 OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that
 customer might incur for any reason whatsoever, NVIDIA’s aggregate and cumulative liability towards customer for the products described
                                  11 ah




 herein shall be limited in accordance with the Terms of Sale for the product.
                                    sn
                                  Ki




 Trademarks
                              ik




 NVIDIA, the NVIDIA logo, BlueField, ConnectX, CUDA, NVIDIA GPU Boost, NVIDIA Grace, NVIDIA HGX, NVIDIA Hopper, NVLink, NVLink-C2C
                           R




 NVSwitch, and Tegra are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and
 product names may be trademarks of the respective companies with which they are associated.


 Copyright
 © 2023, 2024, 2025 NVIDIA Corporation. All rights reserved.




NVIDIA Corporation | 2788 San Tomas Expressway, Santa Clara, CA 95051
http://www.nvidia.com
